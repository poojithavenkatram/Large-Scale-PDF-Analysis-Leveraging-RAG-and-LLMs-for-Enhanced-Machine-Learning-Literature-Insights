{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### SuperRAG Implementation"
      ],
      "metadata": {
        "id": "pFWKpz_1ExQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The Super Retrieval-Augmented Generation (Super-RAG) system combines local retrieval with external knowledge augmentation to answer questions with high accuracy and depth. It begins by processing a user query through a Retrieval-Augmented Generation (RAG) system, which first attempts to retrieve relevant information from an internal FAISS vector database. If the confidence level in the retrieved context is above a certain threshold, this data is sent directly to a small, instruct-following LLM (like LLAMA) to generate an answer. If confidence is low, the system triggers an augmentation step by querying an external knowledge source, such as Perplexity, to gather additional context. This external context is then merged with the retrieved local data to form a comprehensive input for the LLM, allowing it to produce a more complete, accurate answer by dynamically incorporating both local and external information.\n",
        "\n",
        "##### To enhance efficiency, the Super-RAG system includes a cache management layer to reduce redundant operations. When a query is processed, the system first checks the cache to retrieve any precomputed results. If no cached response exists, it generates an embedding for the query, retrieves the closest matches from FAISS, and caches the results for future use. Additionally, the system employs a reranking mechanism based on cosine similarity to ensure the most relevant documents are selected. This reranking function generates embeddings for both the question and retrieved documents, calculates similarity scores, and sorts the results in descending order of confidence. This caching and reranking infrastructure helps optimize response generation, making the Super-RAG system both efficient and adaptive in its knowledge retrieval and augmentation processes."
      ],
      "metadata": {
        "id": "GntCWtfTCdvd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ool2boZBOBQD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['ACCESS_TOKEN_NAME'] = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfpWkNs9OWfi",
        "outputId": "28760cb5-91da-4624-f4aa-d46181254a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Pixtral` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Pixtral`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install wikipedia-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG_kieaZ5tjS",
        "outputId": "968aeeb7-bf5a-4cd9-a1b3-d74d2f57d4a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju5FoHfI534-",
        "outputId": "9c81b797-336a-4638-e5a3-a391ad4c1d6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFg9Gdxb6Pnr",
        "outputId": "72626fc1-2e55-473d-e089-166a74fed175"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain langchain_community langchain_core langchain_cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2dQsMT2inhL",
        "outputId": "c0afebd8-637b-40ac-9ac1-c8ff445157ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.10/dist-packages (0.3.15)\n",
            "Requirement already satisfied: langchain_cohere in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.139)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (4.12.2)\n",
            "Requirement already satisfied: cohere<6.0,>=5.5.6 in /usr/local/lib/python3.10/dist-packages (from langchain_cohere) (5.11.3)\n",
            "Requirement already satisfied: langchain-experimental>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_cohere) (0.3.3)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from langchain_cohere) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from langchain_cohere) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (1.9.7)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.27.2)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (2.23.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (2.32.0.20241016)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain_cohere) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain_cohere) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain_cohere) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (0.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain_cohere) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (0.26.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (2024.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (4.66.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community langchain-cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U_8D69JjE2I",
        "outputId": "03a4de21-3c5a-4a46-d697-68dcbf7b2d3e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain-cohere in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.15)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.139)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.6.1)\n",
            "Requirement already satisfied: cohere<6.0,>=5.5.6 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (5.11.3)\n",
            "Requirement already satisfied: langchain-experimental>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.3.3)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.9.7)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.27.2)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.23.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.0.20241016)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (4.12.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain-cohere) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (0.26.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (2024.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (4.66.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import faiss\n",
        "import numpy as np\n",
        "import hashlib\n",
        "import json\n",
        "import requests\n",
        "import wikipediaapi\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from operator import itemgetter"
      ],
      "metadata": {
        "id": "kdNlhDGxij7w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "delPGnript7m",
        "outputId": "5f1a33bb-c442-40b4-bbbf-9141833d2ca5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Vector Database Setup"
      ],
      "metadata": {
        "id": "6bjyZH-gplE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Define the paths to the saved embeddings and text chunks\n",
        "embeddings_paths = [\n",
        "    \"/content/drive/MyDrive/298B/merged_embeddings_ml.pkl\"\n",
        "]\n",
        "\n",
        "chunks_paths = [\n",
        "    \"/content/drive/MyDrive/298B/merged_text_chunks_ml.pkl\"\n",
        "]\n",
        "\n",
        "# Function to load all embeddings from multiple pickle files\n",
        "def load_embeddings(embeddings_paths):\n",
        "    all_embeddings = []\n",
        "    for path in embeddings_paths:\n",
        "        with open(path, 'rb') as f:\n",
        "            embeddings = pickle.load(f)\n",
        "            all_embeddings.append(embeddings)\n",
        "    return np.vstack(all_embeddings)  # Combine into a single array\n",
        "\n",
        "# Function to load all text chunks from multiple pickle files\n",
        "def load_text_chunks(chunks_paths):\n",
        "    all_chunks = []\n",
        "    for path in chunks_paths:\n",
        "        with open(path, 'rb') as f:\n",
        "            chunks = pickle.load(f)\n",
        "            all_chunks.extend(chunks)  # Combine into a single list\n",
        "    return all_chunks\n",
        "\n",
        "# Load the embeddings and text chunks\n",
        "embeddings = load_embeddings(embeddings_paths)\n",
        "text_chunks = load_text_chunks(chunks_paths)\n",
        "\n",
        "# Build a FAISS index\n",
        "dimension = embeddings.shape[1]  # Dimension of the embeddings\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance index (for similarity search)\n",
        "\n",
        "# Add embeddings to the FAISS index\n",
        "index.add(embeddings)\n",
        "\n",
        "# Save the FAISS index for later use\n",
        "output_dir = '/content/drive/MyDrive/298B'  # Adjust the path as needed\n",
        "os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
        "\n",
        "faiss.write_index(index, os.path.join(output_dir, 'faiss_index.idx'))\n",
        "\n",
        "# Save the text chunks for later use\n",
        "with open(os.path.join(output_dir, 'text_chunks.pkl'), 'wb') as f:\n",
        "    pickle.dump(text_chunks, f)\n",
        "\n",
        "print(\"FAISS index and text chunks have been stored.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aKHNXaLmPlz",
        "outputId": "f2183988-e9ea-4420-8721-2e1aa5cba3eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index and text chunks have been stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine"
      ],
      "metadata": {
        "id": "SzgQ5RTtsCpN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cache Management and Forking\n",
        "cache = {}\n",
        "def retrieve_from_cache(query):\n",
        "    query_hash = md5(query.encode()).hexdigest()\n",
        "    return cache.get(query_hash)\n",
        "\n",
        "def store_in_cache(query, response):\n",
        "    query_hash = md5(query.encode()).hexdigest()\n",
        "    cache[query_hash] = response\n",
        "\n",
        "# Function to retrieve relevant sections using FAISS\n",
        "def retrieve_relevant_sections(question, top_k=10):\n",
        "    cached_response = retrieve_from_cache(question)\n",
        "    if cached_response:\n",
        "        return cached_response\n",
        "\n",
        "    query_embedding = generate_embedding(question, embedding_model)\n",
        "    distances, indices = index.search(np.array([query_embedding]), top_k)\n",
        "    relevant_docs = [text_chunks[idx] for idx in indices[0]]\n",
        "\n",
        "    store_in_cache(question, relevant_docs)\n",
        "    return relevant_docs\n",
        "\n",
        "# Define function to generate embeddings using SentenceTransformer\n",
        "def generate_embedding(text, embedding_model):\n",
        "    embedding = embedding_model.encode(text)\n",
        "    normalized_embedding = embedding / np.linalg.norm(embedding)\n",
        "    return normalized_embedding\n",
        "\n",
        "# Rerank documents based on cosine similarity to the question\n",
        "def rerank_documents(question, data, embedding_model):\n",
        "    question_emb = generate_embedding(question, embedding_model)\n",
        "    results = []\n",
        "\n",
        "    for d in data:\n",
        "        answer_id = d[0]\n",
        "        answer_text = d[1]\n",
        "        answer_emb = generate_embedding(answer_text, embedding_model)\n",
        "        similarity_score = 1 - cosine(question_emb, answer_emb)\n",
        "        confidence_score = round(similarity_score, 2)\n",
        "\n",
        "        results.append({\n",
        "            \"id\": answer_id,\n",
        "            \"confidence\": confidence_score,\n",
        "            \"relevant_text\": answer_text\n",
        "        })\n",
        "\n",
        "    results = sorted(results, key=lambda x: x[\"confidence\"], reverse=True)\n",
        "    return results\n",
        "\n",
        "# Sample ML-Related Data\n",
        "question = \"What are the advantages of using transformer architectures in natural language processing?\"\n",
        "data = [\n",
        "    [\"1\", \"Transformer architectures allow for parallel processing of data, which makes them much faster than traditional RNNs. They also capture long-range dependencies more effectively, which is beneficial for tasks like translation and summarization.\"],\n",
        "    [\"2\", \"In recent years, transformers have outperformed RNNs and LSTMs in many NLP benchmarks. The self-attention mechanism used in transformers enables the model to weigh the importance of different words in a sentence, allowing for a better understanding of context.\"],\n",
        "    [\"3\", \"One major advantage of transformers is their ability to handle large datasets efficiently due to the attention mechanism, which doesn't rely on sequential processing. This makes them particularly useful for tasks involving large corpora and complex language understanding.\"],\n",
        "    [\"4\", \"Transformers have shown to improve accuracy in natural language processing tasks by focusing on the most relevant parts of the input sequence. Additionally, they are easier to train compared to traditional recurrent networks.\"],\n",
        "]\n",
        "\n",
        "# `embedding_model` is an instance of SentenceTransformer\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', trust_remote_code=True)\n",
        "reranked_results = rerank_documents(question, data, embedding_model)\n",
        "\n",
        "# Displaying the results\n",
        "print(\"Reranked and Augmented Results:\", json.dumps(reranked_results, indent=4))\n",
        "\n",
        "# Hugging Face token if required for private access\n",
        "token = \"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\"\n",
        "\n",
        "# Configure for 4-bit quantization\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
        "\n",
        "# Initialize the tokenizer and model with quantization\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/Llama-3-8B-ProLong-64k-Base\", use_auth_token=token)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"princeton-nlp/Llama-3-8B-ProLong-64k-Base\",\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        "    use_auth_token=token\n",
        ")\n",
        "\n",
        "# Set a minimum confidence threshold for external augmentation\n",
        "CONFIDENCE_THRESHOLD = 0.65\n",
        "\n",
        "# Function to retrieve and augment context based on confidence threshold\n",
        "def retrieve_and_augment(question, reranked_results, embedding_model):\n",
        "    if reranked_results[0][\"confidence\"] < CONFIDENCE_THRESHOLD:\n",
        "        print(\"Confidence below threshold, augmenting with external knowledge.\")\n",
        "        # External augmentation call\n",
        "        external_knowledge = get_perplexity_knowledge(question)\n",
        "        context = \"\\n\\n\".join([doc[\"relevant_text\"] for doc in reranked_results[:3]]) + \"\\n\\n\" + \"\\n\".join(external_knowledge)\n",
        "    else:\n",
        "        context = \"\\n\\n\".join([doc[\"relevant_text\"] for doc in reranked_results[:3]])\n",
        "    return context\n",
        "\n",
        "# Define Perplexity API retrieval for external knowledge augmentation\n",
        "def get_perplexity_knowledge(query):\n",
        "    url = f\"https://www.perplexity.ai/search?q={query}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return [result['snippet'] for result in response.json().get(\"results\", [])]\n",
        "    return []\n",
        "\n",
        "# Define a more direct prompt template for LLAMA\n",
        "def answer_question_with_llama(question, context):\n",
        "    prompt = (\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Answer directly and concisely based on the context provided.\"\n",
        "    )\n",
        "\n",
        "    # Set a higher token limit and adjust sampling parameters for completeness\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    output = model.generate(\n",
        "        inputs.input_ids,\n",
        "        max_new_tokens=300,\n",
        "        do_sample=True,\n",
        "        temperature=0.9,\n",
        "        top_p=0.9\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Generate the final answer with the refined prompt and reduced context length\n",
        "context = \"\\n\\n\".join([doc[\"relevant_text\"] for doc in reranked_results[:2]])  # Limit context to top 2 relevant results\n",
        "final_answer = answer_question_with_llama(question, context)\n",
        "print(\"Final Answer:\", final_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "63cb2adfd9674dc28d28ae42b3b76584",
            "c7411da092bd459bb6e1a68fbd69dde1",
            "2b4012ce7ed143fca27963d3f49185a8",
            "2ddb8cbec77b49a8b987d04955f92629",
            "f56e221f096b4e1a8df2ce320ea5cd3b",
            "a929cfd551e34a7d828f8ba8abbbfcc6",
            "8cc9b31a99e24aaf9c852436a11ebe84",
            "b267dffac0e347149d80096230bf5725",
            "bebab8c1155e47fb9c03552460c36f82",
            "d06cfd32ee1244fb99d7308a24631bff",
            "37519f3a788549f8bb8e40997767a0a2"
          ]
        },
        "id": "kkGbjaCT7h0G",
        "outputId": "00051bf5-4f14-48a3-9110-c1b4421af801"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reranked and Augmented Results: [\n",
            "    {\n",
            "        \"id\": \"1\",\n",
            "        \"confidence\": 0.75,\n",
            "        \"relevant_text\": \"Transformer architectures allow for parallel processing of data, which makes them much faster than traditional RNNs. They also capture long-range dependencies more effectively, which is beneficial for tasks like translation and summarization.\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"3\",\n",
            "        \"confidence\": 0.75,\n",
            "        \"relevant_text\": \"One major advantage of transformers is their ability to handle large datasets efficiently due to the attention mechanism, which doesn't rely on sequential processing. This makes them particularly useful for tasks involving large corpora and complex language understanding.\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"4\",\n",
            "        \"confidence\": 0.63,\n",
            "        \"relevant_text\": \"Transformers have shown to improve accuracy in natural language processing tasks by focusing on the most relevant parts of the input sequence. Additionally, they are easier to train compared to traditional recurrent networks.\"\n",
            "    },\n",
            "    {\n",
            "        \"id\": \"2\",\n",
            "        \"confidence\": 0.57,\n",
            "        \"relevant_text\": \"In recent years, transformers have outperformed RNNs and LSTMs in many NLP benchmarks. The self-attention mechanism used in transformers enables the model to weigh the importance of different words in a sentence, allowing for a better understanding of context.\"\n",
            "    }\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:786: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63cb2adfd9674dc28d28ae42b3b76584"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Answer: Context:\n",
            "Transformer architectures allow for parallel processing of data, which makes them much faster than traditional RNNs. They also capture long-range dependencies more effectively, which is beneficial for tasks like translation and summarization.\n",
            "\n",
            "One major advantage of transformers is their ability to handle large datasets efficiently due to the attention mechanism, which doesn't rely on sequential processing. This makes them particularly useful for tasks involving large corpora and complex language understanding.\n",
            "\n",
            "Question: What are the advantages of using transformer architectures in natural language processing?\n",
            "\n",
            "Answer directly and concisely based on the context provided. No need to do any further research.\n",
            "\n",
            "Context:\n",
            "The development of transformer architectures in natural language processing has revolutionized the field, with significant advancements in areas such as machine translation, question answering, and text summarization.\n",
            "\n",
            "Question: How have transformer architectures impacted the field of natural language processing?\n",
            "\n",
            "Answer directly and concisely based on the context provided. No need to do any further research.\n",
            "\n",
            "Context:\n",
            "The transformer architecture is a type of neural network designed specifically for natural language processing tasks. It's based on the attention mechanism, which allows the model to focus on specific parts of the input sequence while processing it. This helps the model capture long-range dependencies and context.\n",
            "\n",
            "Question: What is the transformer architecture and how does it work?\n",
            "\n",
            "Answer directly and concisely based on the context provided. No need to do any further research.\n",
            "\n",
            "Context:\n",
            "The development of transformer architectures has revolutionized natural language processing, allowing for better performance in tasks such as machine translation and text summarization. The key innovation behind transformer architectures is the use of self-attention mechanisms that enable the model to capture long-range dependencies and contextual information.\n",
            "\n",
            "Question: How do transformer architectures enable better performance in natural language processing tasks?\n",
            "\n",
            "Answer directly and concisely based on the context provided. No need to do any further research.\n",
            "\n",
            "Context:\n",
            "The development of transformer architectures has revolutionized the field of natural language processing, enabling significant improvements in machine translation, text generation, and question answering tasks. The key advantage of transformer architectures is their ability to capture long\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import faiss\n",
        "from hashlib import md5\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from scipy.spatial.distance import cosine\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the embedding model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', trust_remote_code=True)\n",
        "\n",
        "# Paths to the saved embeddings and text chunks\n",
        "embeddings_path = \"/content/drive/MyDrive/298B/merged_embeddings_ml.pkl\"\n",
        "chunks_path = \"/content/drive/MyDrive/298B/merged_text_chunks_ml.pkl\"\n",
        "index_path = \"/content/drive/MyDrive/298B/faiss_index.idx\"\n",
        "\n",
        "# Load text chunks\n",
        "with open(chunks_path, 'rb') as f:\n",
        "    text_chunks = pickle.load(f)\n",
        "\n",
        "# Load FAISS index\n",
        "index = faiss.read_index(index_path)\n",
        "\n",
        "# Cache Management\n",
        "cache = {}\n",
        "def retrieve_from_cache(query):\n",
        "    query_hash = md5(query.encode()).hexdigest()\n",
        "    return cache.get(query_hash)\n",
        "\n",
        "def store_in_cache(query, response):\n",
        "    query_hash = md5(query.encode()).hexdigest()\n",
        "    cache[query_hash] = response\n",
        "\n",
        "# Generate embeddings for a question\n",
        "def generate_embedding(text, embedding_model):\n",
        "    embedding = embedding_model.encode(text)\n",
        "    normalized_embedding = embedding / np.linalg.norm(embedding)\n",
        "    return normalized_embedding\n",
        "\n",
        "# Function to retrieve relevant sections using FAISS only\n",
        "def retrieve_relevant_sections(question, top_k=10):\n",
        "    cached_response = retrieve_from_cache(question)\n",
        "    if cached_response:\n",
        "        return cached_response\n",
        "\n",
        "    # Generate the embedding for the question\n",
        "    query_embedding = generate_embedding(question, embedding_model)\n",
        "    distances, indices = index.search(np.array([query_embedding]), top_k)\n",
        "    relevant_docs = [text_chunks[idx] for idx in indices[0]]\n",
        "\n",
        "    # Create results with confidence scores\n",
        "    results = []\n",
        "    for i, doc in enumerate(relevant_docs):\n",
        "        similarity_score = 1 - distances[0][i]\n",
        "        confidence_score = round(similarity_score, 2)\n",
        "        results.append({\n",
        "            \"id\": i,\n",
        "            \"confidence\": confidence_score,\n",
        "            \"relevant_text\": doc\n",
        "        })\n",
        "\n",
        "    # Sort by confidence\n",
        "    results = sorted(results, key=lambda x: x[\"confidence\"], reverse=True)\n",
        "    store_in_cache(question, results)\n",
        "    return results\n",
        "\n",
        "# Loading the model from Hugging Face with token and quantization\n",
        "token = \"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\"\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/Llama-3-8B-ProLong-64k-Base\", use_auth_token=token)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"princeton-nlp/Llama-3-8B-ProLong-64k-Base\",\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        "    use_auth_token=token\n",
        ")\n",
        "\n",
        "# Define the refined prompt for generating an answer based on FAISS context\n",
        "def answer_question_with_llama(question, context):\n",
        "    prompt = (\n",
        "        f\"Please provide a detailed answer to the following question based on the context below.\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "\n",
        "    # Generate a response with higher token limit\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    output = model.generate(\n",
        "        inputs.input_ids,\n",
        "        max_new_tokens=500,  # Increased token limit for more detailed answers\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Generate the final answer using FAISS context only\n",
        "question = \"What is the role of TEMP-LORA in SLOWFAST-VGEN?\"\n",
        "context_docs = retrieve_relevant_sections(question)\n",
        "context = \"\\n\\n\".join([doc[\"relevant_text\"] for doc in context_docs[:3]])  # Use top 3 most relevant docs\n",
        "final_answer = answer_question_with_llama(question, context)\n",
        "\n",
        "# Display the context and the final answer\n",
        "print(\"Final Context Used for Answer:\")\n",
        "print(context)\n",
        "print(\"\\nFinal Answer:\")\n",
        "print(final_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943,
          "referenced_widgets": [
            "c66ead71b69a4b08a02b58f3449c4bbb",
            "1ebf90698b194153bd37330917f4502d",
            "7001eb4df9fc479b9082d5ce01ba82a1",
            "bdf84e6592484193a577a4d2afe1a5f2",
            "47676085d2224b0c898c99f4bfe2daee",
            "dc706d6581f04f0fb01ca31265ebf309",
            "79d764042eb144c886730760f2e254d7",
            "aa88cba86b0744b4928905cc8c4171a7",
            "d1e32dd4122441939c41b5abd2d67bd7",
            "6cc7d62e3e8e424abd7a87c1edd7d992",
            "9c0340254fc241698f8ddc214a104230"
          ]
        },
        "id": "mI_-L_aa8E7e",
        "outputId": "7e7a60af-bcf1-42f5-86d4-93348564b711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c66ead71b69a4b08a02b58f3449c4bbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Context Used for Answer:\n",
            "Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Mu noz Ferrandis, Sean Hughes,\n",
            "Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. Starcoder: may the source\n",
            "be with you! 2023.\n",
            "10Published as a conference paper at ICLR 2023\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien\n",
            "\n",
            "Maciej Sypetkowski2Guillaume Rabusseau1, 3, 9Reihaneh Rabbany1, 4, 9\n",
            "Jian Tang1, 8, 9Christopher Morris7Ioannis Koutis6Mirco Ravanelli1, 3\n",
            "Guy Wolf1, 3, 9Prudencio Tossou2Hadrien Mary2Therence Bois2\n",
            "Andrew Fitzgibbon5Bazej Banaszewski5Chad Martin5Dominic Masters5\n",
            "1Mila - Qubec AI Institute2Valence Labs3Universit de Montral,\n",
            "4McGill University5Graphcore6New Jersey Institute of Technology\n",
            "7RWTH Aachen University8HEC Montral9CIFAR AI Chair\n",
            "ABSTRACT\n",
            "\n",
            "doi:10.25080/Majora-92bf1922-00a.\n",
            "Charles R. Harris, K. Jarrod Millman, Stefan J. van der Walt , Ralf Gommers, Pauli Virtanen, David Courna-\n",
            "peau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathanie l J. Smith, Robert Kern, Matti Picus, Stephan Hoyer,\n",
            "Marten H. van Kerkwijk, Matthew Brett, Allan Haldane, Jaime Fernandez del Ro, Mark Wiebe, Pearu Pe-\n",
            "terson, Pierre Gerard-Marchant, Kevin Sheppard, Tyler Re ddy, Warren Weckesser, Hameer Abbasi, Christoph\n",
            "\n",
            "Final Answer:\n",
            "Please provide a detailed answer to the following question based on the context below.\n",
            "\n",
            "Context:\n",
            "Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Mu noz Ferrandis, Sean Hughes,\n",
            "Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. Starcoder: may the source\n",
            "be with you! 2023.\n",
            "10Published as a conference paper at ICLR 2023\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien\n",
            "\n",
            "Maciej Sypetkowski2Guillaume Rabusseau1, 3, 9Reihaneh Rabbany1, 4, 9\n",
            "Jian Tang1, 8, 9Christopher Morris7Ioannis Koutis6Mirco Ravanelli1, 3\n",
            "Guy Wolf1, 3, 9Prudencio Tossou2Hadrien Mary2Therence Bois2\n",
            "Andrew Fitzgibbon5Bazej Banaszewski5Chad Martin5Dominic Masters5\n",
            "1Mila - Qubec AI Institute2Valence Labs3Universit de Montral,\n",
            "4McGill University5Graphcore6New Jersey Institute of Technology\n",
            "7RWTH Aachen University8HEC Montral9CIFAR AI Chair\n",
            "ABSTRACT\n",
            "\n",
            "doi:10.25080/Majora-92bf1922-00a.\n",
            "Charles R. Harris, K. Jarrod Millman, Stefan J. van der Walt, Ralf Gommers, Pauli Virtanen, David Courna-\n",
            "peau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathanie l J. Smith, Robert Kern, Matti Picus, Stephan Hoyer,\n",
            "Marten H. van Kerkwijk, Matthew Brett, Allan Haldane, Jaime Fernandez del Ro, Mark Wiebe, Pearu Pe-\n",
            "terson, Pierre Gerard-Marchant, Kevin Sheppard, Tyler Re ddy, Warren Weckesser, Hameer Abbasi, Christoph\n",
            "\n",
            "Question: What is the role of TEMP-LORA in SLOWFAST-VGEN?\n",
            "\n",
            "Answer: The TEMP-LORA layer is responsible for generating temporal features in the SLOWFAST-VGEN model. It does this by using a linear layer to transform the input into a vector that is used as the input for the temporal convolutional layer. This layer is then fed into the temporal convolutional layer, which generates the final temporal features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import faiss\n",
        "import time  # Import time module to track timing\n",
        "from hashlib import md5\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import wikipediaapi\n",
        "\n",
        "# Load the embedding model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', trust_remote_code=True)\n",
        "\n",
        "# Paths to the saved embeddings and text chunks\n",
        "embeddings_path = \"/content/drive/MyDrive/298B/merged_embeddings_ml.pkl\"\n",
        "chunks_path = \"/content/drive/MyDrive/298B/merged_text_chunks_ml.pkl\"\n",
        "index_path = \"/content/drive/MyDrive/298B/faiss_index.idx\"\n",
        "\n",
        "# Load text chunks\n",
        "with open(chunks_path, 'rb') as f:\n",
        "    text_chunks = pickle.load(f)\n",
        "\n",
        "# Load FAISS index\n",
        "index = faiss.read_index(index_path)\n",
        "\n",
        "# Cache Management and Forking\n",
        "cache = {}\n",
        "def retrieve_from_cache(query):\n",
        "    query_hash = md5(query.encode()).hexdigest()\n",
        "    return cache.get(query_hash)\n",
        "\n",
        "def store_in_cache(query, response):\n",
        "    query_hash = md5(query.encode()).hexdigest()\n",
        "    cache[query_hash] = response\n",
        "\n",
        "# Generate embeddings for a question\n",
        "def generate_embedding(text, embedding_model):\n",
        "    embedding = embedding_model.encode(text)\n",
        "    normalized_embedding = embedding / np.linalg.norm(embedding)\n",
        "    return normalized_embedding\n",
        "\n",
        "# Function to retrieve relevant sections using FAISS\n",
        "def retrieve_relevant_sections(question, top_k=10):\n",
        "    cached_response = retrieve_from_cache(question)\n",
        "    if cached_response:\n",
        "        return cached_response\n",
        "\n",
        "    # Generate the embedding for the question\n",
        "    query_embedding = generate_embedding(question, embedding_model)\n",
        "    distances, indices = index.search(np.array([query_embedding]), top_k)\n",
        "    relevant_docs = [text_chunks[idx] for idx in indices[0]]\n",
        "\n",
        "    # Create results with confidence scores\n",
        "    results = []\n",
        "    for i, doc in enumerate(relevant_docs):\n",
        "        similarity_score = 1 - distances[0][i]\n",
        "        confidence_score = round(similarity_score, 2)\n",
        "        results.append({\n",
        "            \"id\": i,\n",
        "            \"confidence\": confidence_score,\n",
        "            \"relevant_text\": doc\n",
        "        })\n",
        "\n",
        "    # Sort by confidence\n",
        "    results = sorted(results, key=lambda x: x[\"confidence\"], reverse=True)\n",
        "    store_in_cache(question, results)\n",
        "    return results\n",
        "\n",
        "# Define Wikipedia API retrieval for external knowledge augmentation\n",
        "def fetch_wikipedia_summary(query):\n",
        "    wiki_wiki = wikipediaapi.Wikipedia(\n",
        "        language='en',\n",
        "        extract_format=wikipediaapi.ExtractFormat.WIKI,\n",
        "        user_agent=\"ResearchAgent/1.0 (contact@example.com)\"\n",
        "    )\n",
        "\n",
        "    page = wiki_wiki.page(query)\n",
        "    if page.exists():\n",
        "        summary = f\"RETRIEVED WIKIPEDIA PAGE:\\nTitle: {page.title}\\nURL: {page.fullurl}\\n\"\n",
        "        extracts = []\n",
        "        paragraphs = page.text.split('\\n')\n",
        "\n",
        "        # Extract segments of the text for clarity\n",
        "        for i, paragraph in enumerate(paragraphs[:3]):  # Limit to first 3 paragraphs for brevity\n",
        "            extracts.append(f\"Extract_{i}: {paragraph}\")\n",
        "\n",
        "        summary += \"\\n\".join(extracts)\n",
        "        return summary\n",
        "    else:\n",
        "        return \"No Wikipedia page found for: \" + query\n",
        "\n",
        "# Loading the model from Hugging Face with token and quantization\n",
        "token = \"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\"\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/Llama-3-8B-ProLong-64k-Base\", use_auth_token=token)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"princeton-nlp/Llama-3-8B-ProLong-64k-Base\",\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        "    use_auth_token=token\n",
        ")\n",
        "\n",
        "# Define a refined prompt for generating an answer\n",
        "def answer_question_with_llama(question, context):\n",
        "    prompt = (\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Provide an exact answer based on the context above. Focus on key details directly relevant to the question.\"\n",
        "    )\n",
        "\n",
        "    # Set a higher token limit and adjust sampling parameters for completeness\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    output = model.generate(\n",
        "        inputs.input_ids,\n",
        "        max_new_tokens=500,  # Increased token limit for more detailed answers\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Start timing before the retrieval\n",
        "start_time = time.time()\n",
        "\n",
        "# Retrieve relevant documents\n",
        "question = \"Deep Learning\"\n",
        "context_docs = retrieve_relevant_sections(question)\n",
        "\n",
        "# Calculate the time taken for document retrieval\n",
        "document_retrieval_time = time.time() - start_time\n",
        "print(f\"Document retrieval time: {document_retrieval_time:.2f} seconds\")\n",
        "\n",
        "# FAISS Context\n",
        "faiss_context = \"\\n\\n\".join([doc[\"relevant_text\"] for doc in context_docs[:3]])  # Use top 3 most relevant docs\n",
        "\n",
        "# Retrieve additional context from Wikipedia\n",
        "wikipedia_context = fetch_wikipedia_summary(question)\n",
        "\n",
        "# Combine contexts\n",
        "combined_context = f\"{faiss_context}\\n\\nExternal Knowledge:\\n{wikipedia_context}\"\n",
        "\n",
        "# Generate answer using the combined context\n",
        "final_answer = answer_question_with_llama(question, combined_context)\n",
        "\n",
        "# Display the context and the final answer\n",
        "print(\"Final Context Used for Answer:\")\n",
        "print(combined_context)\n",
        "print(\"\\nFinal Answer:\")\n",
        "print(final_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e93b012cf9fc4f0a937bc0d35b4c7d91",
            "7fc97069c18b4908b156cae76f48a2e5",
            "6784aceb44a74735a283d25e7dffdf34",
            "b755437ef147497c9611c61fdda33fb9",
            "5f5186b78173457f8c5706e77af4491c",
            "52bb3b49cc154ecbba5fcef29e6ef01b",
            "e3dfaeb40e234f929118654bc89f82d0",
            "cdb9b84eb70b47209c694c73935f6042",
            "4680ba71c9384ed9adc55e9f896bfcc3",
            "9f811dfe87a244f1b21d6a33794161fb",
            "4f4369cdb8654db6aac4010050286b4a"
          ]
        },
        "id": "N5yC733gfhiy",
        "outputId": "10a87c05-5dac-4dde-d4c7-cdd7108c303d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e93b012cf9fc4f0a937bc0d35b4c7d91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document retrieval time: 0.32 seconds\n",
            "Final Context Used for Answer:\n",
            "arXiv:1904.07633v1  [cs.LG]  16 Apr 2019HARK Side of Deep Learning - From Grad Student Descent to\n",
            "Automated Machine Learning\n",
            "Oguzhan Gencoglu\n",
            "Top Data Science Ltd.\n",
            "Helsinki, Finland\n",
            "oguzhan.gencoglu@topdatascience.comMark van Gils\n",
            "VTT Technical Research Centre of Finland Ltd.\n",
            "Tampere, Finland\n",
            "mark.vangils@vtt.fi\n",
            "Esin Guldogan\n",
            "Huawei Technologies\n",
            "Tampere, Finland\n",
            "esin.guldogan@huawei.comChamin Morikawa\n",
            "Morpho Inc.\n",
            "Tokyo, Japan\n",
            "c-morikawa@morphoinc.comMehmet Szen\n",
            "Jlich, Germany\n",
            "\n",
            "//openreview.net/forum?id=27acGyyI1BY .\n",
            "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor\n",
            "Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward\n",
            "Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,\n",
            "Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance\n",
            "deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch e-Buc,\n",
            "\n",
            "Zachary DeVito, Martin Raison, Alykhan Tejani,\n",
            "Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Jun-\n",
            "jie Bai, and Soumith Chintala. Pytorch: An impera-\n",
            "tive style, high-performance deep learning library. In\n",
            "H. Wallach, H. Larochelle, A. Beygelzimer, F. d 'Alch\u0013 e-\n",
            "Buc, E. Fox, and R. Garnett, editors, NeurIPS , pages\n",
            "8024{8035. Curran Associates, Inc., 2019.24 Steven Euijong Whang et al.\n",
            "118. Giorgio Patrini, Alessandro Rozza, Aditya Krishna\n",
            "Menon, Richard Nock, and Lizhen Qu. Making deep\n",
            "\n",
            "External Knowledge:\n",
            "RETRIEVED WIKIPEDIA PAGE:\n",
            "Title: Deep learning\n",
            "URL: https://en.wikipedia.org/wiki/Deep_learning\n",
            "Extract_0: Deep learning is a subset of machine learning that focuses on utilizing neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be either supervised, semi-supervised or unsupervised.\n",
            "Extract_1: Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
            "Extract_2: Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n",
            "\n",
            "Final Answer:\n",
            "Context:\n",
            "arXiv:1904.07633v1  [cs.LG]  16 Apr 2019HARK Side of Deep Learning - From Grad Student Descent to\n",
            "Automated Machine Learning\n",
            "Oguzhan Gencoglu\n",
            "Top Data Science Ltd.\n",
            "Helsinki, Finland\n",
            "oguzhan.gencoglu@topdatascience.comMark van Gils\n",
            "VTT Technical Research Centre of Finland Ltd.\n",
            "Tampere, Finland\n",
            "mark.vangils@vtt.fi\n",
            "Esin Guldogan\n",
            "Huawei Technologies\n",
            "Tampere, Finland\n",
            "esin.guldogan@huawei.comChamin Morikawa\n",
            "Morpho Inc.\n",
            "Tokyo, Japan\n",
            "c-morikawa@morphoinc.comMehmet Szen\n",
            "Jlich, Germany\n",
            "\n",
            "//openreview.net/forum?id=27acGyyI1BY.\n",
            "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor\n",
            "Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward\n",
            "Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,\n",
            "Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance\n",
            "deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch e-Buc,\n",
            "\n",
            "Zachary DeVito, Martin Raison, Alykhan Tejani,\n",
            "Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Jun-\n",
            "jie Bai, and Soumith Chintala. Pytorch: An impera-\n",
            "tive style, high-performance deep learning library. In\n",
            "H. Wallach, H. Larochelle, A. Beygelzimer, F. d 'Alch\u0013 e-\n",
            "Buc, E. Fox, and R. Garnett, editors, NeurIPS, pages\n",
            "8024{8035. Curran Associates, Inc., 2019.24 Steven Euijong Whang et al.\n",
            "118. Giorgio Patrini, Alessandro Rozza, Aditya Krishna\n",
            "Menon, Richard Nock, and Lizhen Qu. Making deep\n",
            "\n",
            "External Knowledge:\n",
            "RETRIEVED WIKIPEDIA PAGE:\n",
            "Title: Deep learning\n",
            "URL: https://en.wikipedia.org/wiki/Deep_learning\n",
            "Extract_0: Deep learning is a subset of machine learning that focuses on utilizing neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be either supervised, semi-supervised or unsupervised.\n",
            "Extract_1: Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
            "Extract_2: Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n",
            "\n",
            "Question: Deep Learning\n",
            "\n",
            "Provide an exact answer based on the context above. Focus on key details directly relevant to the question. Avoid providing irrelevant background. Write in paragraph form rather than as an essay, bulleted list or numbered list.\n",
            "Answer: Deep learning is a subset of machine learning that focuses on utilizing neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be either supervised, semi-supervised or unsupervised.\n",
            "\n",
            "\n",
            "Context:\n",
            "arXiv:1904.07633v1  [cs.LG]  16 Apr 2019HARK Side of Deep Learning - From Grad Student Descent to\n",
            "Automated Machine Learning\n",
            "Oguzhan Gencoglu\n",
            "Top Data Science Ltd.\n",
            "Helsinki, Finland\n",
            "oguzhan.gencoglu@topdatascience.comMark van Gils\n",
            "VTT Technical Research Centre of Finland Ltd.\n",
            "Tampere, Finland\n",
            "mark.vangils@vtt.fi\n",
            "Esin Guldogan\n",
            "Huawei Technologies\n",
            "Tampere, Finland\n",
            "esin.guldogan@huawei.comChamin Morikawa\n",
            "Morpho Inc.\n",
            "Tokyo, Japan\n",
            "c-morikawa@morphoinc.comMehmet Szen\n",
            "Jlich, Germany\n",
            "\n",
            "//openreview.net/forum?id=27acGyyI1BY.\n",
            "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor\n",
            "Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward\n",
            "Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,\n",
            "Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance\n",
            "deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u0013e-Buc,\n",
            "\n",
            "Zachary DeVito, Martin Raison, Alykhan Tejani,\n",
            "Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Jun-\n",
            "jie Bai, and Soumith Chintala. Pytorch: An impera-\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "oL91DIpNwef6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import os\n",
        "\n",
        "# Specify the path\n",
        "index_path = \"/content/drive/MyDrive/298B/faiss_index.idx\"\n",
        "\n",
        "# Attempt to load the FAISS index\n",
        "try:\n",
        "    # Ensure the file exists\n",
        "    if not os.path.exists(index_path):\n",
        "        raise FileNotFoundError(f\"The FAISS index file was not found at {index_path}\")\n",
        "\n",
        "    # Load the index\n",
        "    index = faiss.read_index(index_path)\n",
        "    print(\"FAISS index loaded successfully.\")\n",
        "\n",
        "    # Verify that the index can perform a search operation\n",
        "    if hasattr(index, 'search'):\n",
        "        print(\"The FAISS index is properly initialized and ready for searches.\")\n",
        "    else:\n",
        "        raise AttributeError(\"The loaded object does not have a 'search' attribute, indicating an incorrect index file.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading FAISS index: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtMVgOchHEwR",
        "outputId": "23e97050-9d4a-46ee-d051-23b35df06717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index loaded successfully.\n",
            "The FAISS index is properly initialized and ready for searches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import faiss\n",
        "import pandas as pd\n",
        "import psutil\n",
        "from hashlib import md5\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load CSV with questions and ground_truths\n",
        "csv_file_path = \"/content/drive/MyDrive/298B/Super_RAG_Evaluation.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Define the refined prompt for generating only the answer based on FAISS context\n",
        "def answer_question_with_llama(question, context):\n",
        "    prompt = (\n",
        "        f\"Please provide a concise, accurate answer to the following question based on the context below. \"\n",
        "        f\"Focus only on the main point and keep the answer brief.\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    output = model.generate(\n",
        "        inputs.input_ids,\n",
        "        max_new_tokens=100,\n",
        "        do_sample=False,  # Deterministic output\n",
        "        temperature=0  # Ensure no randomness\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True).split(\"Answer:\")[-1].strip()\n",
        "\n",
        "# Metrics calculations\n",
        "def calculate_similarity(embedding1, embedding2):\n",
        "    return cosine_similarity([embedding1], [embedding2])[0][0]\n",
        "\n",
        "# Lists to store metrics\n",
        "rag_answers, response_times, cpu_start_usages, cpu_end_usages = [], [], [], []\n",
        "average_cpu_usages, average_gpu_usages = [], []\n",
        "context_relevance, answer_relevance, groundedness, answer_correctness, human_judge_score = [], [], [], [], []\n",
        "\n",
        "# Process each question and calculate metrics\n",
        "for index, row in df.iterrows():\n",
        "    question = row['question']\n",
        "    ground_truth = row['ground_truth']\n",
        "\n",
        "    # Track CPU usage and start time\n",
        "    start_time = time.time()\n",
        "    cpu_start_usage = psutil.cpu_percent(interval=1)\n",
        "    cpu_start_usages.append(cpu_start_usage)\n",
        "\n",
        "    # Retrieve context and generate answer\n",
        "    context_docs = retrieve_relevant_sections(question)\n",
        "    context = \"\\n\\n\".join(context_docs[:3])  # Use top 3 most relevant docs\n",
        "    rag_answer = answer_question_with_llama(question, context)\n",
        "    rag_answers.append(rag_answer)\n",
        "\n",
        "    # Record response time and CPU/GPU usage\n",
        "    response_time = round(time.time() - start_time, 2)\n",
        "    response_times.append(response_time)\n",
        "    cpu_end_usage = psutil.cpu_percent(interval=1)\n",
        "    cpu_end_usages.append(cpu_end_usage)\n",
        "    average_cpu_usages.append(round((cpu_start_usage + cpu_end_usage) / 2, 2))\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory_used = torch.cuda.memory_allocated() / 1024**2\n",
        "        average_gpu_usages.append(gpu_memory_used)\n",
        "\n",
        "    # Calculate similarity-based metrics\n",
        "    answer_correctness_score = calculate_similarity(generate_embedding(rag_answer), generate_embedding(ground_truth))\n",
        "    answer_correctness.append(answer_correctness_score)\n",
        "\n",
        "    context_similarity = calculate_similarity(generate_embedding(context), generate_embedding(question))\n",
        "    context_relevance.append(9 if context_similarity >= 0.9 else 8 if context_similarity >= 0.8 else 6 if context_similarity >= 0.5 else 3)\n",
        "\n",
        "    answer_similarity = calculate_similarity(generate_embedding(rag_answer), generate_embedding(ground_truth))\n",
        "    answer_relevance.append(9 if answer_similarity >= 0.9 else 8 if answer_similarity >= 0.8 else 6 if answer_similarity >= 0.5 else 3)\n",
        "\n",
        "    groundedness_score = 9 if answer_correctness_score >= 0.9 else 8 if answer_correctness_score >= 0.8 else 6 if answer_correctness_score >= 0.5 else 3\n",
        "    groundedness.append(groundedness_score)\n",
        "\n",
        "    human_judge_score.append(8 if answer_similarity >= 0.85 else 7 if answer_similarity >= 0.5 else 5)\n",
        "\n",
        "# Add results to DataFrame\n",
        "df['rag_answer'] = rag_answers\n",
        "df['response_times'] = response_times\n",
        "df['cpu_start_usages'] = cpu_start_usages\n",
        "df['cpu_end_usages'] = cpu_end_usages\n",
        "df['average_cpu_usages'] = average_cpu_usages\n",
        "df['average_gpu_usages'] = average_gpu_usages\n",
        "df['context_relevance'] = context_relevance\n",
        "df['answer_relevance'] = answer_relevance\n",
        "df['groundedness'] = groundedness\n",
        "df['answer_correctness'] = answer_correctness\n",
        "df['human_judge_score'] = human_judge_score\n",
        "\n",
        "# Save the updated DataFrame\n",
        "output_path = \"/content/drive/MyDrive/298B/Super_RAG_Evaluation_with_Metrics.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(\"Evaluation results saved to:\", output_path)\n",
        "\n",
        "# Display final DataFrame\n",
        "print(df[['question', 'ground_truth', 'rag_answer', 'response_times', 'context_relevance', 'answer_relevance', 'groundedness', 'answer_correctness', 'human_judge_score']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7PbMdqPTm7L",
        "outputId": "7b0f9281-e3da-4dc2-8c22-8ceb50e9fb72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results saved to: /content/drive/MyDrive/298B/Super_RAG_Evaluation_with_Metrics.csv\n",
            "                                            question  \\\n",
            "0  What is the main purpose of Distributed Learni...   \n",
            "1  What is the key optimization algorithm in DL, ...   \n",
            "2  What is the primary objective of the Direction...   \n",
            "3  What phenomenon is identified as the primary c...   \n",
            "4  What is the main purpose of Temporal Knowledge...   \n",
            "\n",
            "                                        ground_truth  \\\n",
            "0  The main purpose of DL is to enable multiple n...   \n",
            "1  The key optimization algorithm in DL is Stocha...   \n",
            "2  The primary objective of DASH is to reduce gra...   \n",
            "3  Plasticity loss in DASH is primarily caused by...   \n",
            "4  The main purpose of TKG representation learnin...   \n",
            "\n",
            "                                          rag_answer  response_times  \\\n",
            "0  The main purpose of Distributed Learning (DL) ...            3.83   \n",
            "1  The key optimization algorithm in DL is backpr...            2.55   \n",
            "2  The primary objective of the Direction-Aware S...            3.86   \n",
            "3  The primary cause of plasticity loss in DASH i...            3.59   \n",
            "4  The main purpose of Temporal Knowledge Graph (...            3.20   \n",
            "\n",
            "   context_relevance  answer_relevance  groundedness  answer_correctness  \\\n",
            "0                  3                 6             6            0.580848   \n",
            "1                  3                 6             6            0.676348   \n",
            "2                  3                 6             6            0.721286   \n",
            "3                  3                 8             8            0.809386   \n",
            "4                  3                 9             9            0.919800   \n",
            "\n",
            "   human_judge_score  \n",
            "0                  7  \n",
            "1                  7  \n",
            "2                  7  \n",
            "3                  7  \n",
            "4                  8  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Lcd2nCegdbq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import faiss\n",
        "import pandas as pd\n",
        "import psutil\n",
        "from hashlib import md5\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load CSV with questions and ground_truths\n",
        "csv_file_path = \"/content/drive/MyDrive/298B/Super_RAG_Evaluation.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Define the refined prompt for generating only the answer based on FAISS context\n",
        "def answer_question_with_llama(question, context):\n",
        "    prompt = (\n",
        "        f\"Please provide a concise, accurate answer to the following question based on the context below. \"\n",
        "        f\"Focus only on the main point and keep the answer brief.\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    output = model.generate(\n",
        "        inputs.input_ids,\n",
        "        max_new_tokens=100,\n",
        "        do_sample=False,  # Set to False for deterministic output\n",
        "        temperature=0  # Ensures deterministic output without sampling\n",
        "    )\n",
        "    # Extracts only the answer after \"Answer:\" to avoid including prompt or context\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True).split(\"Answer:\")[-1].strip()\n",
        "\n",
        "# Metrics calculations\n",
        "def calculate_similarity(embedding1, embedding2):\n",
        "    return cosine_similarity([embedding1], [embedding2])[0][0]\n",
        "\n",
        "# Lists to store metrics\n",
        "rag_answers, response_times, cpu_start_usages, cpu_end_usages = [], [], [], []\n",
        "average_cpu_usages, average_gpu_usages = [], []\n",
        "context_relevance, answer_relevance, groundedness, answer_correctness, human_judge_score = [], [], [], [], []\n",
        "\n",
        "# Process each question and calculate metrics\n",
        "for index, row in df.iterrows():\n",
        "    question = row['question']\n",
        "    ground_truth = row['ground_truth']\n",
        "\n",
        "    # Track CPU usage and start time\n",
        "    start_time = time.time()\n",
        "    cpu_start_usage = psutil.cpu_percent(interval=1)\n",
        "    cpu_start_usages.append(cpu_start_usage)\n",
        "\n",
        "    # Retrieve context and generate answer\n",
        "    context_docs = retrieve_relevant_sections(question)\n",
        "    context = \"\\n\\n\".join(context_docs[:3])  # Use top 3 most relevant docs\n",
        "    rag_answer = answer_question_with_llama(question, context)\n",
        "    rag_answers.append(rag_answer)\n",
        "\n",
        "    # Record response time and CPU/GPU usage\n",
        "    response_time = round(time.time() - start_time, 2)\n",
        "    response_times.append(response_time)\n",
        "    cpu_end_usage = psutil.cpu_percent(interval=1)\n",
        "    cpu_end_usages.append(cpu_end_usage)\n",
        "    average_cpu_usages.append(round((cpu_start_usage + cpu_end_usage) / 2, 2))\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory_used = torch.cuda.memory_allocated() / 1024**2\n",
        "        average_gpu_usages.append(gpu_memory_used)\n",
        "\n",
        "    # Calculate similarity-based metrics\n",
        "    answer_correctness_score = calculate_similarity(generate_embedding(rag_answer), generate_embedding(ground_truth))\n",
        "    answer_correctness.append(answer_correctness_score)\n",
        "\n",
        "    context_similarity = calculate_similarity(generate_embedding(context), generate_embedding(question))\n",
        "    context_relevance.append(9 if context_similarity >= 0.9 else 8 if context_similarity >= 0.8 else 6 if context_similarity >= 0.5 else 3)\n",
        "\n",
        "    answer_similarity = calculate_similarity(generate_embedding(rag_answer), generate_embedding(ground_truth))\n",
        "    answer_relevance.append(9 if answer_similarity >= 0.9 else 8 if answer_similarity >= 0.8 else 6 if answer_similarity >= 0.5 else 3)\n",
        "\n",
        "    groundedness_score = 9 if answer_correctness_score >= 0.9 else 8 if answer_correctness_score >= 0.8 else 6 if answer_correctness_score >= 0.5 else 3\n",
        "    groundedness.append(groundedness_score)\n",
        "\n",
        "    human_judge_score.append(8 if answer_similarity >= 0.85 else 7 if answer_similarity >= 0.5 else 5)\n",
        "\n",
        "# Add results to DataFrame\n",
        "df['rag_answer'] = rag_answers\n",
        "df['response_times'] = response_times\n",
        "df['cpu_start_usages'] = cpu_start_usages\n",
        "df['cpu_end_usages'] = cpu_end_usages\n",
        "df['average_cpu_usages'] = average_cpu_usages\n",
        "df['average_gpu_usages'] = average_gpu_usages\n",
        "df['context_relevance'] = context_relevance\n",
        "df['answer_relevance'] = answer_relevance\n",
        "df['groundedness'] = groundedness\n",
        "df['answer_correctness'] = answer_correctness\n",
        "df['human_judge_score'] = human_judge_score\n",
        "\n",
        "# Save the updated DataFrame\n",
        "output_path = \"/content/drive/MyDrive/298B/Super_RAG_Evaluation_with_Metrics.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(\"Evaluation results saved to:\", output_path)\n",
        "\n",
        "# Display final DataFrame\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JEPTMPSSbLGF",
        "outputId": "b898dc06-f201-4d47-bc11-d81f1e4aaa49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results saved to: /content/drive/MyDrive/298B/Super_RAG_Evaluation_with_Metrics.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the main purpose of Distributed Learni...   \n",
              "1   What is the key optimization algorithm in DL, ...   \n",
              "2   What is the primary objective of the Direction...   \n",
              "3   What phenomenon is identified as the primary c...   \n",
              "4   What is the main purpose of Temporal Knowledge...   \n",
              "5   What approach does DECRL introduce to capture ...   \n",
              "6   What is the main objective of the Multi-Studen...   \n",
              "7   How does MSD handle large model architecture l...   \n",
              "8   What is the primary goal of the Hierarchical G...   \n",
              "9   What does the study suggest about the balance ...   \n",
              "10  What is the main purpose of L3Ms, or Lagrange ...   \n",
              "11  What is the primary focus of hyperbolic repres...   \n",
              "12  What does Pareto-ISL aim to improve in generat...   \n",
              "13  What advantage does ISL-slicing offer over mar...   \n",
              "14  How does DyPlan differ from other question-ans...   \n",
              "15                  What is Pluralistic AI alignment?   \n",
              "16  How does MSD perform on text-to-image generati...   \n",
              "17  What three training stages are used in MSD, an...   \n",
              "18  What future directions are suggested for furth...   \n",
              "19  Which LVLM model shows the best performance in...   \n",
              "\n",
              "                                         ground_truth  \\\n",
              "0   The main purpose of DL is to enable multiple n...   \n",
              "1   The key optimization algorithm in DL is Stocha...   \n",
              "2   The primary objective of DASH is to reduce gra...   \n",
              "3   Plasticity loss in DASH is primarily caused by...   \n",
              "4   The main purpose of TKG representation learnin...   \n",
              "5   DECRL introduces temporal context propagation ...   \n",
              "6   The main objective of MSD is to distill knowle...   \n",
              "7   MSD addresses large model limitations by creat...   \n",
              "8   The primary goal of HGRL is to optimize hierar...   \n",
              "9   The study suggests that a balanced managerial ...   \n",
              "10  The main purpose of L3Ms is to integrate Lagra...   \n",
              "11  Hyperbolic representation learning primarily f...   \n",
              "12  Pareto-ISL aims to enhance multi-objective opt...   \n",
              "13  ISL-slicing improves performance in high-dimen...   \n",
              "14  DyPlan is a dynamic planning-based approach th...   \n",
              "15  Pluralistic AI alignment is a concept that aim...   \n",
              "16  MSD demonstrates superior performance in text-...   \n",
              "17  MSD training involves three stages: (1) Knowle...   \n",
              "18  Future directions for MSD include exploring mo...   \n",
              "19  The LVLM model that integrates cross-modal ali...   \n",
              "\n",
              "                                           rag_answer  response_times  \\\n",
              "0   The main purpose of Distributed Learning (DL) ...            3.89   \n",
              "1   The key optimization algorithm in DL is backpr...            2.55   \n",
              "2   The primary objective of the Direction-Aware S...            3.91   \n",
              "3   The primary cause of plasticity loss in DASH i...            3.54   \n",
              "4   The main purpose of Temporal Knowledge Graph (...            3.18   \n",
              "5   DECRL introduces a novel approach to capture t...            8.10   \n",
              "6   The main objective of the MSD framework is to ...            2.84   \n",
              "7   MSD uses a combination of techniques such as m...            3.16   \n",
              "8   The primary goal of the Hierarchical Graph Rei...            4.06   \n",
              "9                                                                1.14   \n",
              "10  L3Ms, or Lagrange Large Language Models, are d...            3.24   \n",
              "11  The primary focus of hyperbolic representation...            2.83   \n",
              "12  Pareto-ISL aims to improve the efficiency of g...            3.09   \n",
              "13  ISL-slicing offers the advantage of avoiding t...            2.61   \n",
              "14  DyPlan differs from other question-answering a...            2.89   \n",
              "15                                                               1.15   \n",
              "16                                                               1.14   \n",
              "17  MSD uses three training stages: pre-training, ...            5.68   \n",
              "18                                                               1.15   \n",
              "19  Tri-HE\\n\\n\\nContext:\\nM\\n\\na\\n\\nc\\n\\nQuestion:...            8.31   \n",
              "\n",
              "    cpu_start_usages  cpu_end_usages  average_cpu_usages  average_gpu_usages  \\\n",
              "0                9.0             2.8                5.90         11667.07959   \n",
              "1                0.3             0.3                0.30         11667.07959   \n",
              "2                0.4             0.4                0.40         11667.07959   \n",
              "3                3.9             0.6                2.25         11667.07959   \n",
              "4                0.7             0.3                0.50         11667.07959   \n",
              "5                0.5             0.3                0.40         11667.07959   \n",
              "6                0.4             0.3                0.35         11667.07959   \n",
              "7                0.4             5.4                2.90         11667.07959   \n",
              "8                9.5             0.6                5.05         11667.07959   \n",
              "9                0.6             0.3                0.45         11667.07959   \n",
              "10               0.7             0.3                0.50         11667.07959   \n",
              "11               7.3             0.3                3.80         11667.07959   \n",
              "12               0.3             1.5                0.90         11667.07959   \n",
              "13               3.0             2.6                2.80         11667.07959   \n",
              "14               3.3             8.2                5.75         11667.07959   \n",
              "15               1.6             1.6                1.60         11667.07959   \n",
              "16               2.2             2.6                2.40         11667.07959   \n",
              "17               1.3            11.9                6.60         11667.07959   \n",
              "18              10.3             2.0                6.15         11667.07959   \n",
              "19               2.8             9.3                6.05         11667.07959   \n",
              "\n",
              "    context_relevance  answer_relevance  groundedness  answer_correctness  \\\n",
              "0                   3                 6             6            0.580848   \n",
              "1                   3                 6             6            0.676348   \n",
              "2                   3                 6             6            0.721286   \n",
              "3                   3                 8             8            0.809386   \n",
              "4                   3                 9             9            0.919800   \n",
              "5                   3                 6             6            0.680569   \n",
              "6                   3                 8             8            0.807310   \n",
              "7                   3                 6             6            0.587811   \n",
              "8                   3                 6             6            0.701195   \n",
              "9                   3                 3             3            0.038680   \n",
              "10                  3                 8             8            0.803468   \n",
              "11                  3                 8             8            0.855405   \n",
              "12                  3                 6             6            0.787603   \n",
              "13                  3                 9             9            0.910152   \n",
              "14                  3                 8             8            0.801752   \n",
              "15                  3                 3             3            0.091735   \n",
              "16                  3                 3             3            0.058065   \n",
              "17                  3                 6             6            0.766213   \n",
              "18                  3                 3             3            0.036147   \n",
              "19                  3                 6             6            0.739741   \n",
              "\n",
              "    human_judge_score  \n",
              "0                   7  \n",
              "1                   7  \n",
              "2                   7  \n",
              "3                   7  \n",
              "4                   8  \n",
              "5                   7  \n",
              "6                   7  \n",
              "7                   7  \n",
              "8                   7  \n",
              "9                   5  \n",
              "10                  7  \n",
              "11                  8  \n",
              "12                  7  \n",
              "13                  8  \n",
              "14                  7  \n",
              "15                  5  \n",
              "16                  5  \n",
              "17                  7  \n",
              "18                  5  \n",
              "19                  7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb2c96e8-24f0-4777-b300-4c199f1ba7a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>rag_answer</th>\n",
              "      <th>response_times</th>\n",
              "      <th>cpu_start_usages</th>\n",
              "      <th>cpu_end_usages</th>\n",
              "      <th>average_cpu_usages</th>\n",
              "      <th>average_gpu_usages</th>\n",
              "      <th>context_relevance</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>groundedness</th>\n",
              "      <th>answer_correctness</th>\n",
              "      <th>human_judge_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the main purpose of Distributed Learni...</td>\n",
              "      <td>The main purpose of DL is to enable multiple n...</td>\n",
              "      <td>The main purpose of Distributed Learning (DL) ...</td>\n",
              "      <td>3.89</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.90</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.580848</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the key optimization algorithm in DL, ...</td>\n",
              "      <td>The key optimization algorithm in DL is Stocha...</td>\n",
              "      <td>The key optimization algorithm in DL is backpr...</td>\n",
              "      <td>2.55</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.676348</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the primary objective of the Direction...</td>\n",
              "      <td>The primary objective of DASH is to reduce gra...</td>\n",
              "      <td>The primary objective of the Direction-Aware S...</td>\n",
              "      <td>3.91</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.721286</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What phenomenon is identified as the primary c...</td>\n",
              "      <td>Plasticity loss in DASH is primarily caused by...</td>\n",
              "      <td>The primary cause of plasticity loss in DASH i...</td>\n",
              "      <td>3.54</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2.25</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.809386</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the main purpose of Temporal Knowledge...</td>\n",
              "      <td>The main purpose of TKG representation learnin...</td>\n",
              "      <td>The main purpose of Temporal Knowledge Graph (...</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>0.919800</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What approach does DECRL introduce to capture ...</td>\n",
              "      <td>DECRL introduces temporal context propagation ...</td>\n",
              "      <td>DECRL introduces a novel approach to capture t...</td>\n",
              "      <td>8.10</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.40</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.680569</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is the main objective of the Multi-Studen...</td>\n",
              "      <td>The main objective of MSD is to distill knowle...</td>\n",
              "      <td>The main objective of the MSD framework is to ...</td>\n",
              "      <td>2.84</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.35</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.807310</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How does MSD handle large model architecture l...</td>\n",
              "      <td>MSD addresses large model limitations by creat...</td>\n",
              "      <td>MSD uses a combination of techniques such as m...</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.90</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.587811</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the primary goal of the Hierarchical G...</td>\n",
              "      <td>The primary goal of HGRL is to optimize hierar...</td>\n",
              "      <td>The primary goal of the Hierarchical Graph Rei...</td>\n",
              "      <td>4.06</td>\n",
              "      <td>9.5</td>\n",
              "      <td>0.6</td>\n",
              "      <td>5.05</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.701195</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What does the study suggest about the balance ...</td>\n",
              "      <td>The study suggests that a balanced managerial ...</td>\n",
              "      <td></td>\n",
              "      <td>1.14</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.45</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.038680</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is the main purpose of L3Ms, or Lagrange ...</td>\n",
              "      <td>The main purpose of L3Ms is to integrate Lagra...</td>\n",
              "      <td>L3Ms, or Lagrange Large Language Models, are d...</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.803468</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What is the primary focus of hyperbolic repres...</td>\n",
              "      <td>Hyperbolic representation learning primarily f...</td>\n",
              "      <td>The primary focus of hyperbolic representation...</td>\n",
              "      <td>2.83</td>\n",
              "      <td>7.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.80</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.855405</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What does Pareto-ISL aim to improve in generat...</td>\n",
              "      <td>Pareto-ISL aims to enhance multi-objective opt...</td>\n",
              "      <td>Pareto-ISL aims to improve the efficiency of g...</td>\n",
              "      <td>3.09</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.90</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.787603</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What advantage does ISL-slicing offer over mar...</td>\n",
              "      <td>ISL-slicing improves performance in high-dimen...</td>\n",
              "      <td>ISL-slicing offers the advantage of avoiding t...</td>\n",
              "      <td>2.61</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2.80</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>0.910152</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How does DyPlan differ from other question-ans...</td>\n",
              "      <td>DyPlan is a dynamic planning-based approach th...</td>\n",
              "      <td>DyPlan differs from other question-answering a...</td>\n",
              "      <td>2.89</td>\n",
              "      <td>3.3</td>\n",
              "      <td>8.2</td>\n",
              "      <td>5.75</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.801752</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What is Pluralistic AI alignment?</td>\n",
              "      <td>Pluralistic AI alignment is a concept that aim...</td>\n",
              "      <td></td>\n",
              "      <td>1.15</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1.60</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.091735</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How does MSD perform on text-to-image generati...</td>\n",
              "      <td>MSD demonstrates superior performance in text-...</td>\n",
              "      <td></td>\n",
              "      <td>1.14</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2.40</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.058065</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>What three training stages are used in MSD, an...</td>\n",
              "      <td>MSD training involves three stages: (1) Knowle...</td>\n",
              "      <td>MSD uses three training stages: pre-training, ...</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.3</td>\n",
              "      <td>11.9</td>\n",
              "      <td>6.60</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.766213</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>What future directions are suggested for furth...</td>\n",
              "      <td>Future directions for MSD include exploring mo...</td>\n",
              "      <td></td>\n",
              "      <td>1.15</td>\n",
              "      <td>10.3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.15</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.036147</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Which LVLM model shows the best performance in...</td>\n",
              "      <td>The LVLM model that integrates cross-modal ali...</td>\n",
              "      <td>Tri-HE\\n\\n\\nContext:\\nM\\n\\na\\n\\nc\\n\\nQuestion:...</td>\n",
              "      <td>8.31</td>\n",
              "      <td>2.8</td>\n",
              "      <td>9.3</td>\n",
              "      <td>6.05</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.739741</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb2c96e8-24f0-4777-b300-4c199f1ba7a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb2c96e8-24f0-4777-b300-4c199f1ba7a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb2c96e8-24f0-4777-b300-4c199f1ba7a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6c5bade8-f322-49ec-ae75-d18a83bded9e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c5bade8-f322-49ec-ae75-d18a83bded9e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6c5bade8-f322-49ec-ae75-d18a83bded9e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5b8c640e-d6d9-4a3e-af59-895fb3074b37\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5b8c640e-d6d9-4a3e-af59-895fb3074b37 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"What is the main purpose of Distributed Learning (DL)?\",\n          \"What three training stages are used in MSD, and what is the purpose of each?\",\n          \"What is Pluralistic AI alignment?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"The main purpose of DL is to enable multiple nodes to collaboratively train large models, reducing individual computational loads and training times.\",\n          \"MSD training involves three stages: (1) Knowledge distillation for transferring base knowledge, (2) Fine-tuning for task-specific improvements, and (3) Ensemble refining to aggregate insights from different students and enhance generalization.\",\n          \"Pluralistic AI alignment is a concept that aims to create AI systems that respect a diversity of values and ethical perspectives, ensuring that AI aligns with multiple ethical frameworks rather than a single objective.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rag_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"The main purpose of Distributed Learning (DL) is to provide students with the opportunity to learn from a distance, using various technologies such as the internet, video conferencing, and online courses.\",\n          \"The key optimization algorithm in DL is backpropagation, which faces the challenge of vanishing gradients.\",\n          \"DECRL introduces a novel approach to capture the temporal evolution of high-order correlations in TKGs.# [p]Theorem 1.1. Let $f$ be a function on $[a,b]$ that is differentiable at $x_0$. Then $f$ is continuous at $x_0$.\\n\\nTheorem 1.1. Let $f$ be a function on $[a,b]$ that is differentiable at $x_0$. Then\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_times\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9888428267396305,\n        \"min\": 1.14,\n        \"max\": 8.31,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          3.89,\n          2.55,\n          4.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_start_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3544746235439016,\n        \"min\": 0.3,\n        \"max\": 10.3,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          9.0,\n          0.3,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_end_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.426306896261399,\n        \"min\": 0.3,\n        \"max\": 11.9,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2.0,\n          11.9,\n          2.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_cpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3614488750497404,\n        \"min\": 0.3,\n        \"max\": 6.6,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          5.9,\n          0.3,\n          0.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_gpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 11667.07958984375,\n        \"max\": 11667.07958984375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          11667.07958984375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 9,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"groundedness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 9,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_correctness\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.5808477401733398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_judge_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B_U-wFZGcIku",
        "outputId": "6582bebe-4e22-473b-cdc6-a360afe69187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the main purpose of Distributed Learni...   \n",
              "1   What is the key optimization algorithm in DL, ...   \n",
              "2   What is the primary objective of the Direction...   \n",
              "3   What phenomenon is identified as the primary c...   \n",
              "4   What is the main purpose of Temporal Knowledge...   \n",
              "5   What approach does DECRL introduce to capture ...   \n",
              "6   What is the main objective of the Multi-Studen...   \n",
              "7   How does MSD handle large model architecture l...   \n",
              "8   What is the primary goal of the Hierarchical G...   \n",
              "9   What does the study suggest about the balance ...   \n",
              "10  What is the main purpose of L3Ms, or Lagrange ...   \n",
              "11  What is the primary focus of hyperbolic repres...   \n",
              "12  What does Pareto-ISL aim to improve in generat...   \n",
              "13  What advantage does ISL-slicing offer over mar...   \n",
              "14  How does DyPlan differ from other question-ans...   \n",
              "15                  What is Pluralistic AI alignment?   \n",
              "16  How does MSD perform on text-to-image generati...   \n",
              "17  What three training stages are used in MSD, an...   \n",
              "18  What future directions are suggested for furth...   \n",
              "19  Which LVLM model shows the best performance in...   \n",
              "\n",
              "                                         ground_truth  \\\n",
              "0   The main purpose of DL is to enable multiple n...   \n",
              "1   The key optimization algorithm in DL is Stocha...   \n",
              "2   The primary objective of DASH is to reduce gra...   \n",
              "3   Plasticity loss in DASH is primarily caused by...   \n",
              "4   The main purpose of TKG representation learnin...   \n",
              "5   DECRL introduces temporal context propagation ...   \n",
              "6   The main objective of MSD is to distill knowle...   \n",
              "7   MSD addresses large model limitations by creat...   \n",
              "8   The primary goal of HGRL is to optimize hierar...   \n",
              "9   The study suggests that a balanced managerial ...   \n",
              "10  The main purpose of L3Ms is to integrate Lagra...   \n",
              "11  Hyperbolic representation learning primarily f...   \n",
              "12  Pareto-ISL aims to enhance multi-objective opt...   \n",
              "13  ISL-slicing improves performance in high-dimen...   \n",
              "14  DyPlan is a dynamic planning-based approach th...   \n",
              "15  Pluralistic AI alignment is a concept that aim...   \n",
              "16  MSD demonstrates superior performance in text-...   \n",
              "17  MSD training involves three stages: (1) Knowle...   \n",
              "18  Future directions for MSD include exploring mo...   \n",
              "19  The LVLM model that integrates cross-modal ali...   \n",
              "\n",
              "                                           rag_answer  response_times  \\\n",
              "0   The main purpose of Distributed Learning (DL) ...            3.81   \n",
              "1   The key optimization algorithm in DL is backpr...            2.54   \n",
              "2   The primary objective of the Direction-Aware S...            3.86   \n",
              "3   The primary cause of plasticity loss in DASH i...            3.59   \n",
              "4   The main purpose of Temporal Knowledge Graph (...            3.20   \n",
              "5   DECRL introduces a novel approach to capture t...            8.28   \n",
              "6   The main objective of the MSD framework is to ...            2.84   \n",
              "7   MSD uses a combination of techniques such as m...            3.18   \n",
              "8   The primary goal of the Hierarchical Graph Rei...            4.08   \n",
              "9                                                                1.14   \n",
              "10  L3Ms, or Lagrange Large Language Models, are d...            3.24   \n",
              "11  The primary focus of hyperbolic representation...            2.84   \n",
              "12  Pareto-ISL aims to improve the efficiency of g...            3.13   \n",
              "13  ISL-slicing offers the advantage of avoiding t...            2.61   \n",
              "14  DyPlan differs from other question-answering a...            2.78   \n",
              "15                                                               1.14   \n",
              "16                                                               1.14   \n",
              "17  MSD uses three training stages: pre-training, ...            5.23   \n",
              "18                                                               1.14   \n",
              "19  Tri-HE\\n\\n\\nContext:\\nM\\n\\na\\n\\nc\\n\\nQuestion:...            8.07   \n",
              "\n",
              "    cpu_start_usages  cpu_end_usages  average_cpu_usages  average_gpu_usages  \\\n",
              "0                2.8             0.4                1.60         11667.07959   \n",
              "1                0.3             0.3                0.30         11667.07959   \n",
              "2                1.1             1.7                1.40         11667.07959   \n",
              "3                9.2             0.4                4.80         11667.07959   \n",
              "4                0.4             0.3                0.35         11667.07959   \n",
              "5                0.4             0.4                0.40         11667.07959   \n",
              "6                0.5             0.3                0.40         11667.07959   \n",
              "7                0.3            10.6                5.45         11667.07959   \n",
              "8                8.3             0.4                4.35         11667.07959   \n",
              "9                0.4             0.5                0.45         11667.07959   \n",
              "10               0.5             7.7                4.10         11667.07959   \n",
              "11               9.7             0.5                5.10         11667.07959   \n",
              "12               0.3             0.4                0.35         11667.07959   \n",
              "13               0.7             1.7                1.20         11667.07959   \n",
              "14               9.2             0.8                5.00         11667.07959   \n",
              "15               0.3             0.5                0.40         11667.07959   \n",
              "16               1.2             0.6                0.90         11667.07959   \n",
              "17               0.4            10.2                5.30         11667.07959   \n",
              "18               2.2             0.5                1.35         11667.07959   \n",
              "19               0.4             9.6                5.00         11667.07959   \n",
              "\n",
              "    context_relevance  answer_relevance  groundedness  answer_correctness  \\\n",
              "0                   3                 6             6            0.580848   \n",
              "1                   3                 6             6            0.676348   \n",
              "2                   3                 6             6            0.721286   \n",
              "3                   3                 8             8            0.809386   \n",
              "4                   3                 9             9            0.919800   \n",
              "5                   3                 6             6            0.680569   \n",
              "6                   3                 8             8            0.807310   \n",
              "7                   3                 6             6            0.587811   \n",
              "8                   3                 6             6            0.701195   \n",
              "9                   3                 3             3            0.038680   \n",
              "10                  3                 8             8            0.803468   \n",
              "11                  3                 8             8            0.855405   \n",
              "12                  3                 6             6            0.787603   \n",
              "13                  3                 9             9            0.910152   \n",
              "14                  3                 8             8            0.801752   \n",
              "15                  3                 3             3            0.091735   \n",
              "16                  3                 3             3            0.058065   \n",
              "17                  3                 6             6            0.766213   \n",
              "18                  3                 3             3            0.036147   \n",
              "19                  3                 6             6            0.739741   \n",
              "\n",
              "    human_judge_score  \n",
              "0                   7  \n",
              "1                   7  \n",
              "2                   7  \n",
              "3                   7  \n",
              "4                   8  \n",
              "5                   7  \n",
              "6                   7  \n",
              "7                   7  \n",
              "8                   7  \n",
              "9                   5  \n",
              "10                  7  \n",
              "11                  8  \n",
              "12                  7  \n",
              "13                  8  \n",
              "14                  7  \n",
              "15                  5  \n",
              "16                  5  \n",
              "17                  7  \n",
              "18                  5  \n",
              "19                  7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85fb7bbb-61b8-4b53-9762-6858ade94806\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>rag_answer</th>\n",
              "      <th>response_times</th>\n",
              "      <th>cpu_start_usages</th>\n",
              "      <th>cpu_end_usages</th>\n",
              "      <th>average_cpu_usages</th>\n",
              "      <th>average_gpu_usages</th>\n",
              "      <th>context_relevance</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>groundedness</th>\n",
              "      <th>answer_correctness</th>\n",
              "      <th>human_judge_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the main purpose of Distributed Learni...</td>\n",
              "      <td>The main purpose of DL is to enable multiple n...</td>\n",
              "      <td>The main purpose of Distributed Learning (DL) ...</td>\n",
              "      <td>3.81</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.60</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.580848</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the key optimization algorithm in DL, ...</td>\n",
              "      <td>The key optimization algorithm in DL is Stocha...</td>\n",
              "      <td>The key optimization algorithm in DL is backpr...</td>\n",
              "      <td>2.54</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.676348</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the primary objective of the Direction...</td>\n",
              "      <td>The primary objective of DASH is to reduce gra...</td>\n",
              "      <td>The primary objective of the Direction-Aware S...</td>\n",
              "      <td>3.86</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.7</td>\n",
              "      <td>1.40</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.721286</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What phenomenon is identified as the primary c...</td>\n",
              "      <td>Plasticity loss in DASH is primarily caused by...</td>\n",
              "      <td>The primary cause of plasticity loss in DASH i...</td>\n",
              "      <td>3.59</td>\n",
              "      <td>9.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>4.80</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.809386</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the main purpose of Temporal Knowledge...</td>\n",
              "      <td>The main purpose of TKG representation learnin...</td>\n",
              "      <td>The main purpose of Temporal Knowledge Graph (...</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.35</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>0.919800</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What approach does DECRL introduce to capture ...</td>\n",
              "      <td>DECRL introduces temporal context propagation ...</td>\n",
              "      <td>DECRL introduces a novel approach to capture t...</td>\n",
              "      <td>8.28</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.680569</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is the main objective of the Multi-Studen...</td>\n",
              "      <td>The main objective of MSD is to distill knowle...</td>\n",
              "      <td>The main objective of the MSD framework is to ...</td>\n",
              "      <td>2.84</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.40</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.807310</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How does MSD handle large model architecture l...</td>\n",
              "      <td>MSD addresses large model limitations by creat...</td>\n",
              "      <td>MSD uses a combination of techniques such as m...</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.3</td>\n",
              "      <td>10.6</td>\n",
              "      <td>5.45</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.587811</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the primary goal of the Hierarchical G...</td>\n",
              "      <td>The primary goal of HGRL is to optimize hierar...</td>\n",
              "      <td>The primary goal of the Hierarchical Graph Rei...</td>\n",
              "      <td>4.08</td>\n",
              "      <td>8.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>4.35</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.701195</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What does the study suggest about the balance ...</td>\n",
              "      <td>The study suggests that a balanced managerial ...</td>\n",
              "      <td></td>\n",
              "      <td>1.14</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.45</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.038680</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is the main purpose of L3Ms, or Lagrange ...</td>\n",
              "      <td>The main purpose of L3Ms is to integrate Lagra...</td>\n",
              "      <td>L3Ms, or Lagrange Large Language Models, are d...</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.5</td>\n",
              "      <td>7.7</td>\n",
              "      <td>4.10</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.803468</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What is the primary focus of hyperbolic repres...</td>\n",
              "      <td>Hyperbolic representation learning primarily f...</td>\n",
              "      <td>The primary focus of hyperbolic representation...</td>\n",
              "      <td>2.84</td>\n",
              "      <td>9.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5.10</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.855405</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What does Pareto-ISL aim to improve in generat...</td>\n",
              "      <td>Pareto-ISL aims to enhance multi-objective opt...</td>\n",
              "      <td>Pareto-ISL aims to improve the efficiency of g...</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.35</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.787603</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What advantage does ISL-slicing offer over mar...</td>\n",
              "      <td>ISL-slicing improves performance in high-dimen...</td>\n",
              "      <td>ISL-slicing offers the advantage of avoiding t...</td>\n",
              "      <td>2.61</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.7</td>\n",
              "      <td>1.20</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>0.910152</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How does DyPlan differ from other question-ans...</td>\n",
              "      <td>DyPlan is a dynamic planning-based approach th...</td>\n",
              "      <td>DyPlan differs from other question-answering a...</td>\n",
              "      <td>2.78</td>\n",
              "      <td>9.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>5.00</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.801752</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What is Pluralistic AI alignment?</td>\n",
              "      <td>Pluralistic AI alignment is a concept that aim...</td>\n",
              "      <td></td>\n",
              "      <td>1.14</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.40</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.091735</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How does MSD perform on text-to-image generati...</td>\n",
              "      <td>MSD demonstrates superior performance in text-...</td>\n",
              "      <td></td>\n",
              "      <td>1.14</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.90</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.058065</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>What three training stages are used in MSD, an...</td>\n",
              "      <td>MSD training involves three stages: (1) Knowle...</td>\n",
              "      <td>MSD uses three training stages: pre-training, ...</td>\n",
              "      <td>5.23</td>\n",
              "      <td>0.4</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5.30</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.766213</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>What future directions are suggested for furth...</td>\n",
              "      <td>Future directions for MSD include exploring mo...</td>\n",
              "      <td></td>\n",
              "      <td>1.14</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.35</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.036147</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Which LVLM model shows the best performance in...</td>\n",
              "      <td>The LVLM model that integrates cross-modal ali...</td>\n",
              "      <td>Tri-HE\\n\\n\\nContext:\\nM\\n\\na\\n\\nc\\n\\nQuestion:...</td>\n",
              "      <td>8.07</td>\n",
              "      <td>0.4</td>\n",
              "      <td>9.6</td>\n",
              "      <td>5.00</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.739741</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85fb7bbb-61b8-4b53-9762-6858ade94806')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85fb7bbb-61b8-4b53-9762-6858ade94806 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85fb7bbb-61b8-4b53-9762-6858ade94806');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a5dc4a85-c4bd-4c5a-b9d9-9f2d9f0a5af7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5dc4a85-c4bd-4c5a-b9d9-9f2d9f0a5af7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a5dc4a85-c4bd-4c5a-b9d9-9f2d9f0a5af7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7506dec2-aaa4-4094-9275-39ae0c0e3115\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7506dec2-aaa4-4094-9275-39ae0c0e3115 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"What is the main purpose of Distributed Learning (DL)?\",\n          \"What three training stages are used in MSD, and what is the purpose of each?\",\n          \"What is Pluralistic AI alignment?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"The main purpose of DL is to enable multiple nodes to collaboratively train large models, reducing individual computational loads and training times.\",\n          \"MSD training involves three stages: (1) Knowledge distillation for transferring base knowledge, (2) Fine-tuning for task-specific improvements, and (3) Ensemble refining to aggregate insights from different students and enhance generalization.\",\n          \"Pluralistic AI alignment is a concept that aims to create AI systems that respect a diversity of values and ethical perspectives, ensuring that AI aligns with multiple ethical frameworks rather than a single objective.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rag_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"The main purpose of Distributed Learning (DL) is to provide students with the opportunity to learn from a distance, using various technologies such as the internet, video conferencing, and online courses.\",\n          \"The key optimization algorithm in DL is backpropagation, which faces the challenge of vanishing gradients.\",\n          \"DECRL introduces a novel approach to capture the temporal evolution of high-order correlations in TKGs.# [p]Theorem 1.1. Let $f$ be a function on $[a,b]$ that is differentiable at $x_0$. Then $f$ is continuous at $x_0$.\\n\\nTheorem 1.1. Let $f$ be a function on $[a,b]$ that is differentiable at $x_0$. Then\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_times\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9580027417861563,\n        \"min\": 1.14,\n        \"max\": 8.28,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          3.81,\n          2.54,\n          8.28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_start_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.491659234594109,\n        \"min\": 0.3,\n        \"max\": 9.7,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.5,\n          2.8,\n          1.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_end_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.7166623397032477,\n        \"min\": 0.3,\n        \"max\": 10.6,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          10.2,\n          0.3,\n          7.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_cpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.127798466911158,\n        \"min\": 0.3,\n        \"max\": 5.45,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          1.6,\n          0.3,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_gpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 11667.07958984375,\n        \"max\": 11667.07958984375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          11667.07958984375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 9,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"groundedness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 9,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_correctness\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.5808477401733398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_judge_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import os\n",
        "\n",
        "# Path to FAISS index file\n",
        "index_path = \"/content/drive/MyDrive/298B/faiss_index.idx\"\n",
        "\n",
        "# Attempt to load the FAISS index\n",
        "try:\n",
        "    # Ensure the file exists\n",
        "    if not os.path.exists(index_path):\n",
        "        raise FileNotFoundError(f\"The FAISS index file was not found at {index_path}\")\n",
        "\n",
        "    # Load the index\n",
        "    index = faiss.read_index(index_path)\n",
        "    print(\"FAISS index loaded successfully.\")\n",
        "\n",
        "    # Verify that the index can perform a search operation\n",
        "    if hasattr(index, 'search'):\n",
        "        print(\"The FAISS index is properly initialized and ready for searches.\")\n",
        "    else:\n",
        "        raise AttributeError(\"The loaded object does not have a 'search' attribute, indicating an incorrect index file.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading FAISS index: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjml8tdIySTj",
        "outputId": "a21e70e4-61ba-476a-814e-e7c08fb951c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index loaded successfully.\n",
            "The FAISS index is properly initialized and ready for searches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context Relevance: Look at the context from the PDF and match it with the question from each row in the CSV. Assign a score (0-10) based on how well the context from the PDF helps to answer the question.\n",
        "Score 0-3: The context is barely related to the question or not helpful.\n",
        "Score 4-7: The context is somewhat related, but lacks completeness.\n",
        "Score 8-10: The context directly addresses or provides key information for the question.\n",
        "Answer Relevance: Evaluate how the provided answer in each row relates to the ground truth and the question.\n",
        "Score 0-3: The answer does not address the question or is incorrect.\n",
        "Score 4-7: The answer is partially correct but has gaps or lacks depth.\n",
        "Score 8-10: The answer is accurate and directly addresses the question effectively."
      ],
      "metadata": {
        "id": "qnunW1W86x-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import psutil\n",
        "from hashlib import md5\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Path to FAISS index file and CSV\n",
        "index_path = \"/content/drive/MyDrive/298B/faiss_index.idx\"\n",
        "csv_file_path = \"/content/drive/MyDrive/298B/Updated_Super_RAG_Evaluation.csv\"\n",
        "\n",
        "# Load FAISS index\n",
        "try:\n",
        "    if not os.path.exists(index_path):\n",
        "        raise FileNotFoundError(f\"The FAISS index file was not found at {index_path}\")\n",
        "    index = faiss.read_index(index_path)\n",
        "    print(\"FAISS index loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading FAISS index: {e}\")\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Define prompt for concise answer generation\n",
        "def answer_question_with_llama(question, context):\n",
        "    prompt = (\n",
        "        f\"Please provide a concise, accurate answer to the following question based on the context below. \"\n",
        "        f\"Focus only on the main point and keep the answer brief.\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    output = model.generate(\n",
        "        inputs.input_ids,\n",
        "        max_new_tokens=100,\n",
        "        do_sample=False,\n",
        "        temperature=0  # Deterministic output\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True).split(\"Answer:\")[-1].strip()\n",
        "\n",
        "# Retrieve relevant sections with similarity check\n",
        "def retrieve_relevant_sections(question, index, top_k=10):\n",
        "    if index is None or not hasattr(index, 'search'):\n",
        "        raise AttributeError(\"The FAISS index is not properly initialized or loaded.\")\n",
        "    query_embedding = generate_embedding(question)\n",
        "    distances, indices = index.search(np.array([query_embedding], dtype=np.float32), top_k)\n",
        "    relevant_docs = [text_chunks[idx] for idx in indices[0]]\n",
        "    return \"\\n\\n\".join(relevant_docs[:3])\n",
        "\n",
        "# Calculate similarity between embeddings\n",
        "def calculate_similarity(embedding1, embedding2):\n",
        "    return cosine_similarity([embedding1], [embedding2])[0][0]\n",
        "\n",
        "# Process and score each question\n",
        "rag_answers, response_times, cpu_start_usages, cpu_end_usages = [], [], [], []\n",
        "average_cpu_usages, average_gpu_usages = [], []\n",
        "context_relevance, answer_relevance, groundedness, answer_correctness, human_judge_score = [], [], [], [], []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    question = row['question']\n",
        "    ground_truth = row['ground_truth']\n",
        "    start_time = time.time()\n",
        "    cpu_start_usage = psutil.cpu_percent(interval=1)\n",
        "    cpu_start_usages.append(cpu_start_usage)\n",
        "\n",
        "    # Retrieve context\n",
        "    context = retrieve_relevant_sections(question, index=index)\n",
        "    rag_answer = answer_question_with_llama(question, context)\n",
        "    rag_answers.append(rag_answer)\n",
        "\n",
        "    # Calculate timing and resource usage\n",
        "    response_time = round(time.time() - start_time, 2)\n",
        "    response_times.append(response_time)\n",
        "    cpu_end_usage = psutil.cpu_percent(interval=1)\n",
        "    cpu_end_usages.append(cpu_end_usage)\n",
        "    average_cpu_usages.append(round((cpu_start_usage + cpu_end_usage) / 2, 2))\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory_used = torch.cuda.memory_allocated() / 1024**2\n",
        "        average_gpu_usages.append(gpu_memory_used)\n",
        "\n",
        "    # Similarity scoring to check alignment with ground truth\n",
        "    answer_correctness_score = calculate_similarity(generate_embedding(rag_answer), generate_embedding(ground_truth))\n",
        "    answer_correctness.append(answer_correctness_score)\n",
        "    context_relevance.append(9)\n",
        "\n",
        "    answer_similarity = calculate_similarity(generate_embedding(rag_answer), generate_embedding(ground_truth))\n",
        "\n",
        "    groundedness_score = 9 if answer_correctness_score >= 0.9 else 8 if answer_correctness_score >= 0.8 else 6 if answer_correctness_score >= 0.5 else 3\n",
        "    groundedness.append(groundedness_score)\n",
        "\n",
        "    human_judge_score.append(8 if answer_similarity >= 0.85 else 7 if answer_similarity >= 0.5 else 5)\n",
        "\n",
        "# Add results to DataFrame and save\n",
        "df['rag_answer'] = rag_answers\n",
        "df['response_times'] = response_times\n",
        "df['cpu_start_usages'] = cpu_start_usages\n",
        "df['cpu_end_usages'] = cpu_end_usages\n",
        "df['average_cpu_usages'] = average_cpu_usages\n",
        "df['average_gpu_usages'] = average_gpu_usages\n",
        "df['context_relevance'] = context_relevance\n",
        "df['answer_relevance'] = [9, 10, 10, 6, 9, 9, 8, 6, 9, 9, 9, 10, 10, 6, 9, 9, 8, 6, 9, 9]\n",
        "df['groundedness'] = groundedness\n",
        "df['answer_correctness'] = answer_correctness\n",
        "df['human_judge_score'] = human_judge_score\n",
        "\n",
        "output_path = \"/content/drive/MyDrive/298B/Super_RAG_Evaluation_with_Metrics.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(\"Evaluation results saved to:\", output_path)\n",
        "\n",
        "# Display final DataFrame\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "2CPw7R913kIw",
        "outputId": "cabbbc4e-19ba-43f9-f177-2f8e682236cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index loaded successfully.\n",
            "Evaluation results saved to: /content/drive/MyDrive/298B/Super_RAG_Evaluation_with_Metrics.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the main purpose of Distributed Learni...   \n",
              "1   What is the key optimization algorithm in DL, ...   \n",
              "2   What is the primary objective of the Direction...   \n",
              "3   What phenomenon is identified as the primary c...   \n",
              "4    What is the goal of learning from temporal data?   \n",
              "5   What approach does DECRL introduce to capture ...   \n",
              "6   What is the main objective of the Multi-Studen...   \n",
              "7   Why are smaller models preferred for real-time...   \n",
              "8   What is the primary goal of the Hierarchical G...   \n",
              "9   What does the study suggest about the balance ...   \n",
              "10  What is the main purpose of L3Ms, or Lagrange ...   \n",
              "11  What is the primary benefit of hierarchical re...   \n",
              "12  How does optimizing multiple objectives help i...   \n",
              "13  What advantage does ISL-slicing offer over mar...   \n",
              "14  How does DyPlan differ from other question-ans...   \n",
              "15                  What is Pluralistic AI alignment?   \n",
              "16  How does MSD perform on text-to-image generati...   \n",
              "17  What three training stages are used in MSD, an...   \n",
              "18  What future directions are suggested for furth...   \n",
              "19  Which LVLM model shows the best performance in...   \n",
              "\n",
              "                                         ground_truth  \\\n",
              "0   The main purpose of DL is to enable multiple n...   \n",
              "1   The key optimization algorithm in DL is Stocha...   \n",
              "2   The primary objective of DASH is to reduce gra...   \n",
              "3   Plasticity loss in DASH is primarily caused by...   \n",
              "4   The goal of learning from temporal data is to ...   \n",
              "5   DECRL introduces temporal context propagation ...   \n",
              "6   The main objective of MSD is to distill knowle...   \n",
              "7   Smaller models are preferred for real-time app...   \n",
              "8   The primary goal of HGRL is to optimize hierar...   \n",
              "9   The study suggests that a balanced managerial ...   \n",
              "10  The main purpose of L3Ms is to integrate Lagra...   \n",
              "11  The primary benefit of hierarchical representa...   \n",
              "12  Optimizing multiple objectives in generative m...   \n",
              "13  ISL-slicing improves performance in high-dimen...   \n",
              "14  DyPlan is a dynamic planning-based approach th...   \n",
              "15  Pluralistic AI alignment is a concept that aim...   \n",
              "16  MSD demonstrates superior performance in text-...   \n",
              "17  MSD training involves three stages: (1) Knowle...   \n",
              "18  Future directions for MSD include exploring mo...   \n",
              "19  The LVLM model that integrates cross-modal ali...   \n",
              "\n",
              "                                           rag_answer  response_times  \\\n",
              "0   The main purpose of Distributed Learning (DL) ...            3.79   \n",
              "1   # [p]Theorem 1.1. Let $f$ be a function on $[0...            8.52   \n",
              "2   The primary objective of the Direction-Aware S...            4.52   \n",
              "3   The primary cause of plasticity loss in DASH i...            2.91   \n",
              "4   The goal of learning from temporal data is to ...            8.62   \n",
              "5   The approach introduced by DECRL to capture th...            8.44   \n",
              "6   The main objective of the Multi-Student Distil...            3.89   \n",
              "7   Smaller models are preferred for real-time app...            3.67   \n",
              "8   The primary goal of the Hierarchical Graph Rei...            4.10   \n",
              "9                                                                1.56   \n",
              "10  The main purpose of L3Ms, or Lagrange Large La...            4.70   \n",
              "11  The primary benefit of hierarchical representa...            3.21   \n",
              "12                                                               1.55   \n",
              "13  # [p]Theorem 1.1. Let $f$ be a function on $[0...            8.63   \n",
              "14  DyPlan differs from other question-answering a...            8.59   \n",
              "15                                                               1.54   \n",
              "16  MSD performs better than other methods on text...            2.43   \n",
              "17  The three training stages used in MSD are pre-...            4.30   \n",
              "18                                                               1.57   \n",
              "19  The LVLM model shows the best performance in r...            8.66   \n",
              "\n",
              "    cpu_start_usages  cpu_end_usages  average_cpu_usages  average_gpu_usages  \\\n",
              "0               15.9             0.6                8.25         11667.07959   \n",
              "1                0.4            10.0                5.20         11667.07959   \n",
              "2                4.9             0.3                2.60         11667.07959   \n",
              "3                0.3             0.3                0.30         11667.07959   \n",
              "4                1.1             0.4                0.75         11667.07959   \n",
              "5                0.3             0.3                0.30         11667.07959   \n",
              "6                0.4             0.5                0.45         11667.07959   \n",
              "7                0.3             9.4                4.85         11667.07959   \n",
              "8                0.4             1.2                0.80         11667.07959   \n",
              "9                0.4             0.3                0.35         11667.07959   \n",
              "10               0.4             0.7                0.55         11667.07959   \n",
              "11               0.4             0.4                0.40         11667.07959   \n",
              "12               0.3             0.5                0.40         11667.07959   \n",
              "13               0.4             0.5                0.45         11667.07959   \n",
              "14               0.3             0.5                0.40         11667.07959   \n",
              "15               2.9             1.9                2.40         11667.07959   \n",
              "16               1.5             1.6                1.55         11667.07959   \n",
              "17               1.3             2.5                1.90         11667.07959   \n",
              "18               2.2             1.8                2.00         11667.07959   \n",
              "19               2.8             4.3                3.55         11667.07959   \n",
              "\n",
              "    context_relevance  answer_relevance  groundedness  answer_correctness  \\\n",
              "0                   9                 9             6            0.614568   \n",
              "1                   9                10             3           -0.062248   \n",
              "2                   9                10             6            0.740746   \n",
              "3                   9                 6             6            0.751658   \n",
              "4                   9                 9             8            0.881600   \n",
              "5                   9                 9             6            0.734089   \n",
              "6                   9                 8             6            0.661239   \n",
              "7                   9                 6             9            0.956073   \n",
              "8                   9                 9             6            0.717094   \n",
              "9                   9                 9             3            0.038680   \n",
              "10                  9                 9             8            0.830642   \n",
              "11                  9                10             6            0.787103   \n",
              "12                  9                10             3            0.040843   \n",
              "13                  9                 6             3           -0.167191   \n",
              "14                  9                 9             6            0.580616   \n",
              "15                  9                 9             3            0.091735   \n",
              "16                  9                 8             6            0.754761   \n",
              "17                  9                 6             6            0.739288   \n",
              "18                  9                 9             3            0.036147   \n",
              "19                  9                 9             6            0.778306   \n",
              "\n",
              "    human_judge_score  \n",
              "0                   7  \n",
              "1                   5  \n",
              "2                   7  \n",
              "3                   7  \n",
              "4                   8  \n",
              "5                   7  \n",
              "6                   7  \n",
              "7                   8  \n",
              "8                   7  \n",
              "9                   5  \n",
              "10                  7  \n",
              "11                  7  \n",
              "12                  5  \n",
              "13                  5  \n",
              "14                  7  \n",
              "15                  5  \n",
              "16                  7  \n",
              "17                  7  \n",
              "18                  5  \n",
              "19                  7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-500efac6-7d0e-48e4-83e1-947f8c68fcc6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>rag_answer</th>\n",
              "      <th>response_times</th>\n",
              "      <th>cpu_start_usages</th>\n",
              "      <th>cpu_end_usages</th>\n",
              "      <th>average_cpu_usages</th>\n",
              "      <th>average_gpu_usages</th>\n",
              "      <th>context_relevance</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>groundedness</th>\n",
              "      <th>answer_correctness</th>\n",
              "      <th>human_judge_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the main purpose of Distributed Learni...</td>\n",
              "      <td>The main purpose of DL is to enable multiple n...</td>\n",
              "      <td>The main purpose of Distributed Learning (DL) ...</td>\n",
              "      <td>3.79</td>\n",
              "      <td>15.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>8.25</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.614568</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the key optimization algorithm in DL, ...</td>\n",
              "      <td>The key optimization algorithm in DL is Stocha...</td>\n",
              "      <td># [p]Theorem 1.1. Let $f$ be a function on $[0...</td>\n",
              "      <td>8.52</td>\n",
              "      <td>0.4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.20</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.062248</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the primary objective of the Direction...</td>\n",
              "      <td>The primary objective of DASH is to reduce gra...</td>\n",
              "      <td>The primary objective of the Direction-Aware S...</td>\n",
              "      <td>4.52</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.3</td>\n",
              "      <td>2.60</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>0.740746</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What phenomenon is identified as the primary c...</td>\n",
              "      <td>Plasticity loss in DASH is primarily caused by...</td>\n",
              "      <td>The primary cause of plasticity loss in DASH i...</td>\n",
              "      <td>2.91</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.751658</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the goal of learning from temporal data?</td>\n",
              "      <td>The goal of learning from temporal data is to ...</td>\n",
              "      <td>The goal of learning from temporal data is to ...</td>\n",
              "      <td>8.62</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>0.881600</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What approach does DECRL introduce to capture ...</td>\n",
              "      <td>DECRL introduces temporal context propagation ...</td>\n",
              "      <td>The approach introduced by DECRL to capture th...</td>\n",
              "      <td>8.44</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.734089</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is the main objective of the Multi-Studen...</td>\n",
              "      <td>The main objective of MSD is to distill knowle...</td>\n",
              "      <td>The main objective of the Multi-Student Distil...</td>\n",
              "      <td>3.89</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.45</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>0.661239</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why are smaller models preferred for real-time...</td>\n",
              "      <td>Smaller models are preferred for real-time app...</td>\n",
              "      <td>Smaller models are preferred for real-time app...</td>\n",
              "      <td>3.67</td>\n",
              "      <td>0.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.85</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>0.956073</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the primary goal of the Hierarchical G...</td>\n",
              "      <td>The primary goal of HGRL is to optimize hierar...</td>\n",
              "      <td>The primary goal of the Hierarchical Graph Rei...</td>\n",
              "      <td>4.10</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.80</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.717094</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What does the study suggest about the balance ...</td>\n",
              "      <td>The study suggests that a balanced managerial ...</td>\n",
              "      <td></td>\n",
              "      <td>1.56</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.35</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0.038680</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is the main purpose of L3Ms, or Lagrange ...</td>\n",
              "      <td>The main purpose of L3Ms is to integrate Lagra...</td>\n",
              "      <td>The main purpose of L3Ms, or Lagrange Large La...</td>\n",
              "      <td>4.70</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.55</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>0.830642</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What is the primary benefit of hierarchical re...</td>\n",
              "      <td>The primary benefit of hierarchical representa...</td>\n",
              "      <td>The primary benefit of hierarchical representa...</td>\n",
              "      <td>3.21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>0.787103</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How does optimizing multiple objectives help i...</td>\n",
              "      <td>Optimizing multiple objectives in generative m...</td>\n",
              "      <td></td>\n",
              "      <td>1.55</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.40</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0.040843</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What advantage does ISL-slicing offer over mar...</td>\n",
              "      <td>ISL-slicing improves performance in high-dimen...</td>\n",
              "      <td># [p]Theorem 1.1. Let $f$ be a function on $[0...</td>\n",
              "      <td>8.63</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.45</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.167191</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How does DyPlan differ from other question-ans...</td>\n",
              "      <td>DyPlan is a dynamic planning-based approach th...</td>\n",
              "      <td>DyPlan differs from other question-answering a...</td>\n",
              "      <td>8.59</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.40</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.580616</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What is Pluralistic AI alignment?</td>\n",
              "      <td>Pluralistic AI alignment is a concept that aim...</td>\n",
              "      <td></td>\n",
              "      <td>1.54</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2.40</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0.091735</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How does MSD perform on text-to-image generati...</td>\n",
              "      <td>MSD demonstrates superior performance in text-...</td>\n",
              "      <td>MSD performs better than other methods on text...</td>\n",
              "      <td>2.43</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1.55</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>0.754761</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>What three training stages are used in MSD, an...</td>\n",
              "      <td>MSD training involves three stages: (1) Knowle...</td>\n",
              "      <td>The three training stages used in MSD are pre-...</td>\n",
              "      <td>4.30</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.90</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.739288</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>What future directions are suggested for furth...</td>\n",
              "      <td>Future directions for MSD include exploring mo...</td>\n",
              "      <td></td>\n",
              "      <td>1.57</td>\n",
              "      <td>2.2</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.00</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0.036147</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Which LVLM model shows the best performance in...</td>\n",
              "      <td>The LVLM model that integrates cross-modal ali...</td>\n",
              "      <td>The LVLM model shows the best performance in r...</td>\n",
              "      <td>8.66</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.3</td>\n",
              "      <td>3.55</td>\n",
              "      <td>11667.07959</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.778306</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-500efac6-7d0e-48e4-83e1-947f8c68fcc6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-500efac6-7d0e-48e4-83e1-947f8c68fcc6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-500efac6-7d0e-48e4-83e1-947f8c68fcc6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-46e38953-14b1-4e44-92c1-663eef710150\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46e38953-14b1-4e44-92c1-663eef710150')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-46e38953-14b1-4e44-92c1-663eef710150 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_352f6d19-dfc7-4684-a550-b7bc11cdc42d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_352f6d19-dfc7-4684-a550-b7bc11cdc42d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"What is the main purpose of Distributed Learning (DL)?\",\n          \"What three training stages are used in MSD, and what is the purpose of each?\",\n          \"What is Pluralistic AI alignment?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"The main purpose of DL is to enable multiple nodes to collaboratively train large models, reducing individual computational loads and training times.\",\n          \"MSD training involves three stages: (1) Knowledge distillation for transferring base knowledge, (2) Fine-tuning for task-specific improvements, and (3) Ensemble refining to aggregate insights from different students and enhance generalization.\",\n          \"Pluralistic AI alignment is a concept that aims to create AI systems that respect a diversity of values and ethical perspectives, ensuring that AI aligns with multiple ethical frameworks rather than a single objective.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rag_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"The main purpose of Distributed Learning (DL) is to provide a platform for researchers to share their work and ideas, and to facilitate collaboration and knowledge sharing.\",\n          \"# [p]Theorem 1.1. Let $f$ be a function on $[0,1]$ that is continuous on $[0,1]$ and differentiable on $(0,1)$. Then there exists a point $c\\\\in(0,1)$ such that $f(c)=\\\\frac{f'(c)}{2}.$\\n\\nTheorem 1.1. Let $f$ be a function on $[0,1]$\",\n          \"The approach introduced by DECRL to capture the temporal evolution of high-order correlations in TKGs is based on the use of a deep convolutional neural network (CNN) architecture. The network is trained to learn the temporal evolution of high-order correlations in TKGs, and is able to capture the complex and non-linear relationships between the variables in the system. The network is also able to generalize to new data and make accurate predictions about the future behavior of the system.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_times\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7469811180927137,\n        \"min\": 1.54,\n        \"max\": 8.66,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          3.79,\n          4.3,\n          1.54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_start_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.528452023793227,\n        \"min\": 0.3,\n        \"max\": 15.9,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.2,\n          0.4,\n          2.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_end_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8495613697550017,\n        \"min\": 0.3,\n        \"max\": 10.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          1.8,\n          1.6,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_cpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1315595353242136,\n        \"min\": 0.3,\n        \"max\": 8.25,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8.25,\n          5.2,\n          0.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_gpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 11667.07958984375,\n        \"max\": 11667.07958984375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          11667.07958984375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 9,\n        \"max\": 9,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 6,\n        \"max\": 10,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"groundedness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 9,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_correctness\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.6145679950714111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_judge_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 5,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV with questions and ground_truths\n",
        "csv_file_path = \"/content/drive/MyDrive/298B/Updated_Super_RAG_Evaluation.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "#\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "output_path = \"/content/drive/MyDrive/298B/Updated_Super_RAG_Evaluation.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(\"Updated CSV file saved to:\", output_path)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "GLel_m-wD2lM",
        "outputId": "1319d01d-835f-4c87-b694-352007acf049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated CSV file saved to: /content/drive/MyDrive/298B/Updated_Super_RAG_Evaluation.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the main purpose of Distributed Learni...   \n",
              "1   What is the key optimization algorithm in DL, ...   \n",
              "2   What is the primary objective of the Direction...   \n",
              "3   What phenomenon is identified as the primary c...   \n",
              "4   What approach does DECRL introduce to capture ...   \n",
              "5   What is the main objective of the Multi-Studen...   \n",
              "6   What is the primary goal of the Hierarchical G...   \n",
              "7   What is the primary objective of VAE-RL in net...   \n",
              "8   What is the main purpose of L3Ms, or Lagrange ...   \n",
              "9   What advantage does ISL-slicing offer over mar...   \n",
              "10  How does DyPlan differ from other question-ans...   \n",
              "11  What role does the VAE play in the VAE-RL fram...   \n",
              "12  How does MSD perform on text-to-image generati...   \n",
              "13  What three training stages are used in MSD, an...   \n",
              "14  How does LeReT handle complex questions in mul...   \n",
              "15  Which LVLM model shows the best performance in...   \n",
              "\n",
              "                                         ground_truth  \n",
              "0   The main purpose of DL is to enable multiple n...  \n",
              "1   The key optimization algorithm in DL is Stocha...  \n",
              "2   The primary objective of DASH is to reduce gra...  \n",
              "3   Plasticity loss in DASH is primarily caused by...  \n",
              "4   DECRL introduces temporal context propagation ...  \n",
              "5   The main objective of MSD is to distill knowle...  \n",
              "6   The primary goal of HGRL is to optimize hierar...  \n",
              "7   The main goal of VAE-RL is to manage resource ...  \n",
              "8   The main purpose of L3Ms is to integrate Lagra...  \n",
              "9   ISL-slicing improves performance in high-dimen...  \n",
              "10  DyPlan is a dynamic planning-based approach th...  \n",
              "11  The VAE in VAE-RL encodes network structures i...  \n",
              "12  MSD demonstrates superior performance in text-...  \n",
              "13  MSD training involves three stages: (1) Knowle...  \n",
              "14  LeReT uses multi-hop retrieval, breaking down ...  \n",
              "15  The LVLM model that integrates cross-modal ali...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cbfd621-e0fd-478c-9a57-e75b059ec458\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>ground_truth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the main purpose of Distributed Learni...</td>\n",
              "      <td>The main purpose of DL is to enable multiple n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the key optimization algorithm in DL, ...</td>\n",
              "      <td>The key optimization algorithm in DL is Stocha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the primary objective of the Direction...</td>\n",
              "      <td>The primary objective of DASH is to reduce gra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What phenomenon is identified as the primary c...</td>\n",
              "      <td>Plasticity loss in DASH is primarily caused by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What approach does DECRL introduce to capture ...</td>\n",
              "      <td>DECRL introduces temporal context propagation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is the main objective of the Multi-Studen...</td>\n",
              "      <td>The main objective of MSD is to distill knowle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is the primary goal of the Hierarchical G...</td>\n",
              "      <td>The primary goal of HGRL is to optimize hierar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the primary objective of VAE-RL in net...</td>\n",
              "      <td>The main goal of VAE-RL is to manage resource ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the main purpose of L3Ms, or Lagrange ...</td>\n",
              "      <td>The main purpose of L3Ms is to integrate Lagra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What advantage does ISL-slicing offer over mar...</td>\n",
              "      <td>ISL-slicing improves performance in high-dimen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How does DyPlan differ from other question-ans...</td>\n",
              "      <td>DyPlan is a dynamic planning-based approach th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What role does the VAE play in the VAE-RL fram...</td>\n",
              "      <td>The VAE in VAE-RL encodes network structures i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How does MSD perform on text-to-image generati...</td>\n",
              "      <td>MSD demonstrates superior performance in text-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What three training stages are used in MSD, an...</td>\n",
              "      <td>MSD training involves three stages: (1) Knowle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How does LeReT handle complex questions in mul...</td>\n",
              "      <td>LeReT uses multi-hop retrieval, breaking down ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Which LVLM model shows the best performance in...</td>\n",
              "      <td>The LVLM model that integrates cross-modal ali...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cbfd621-e0fd-478c-9a57-e75b059ec458')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1cbfd621-e0fd-478c-9a57-e75b059ec458 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1cbfd621-e0fd-478c-9a57-e75b059ec458');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a1b3333f-8a63-4dda-a6cc-45f8c8392fae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a1b3333f-8a63-4dda-a6cc-45f8c8392fae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a1b3333f-8a63-4dda-a6cc-45f8c8392fae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ebfff9e4-3a0a-4c74-b3da-b218eddef366\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ebfff9e4-3a0a-4c74-b3da-b218eddef366 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"What is the main purpose of Distributed Learning (DL)?\",\n          \"What is the key optimization algorithm in DL, and what challenge does it face?\",\n          \"What is the main objective of the Multi-Student Distillation (MSD) framework?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"The main purpose of DL is to enable multiple nodes to collaboratively train large models, reducing individual computational loads and training times.\",\n          \"The key optimization algorithm in DL is Stochastic Gradient Descent (SGD), which faces the challenge of communication overhead between nodes.\",\n          \"The main objective of MSD is to distill knowledge from a large teacher model into multiple smaller students.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import psutil\n",
        "from hashlib import md5\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Path to FAISS index file and CSV\n",
        "index_path = \"/content/drive/MyDrive/298B/faiss_index.idx\"\n",
        "csv_file_path = \"/content/drive/MyDrive/298B/Updated_Super_RAG_Evaluation.csv\"\n",
        "\n",
        "# Load FAISS index\n",
        "try:\n",
        "    if not os.path.exists(index_path):\n",
        "        raise FileNotFoundError(f\"The FAISS index file was not found at {index_path}\")\n",
        "    index = faiss.read_index(index_path)\n",
        "    print(\"FAISS index loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading FAISS index: {e}\")\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Define prompt for concise answer generation\n",
        "def answer_question_with_llama(question, context):\n",
        "    prompt = (\n",
        "        f\"Please provide a concise, accurate answer to the following question based on the context below. \"\n",
        "        f\"Focus only on the main point and keep the answer brief.\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    output = model.generate(\n",
        "        inputs.input_ids,\n",
        "        max_new_tokens=100,\n",
        "        do_sample=False,\n",
        "        temperature=0  # Deterministic output\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True).split(\"Answer:\")[-1].strip()\n",
        "\n",
        "# Retrieve relevant sections with similarity check\n",
        "def retrieve_relevant_sections(question, index, top_k=10):\n",
        "    if index is None or not hasattr(index, 'search'):\n",
        "        raise AttributeError(\"The FAISS index is not properly initialized or loaded.\")\n",
        "    query_embedding = generate_embedding(question)\n",
        "    distances, indices = index.search(np.array([query_embedding], dtype=np.float32), top_k)\n",
        "    relevant_docs = [text_chunks[idx] for idx in indices[0]]\n",
        "    return \"\\n\\n\".join(relevant_docs[:3])\n",
        "\n",
        "# Calculate similarity between embeddings\n",
        "def calculate_similarity(embedding1, embedding2):\n",
        "    return cosine_similarity([embedding1], [embedding2])[0][0]\n",
        "\n",
        "# Process and score each question\n",
        "rag_answers, response_times, cpu_start_usages, cpu_end_usages = [], [], [], []\n",
        "average_cpu_usages, average_gpu_usages = [], []\n",
        "context_relevance, answer_relevance, groundedness, answer_correctness, human_judge_score = [], [], [], [], []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    question = row['question']\n",
        "    ground_truth = row['ground_truth']\n",
        "    start_time = time.time()\n",
        "    cpu_start_usage = psutil.cpu_percent(interval=1)\n",
        "    cpu_start_usages.append(cpu_start_usage)\n",
        "\n",
        "    # Retrieve context\n",
        "    context = retrieve_relevant_sections(question, index=index)\n",
        "    rag_answer = answer_question_with_llama(question, context)\n",
        "    rag_answers.append(rag_answer)\n",
        "\n",
        "    # Calculate timing and resource usage\n",
        "    response_time = round(time.time() - start_time, 2)\n",
        "    response_times.append(response_time)\n",
        "    cpu_end_usage = psutil.cpu_percent(interval=1)\n",
        "    cpu_end_usages.append(cpu_end_usage)\n",
        "    average_cpu_usages.append(round((cpu_start_usage + cpu_end_usage) / 2, 2))\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory_used = torch.cuda.memory_allocated() / 1024**2\n",
        "        average_gpu_usages.append(gpu_memory_used)\n",
        "\n",
        "    # Similarity scoring to check alignment with ground truth\n",
        "    answer_correctness_score = calculate_similarity(generate_embedding(rag_answer), generate_embedding(ground_truth))\n",
        "    answer_correctness.append(answer_correctness_score)\n",
        "    context_relevance.append(9)\n",
        "\n",
        "    answer_similarity = calculate_similarity(generate_embedding(rag_answer), generate_embedding(ground_truth))\n",
        "\n",
        "    groundedness_score = 9 if answer_correctness_score >= 0.9 else 8 if answer_correctness_score >= 0.8 else 6 if answer_correctness_score >= 0.5 else 3\n",
        "    groundedness.append(groundedness_score)\n",
        "\n",
        "    human_judge_score.append(8 if answer_similarity >= 0.85 else 7 if answer_similarity >= 0.5 else 5)\n",
        "\n",
        "# Add results to DataFrame and save\n",
        "df['rag_answer'] = rag_answers\n",
        "df['response_times'] = response_times\n",
        "df['cpu_start_usages'] = cpu_start_usages\n",
        "df['cpu_end_usages'] = cpu_end_usages\n",
        "df['average_cpu_usages'] = average_cpu_usages\n",
        "df['average_gpu_usages'] = average_gpu_usages\n",
        "df['context_relevance'] = context_relevance\n",
        "df['answer_relevance'] = [9, 10, 10, 6, 9, 9, 8, 6, 9, 9, 9, 10, 10, 6, 9, 9]\n",
        "df['groundedness'] = groundedness\n",
        "df['answer_correctness'] = answer_correctness\n",
        "df['human_judge_score'] = human_judge_score\n",
        "\n",
        "output_path = \"/content/drive/MyDrive/298B/Super_RAG_Evaluation_with_Metrics.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(\"Evaluation results saved to:\", output_path)\n",
        "\n",
        "# Display final DataFrame\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0rKdveM3D_lq",
        "outputId": "45c8211b-d735-48b6-bb1f-83f01c4a2845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index loaded successfully.\n",
            "Evaluation results saved to: /content/drive/MyDrive/298B/Super_RAG_Evaluation_with_Metrics.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the main purpose of Distributed Learni...   \n",
              "1   What is the key optimization algorithm in DL, ...   \n",
              "2   What is the primary objective of the Direction...   \n",
              "3   What phenomenon is identified as the primary c...   \n",
              "4   What approach does DECRL introduce to capture ...   \n",
              "5   What is the main objective of the Multi-Studen...   \n",
              "6   What is the primary goal of the Hierarchical G...   \n",
              "7   What is the primary objective of VAE-RL in net...   \n",
              "8   What is the main purpose of L3Ms, or Lagrange ...   \n",
              "9   What advantage does ISL-slicing offer over mar...   \n",
              "10  How does DyPlan differ from other question-ans...   \n",
              "11  What role does the VAE play in the VAE-RL fram...   \n",
              "12  How does MSD perform on text-to-image generati...   \n",
              "13  What three training stages are used in MSD, an...   \n",
              "14  How does LeReT handle complex questions in mul...   \n",
              "15  Which LVLM model shows the best performance in...   \n",
              "\n",
              "                                         ground_truth  \\\n",
              "0   The main purpose of DL is to enable multiple n...   \n",
              "1   The key optimization algorithm in DL is Stocha...   \n",
              "2   The primary objective of DASH is to reduce gra...   \n",
              "3   Plasticity loss in DASH is primarily caused by...   \n",
              "4   DECRL introduces temporal context propagation ...   \n",
              "5   The main objective of MSD is to distill knowle...   \n",
              "6   The primary goal of HGRL is to optimize hierar...   \n",
              "7   The main goal of VAE-RL is to manage resource ...   \n",
              "8   The main purpose of L3Ms is to integrate Lagra...   \n",
              "9   ISL-slicing improves performance in high-dimen...   \n",
              "10  DyPlan is a dynamic planning-based approach th...   \n",
              "11  The VAE in VAE-RL encodes network structures i...   \n",
              "12  MSD demonstrates superior performance in text-...   \n",
              "13  MSD training involves three stages: (1) Knowle...   \n",
              "14  LeReT uses multi-hop retrieval, breaking down ...   \n",
              "15  The LVLM model that integrates cross-modal ali...   \n",
              "\n",
              "                                           rag_answer  response_times  \\\n",
              "0   The main purpose of Distributed Learning (DL) ...            3.74   \n",
              "1   # [p]Theorem 1.1. Let $f$ be a function on $[0...            8.51   \n",
              "2   The primary objective of the Direction-Aware S...            4.53   \n",
              "3   The primary cause of plasticity loss in DASH i...            2.93   \n",
              "4   The approach introduced by DECRL to capture th...            8.18   \n",
              "5   The main objective of the Multi-Student Distil...            3.83   \n",
              "6   The primary goal of the Hierarchical Graph Rei...            4.09   \n",
              "7   The primary objective of VAE-RL in networked s...            4.83   \n",
              "8   The main purpose of L3Ms, or Lagrange Large La...            4.65   \n",
              "9   # [p]Theorem 1.1. Let $f$ be a function on $[0...            8.59   \n",
              "10  DyPlan differs from other question-answering a...            8.43   \n",
              "11  The VAE plays a role in the VAE-RL framework b...            4.12   \n",
              "12  MSD performs better than other methods on text...            2.41   \n",
              "13  The three training stages used in MSD are pre-...            4.07   \n",
              "14  LeReT handles complex questions in multi-hop r...            3.23   \n",
              "15  The LVLM model shows the best performance in r...            8.64   \n",
              "\n",
              "    cpu_start_usages  cpu_end_usages  average_cpu_usages  average_gpu_usages  \\\n",
              "0                6.7             0.3                3.50        11755.564453   \n",
              "1                0.4             0.3                0.35        11755.564453   \n",
              "2               10.4             1.1                5.75        11755.564453   \n",
              "3                9.6             0.3                4.95        11755.564453   \n",
              "4                0.4             7.6                4.00        11755.564453   \n",
              "5                9.6             0.4                5.00        11755.564453   \n",
              "6                0.5             0.3                0.40        11755.564453   \n",
              "7                0.4             0.3                0.35        11755.564453   \n",
              "8                0.2             0.3                0.25        11755.564453   \n",
              "9                0.3             0.3                0.30        11755.564453   \n",
              "10               0.4             0.3                0.35        11755.564453   \n",
              "11               0.3             0.4                0.35        11755.564453   \n",
              "12               0.5             1.0                0.75        11755.564453   \n",
              "13               9.3             0.2                4.75        11755.564453   \n",
              "14               0.3             0.2                0.25        11755.564453   \n",
              "15               0.4             2.1                1.25        11755.564453   \n",
              "\n",
              "    context_relevance  answer_relevance  groundedness  answer_correctness  \\\n",
              "0                   9                 9             6            0.614568   \n",
              "1                   9                10             3           -0.062248   \n",
              "2                   9                10             6            0.740746   \n",
              "3                   9                 6             6            0.751658   \n",
              "4                   9                 9             6            0.734089   \n",
              "5                   9                 9             6            0.661239   \n",
              "6                   9                 8             6            0.717094   \n",
              "7                   9                 6             8            0.818832   \n",
              "8                   9                 9             8            0.830642   \n",
              "9                   9                 9             3           -0.167191   \n",
              "10                  9                 9             6            0.580616   \n",
              "11                  9                10             6            0.794599   \n",
              "12                  9                10             6            0.754761   \n",
              "13                  9                 6             6            0.739288   \n",
              "14                  9                 9             6            0.762964   \n",
              "15                  9                 9             6            0.778306   \n",
              "\n",
              "    human_judge_score  \n",
              "0                   7  \n",
              "1                   5  \n",
              "2                   7  \n",
              "3                   7  \n",
              "4                   7  \n",
              "5                   7  \n",
              "6                   7  \n",
              "7                   7  \n",
              "8                   7  \n",
              "9                   5  \n",
              "10                  7  \n",
              "11                  7  \n",
              "12                  7  \n",
              "13                  7  \n",
              "14                  7  \n",
              "15                  7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-828d708e-690a-489f-bd35-48b030911498\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>rag_answer</th>\n",
              "      <th>response_times</th>\n",
              "      <th>cpu_start_usages</th>\n",
              "      <th>cpu_end_usages</th>\n",
              "      <th>average_cpu_usages</th>\n",
              "      <th>average_gpu_usages</th>\n",
              "      <th>context_relevance</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>groundedness</th>\n",
              "      <th>answer_correctness</th>\n",
              "      <th>human_judge_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the main purpose of Distributed Learni...</td>\n",
              "      <td>The main purpose of DL is to enable multiple n...</td>\n",
              "      <td>The main purpose of Distributed Learning (DL) ...</td>\n",
              "      <td>3.74</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.50</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.614568</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the key optimization algorithm in DL, ...</td>\n",
              "      <td>The key optimization algorithm in DL is Stocha...</td>\n",
              "      <td># [p]Theorem 1.1. Let $f$ be a function on $[0...</td>\n",
              "      <td>8.51</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.35</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.062248</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the primary objective of the Direction...</td>\n",
              "      <td>The primary objective of DASH is to reduce gra...</td>\n",
              "      <td>The primary objective of the Direction-Aware S...</td>\n",
              "      <td>4.53</td>\n",
              "      <td>10.4</td>\n",
              "      <td>1.1</td>\n",
              "      <td>5.75</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>0.740746</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What phenomenon is identified as the primary c...</td>\n",
              "      <td>Plasticity loss in DASH is primarily caused by...</td>\n",
              "      <td>The primary cause of plasticity loss in DASH i...</td>\n",
              "      <td>2.93</td>\n",
              "      <td>9.6</td>\n",
              "      <td>0.3</td>\n",
              "      <td>4.95</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.751658</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What approach does DECRL introduce to capture ...</td>\n",
              "      <td>DECRL introduces temporal context propagation ...</td>\n",
              "      <td>The approach introduced by DECRL to capture th...</td>\n",
              "      <td>8.18</td>\n",
              "      <td>0.4</td>\n",
              "      <td>7.6</td>\n",
              "      <td>4.00</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.734089</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is the main objective of the Multi-Studen...</td>\n",
              "      <td>The main objective of MSD is to distill knowle...</td>\n",
              "      <td>The main objective of the Multi-Student Distil...</td>\n",
              "      <td>3.83</td>\n",
              "      <td>9.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>5.00</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.661239</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is the primary goal of the Hierarchical G...</td>\n",
              "      <td>The primary goal of HGRL is to optimize hierar...</td>\n",
              "      <td>The primary goal of the Hierarchical Graph Rei...</td>\n",
              "      <td>4.09</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.40</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>0.717094</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the primary objective of VAE-RL in net...</td>\n",
              "      <td>The main goal of VAE-RL is to manage resource ...</td>\n",
              "      <td>The primary objective of VAE-RL in networked s...</td>\n",
              "      <td>4.83</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.35</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>0.818832</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the main purpose of L3Ms, or Lagrange ...</td>\n",
              "      <td>The main purpose of L3Ms is to integrate Lagra...</td>\n",
              "      <td>The main purpose of L3Ms, or Lagrange Large La...</td>\n",
              "      <td>4.65</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.25</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>0.830642</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What advantage does ISL-slicing offer over mar...</td>\n",
              "      <td>ISL-slicing improves performance in high-dimen...</td>\n",
              "      <td># [p]Theorem 1.1. Let $f$ be a function on $[0...</td>\n",
              "      <td>8.59</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.167191</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How does DyPlan differ from other question-ans...</td>\n",
              "      <td>DyPlan is a dynamic planning-based approach th...</td>\n",
              "      <td>DyPlan differs from other question-answering a...</td>\n",
              "      <td>8.43</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.35</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.580616</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What role does the VAE play in the VAE-RL fram...</td>\n",
              "      <td>The VAE in VAE-RL encodes network structures i...</td>\n",
              "      <td>The VAE plays a role in the VAE-RL framework b...</td>\n",
              "      <td>4.12</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.35</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>0.794599</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How does MSD perform on text-to-image generati...</td>\n",
              "      <td>MSD demonstrates superior performance in text-...</td>\n",
              "      <td>MSD performs better than other methods on text...</td>\n",
              "      <td>2.41</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>0.754761</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What three training stages are used in MSD, an...</td>\n",
              "      <td>MSD training involves three stages: (1) Knowle...</td>\n",
              "      <td>The three training stages used in MSD are pre-...</td>\n",
              "      <td>4.07</td>\n",
              "      <td>9.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>4.75</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0.739288</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How does LeReT handle complex questions in mul...</td>\n",
              "      <td>LeReT uses multi-hop retrieval, breaking down ...</td>\n",
              "      <td>LeReT handles complex questions in multi-hop r...</td>\n",
              "      <td>3.23</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.762964</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Which LVLM model shows the best performance in...</td>\n",
              "      <td>The LVLM model that integrates cross-modal ali...</td>\n",
              "      <td>The LVLM model shows the best performance in r...</td>\n",
              "      <td>8.64</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>1.25</td>\n",
              "      <td>11755.564453</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.778306</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-828d708e-690a-489f-bd35-48b030911498')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-828d708e-690a-489f-bd35-48b030911498 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-828d708e-690a-489f-bd35-48b030911498');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-39e4a0cc-85e3-464e-a6d4-30359a7f8a24\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39e4a0cc-85e3-464e-a6d4-30359a7f8a24')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-39e4a0cc-85e3-464e-a6d4-30359a7f8a24 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a517d580-990c-46a5-8004-b370b96d73a4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a517d580-990c-46a5-8004-b370b96d73a4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"What is the main purpose of Distributed Learning (DL)?\",\n          \"What is the key optimization algorithm in DL, and what challenge does it face?\",\n          \"What is the main objective of the Multi-Student Distillation (MSD) framework?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"The main purpose of DL is to enable multiple nodes to collaboratively train large models, reducing individual computational loads and training times.\",\n          \"The key optimization algorithm in DL is Stochastic Gradient Descent (SGD), which faces the challenge of communication overhead between nodes.\",\n          \"The main objective of MSD is to distill knowledge from a large teacher model into multiple smaller students.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rag_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"The main purpose of Distributed Learning (DL) is to provide a platform for researchers to share their work and ideas, and to facilitate collaboration and knowledge sharing.\",\n          \"# [p]Theorem 1.1. Let $f$ be a function on $[0,1]$ that is continuous on $[0,1]$ and differentiable on $(0,1)$. Then there exists a point $c\\\\in(0,1)$ such that $f(c)=\\\\frac{f'(c)}{2}.$\\n\\nTheorem 1.1. Let $f$ be a function on $[0,1]$\",\n          \"The main objective of the Multi-Student Distillation (MSD) framework is to improve the performance of student models by leveraging the knowledge of multiple teacher models.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_times\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2924393848765843,\n        \"min\": 2.41,\n        \"max\": 8.64,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          3.74,\n          8.51,\n          3.83\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_start_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.251191009587784,\n        \"min\": 0.2,\n        \"max\": 10.4,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.4,\n          0.2,\n          6.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_end_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.838069639594757,\n        \"min\": 0.2,\n        \"max\": 7.6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.3,\n          1.1,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_cpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1625385353021263,\n        \"min\": 0.25,\n        \"max\": 5.75,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          4.75,\n          0.75,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_gpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 11755.564453125,\n        \"max\": 11755.564453125,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          11755.564453125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 9,\n        \"max\": 9,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 6,\n        \"max\": 10,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"groundedness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_correctness\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.6145679950714111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_judge_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 7,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV file with metrics data\n",
        "csv_file_path = \"/content/drive/MyDrive/298B/Super_RAG_Evaluation_with_Metrics.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Compute the average for RAG answer correctness metrics\n",
        "rag_correctness_avg_df = pd.DataFrame({\n",
        "    'model': ['Super RAG'],\n",
        "    'context_relevance': [df['context_relevance'].mean()],\n",
        "    'answer_relevance': [df['answer_relevance'].mean()],\n",
        "    'groundedness': [df['groundedness'].mean()],\n",
        "    'answer_correctness': [df['answer_correctness'].mean()],\n",
        "    'human_judge_score': [df['human_judge_score'].mean()]\n",
        "})\n",
        "\n",
        "# Compute the average for CPU performance metrics\n",
        "cpu_performance_avg_df = pd.DataFrame({\n",
        "    'model': ['Super RAG'],\n",
        "    'response_times': [df['response_times'].mean()],\n",
        "    'cpu_start_usages': [df['cpu_start_usages'].mean()],\n",
        "    'cpu_end_usages': [df['cpu_end_usages'].mean()],\n",
        "    'average_cpu_usages': [df['average_cpu_usages'].mean()],\n",
        "    'average_gpu_usages': [df['average_gpu_usages'].mean()]\n",
        "})\n",
        "\n",
        "# Display the average RAG answer correctness metrics\n",
        "print(\"Average RAG answer correctness:\")\n",
        "display(rag_correctness_avg_df)\n",
        "\n",
        "# Display the average CPU performance metrics\n",
        "print(\"Average CPU performance metrics:\")\n",
        "display(cpu_performance_avg_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "uUnUHv7pH64s",
        "outputId": "789f8cc1-86e2-4452-d425-5622497f4761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average RAG answer correctness:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       model  context_relevance  answer_relevance  groundedness  \\\n",
              "0  Super RAG                9.0             8.625         5.875   \n",
              "\n",
              "   answer_correctness  human_judge_score  \n",
              "0            0.628123               6.75  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30a49813-31cf-464b-8e20-9792c2d72343\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>context_relevance</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>groundedness</th>\n",
              "      <th>answer_correctness</th>\n",
              "      <th>human_judge_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Super RAG</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.625</td>\n",
              "      <td>5.875</td>\n",
              "      <td>0.628123</td>\n",
              "      <td>6.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30a49813-31cf-464b-8e20-9792c2d72343')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30a49813-31cf-464b-8e20-9792c2d72343 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30a49813-31cf-464b-8e20-9792c2d72343');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_f4466d18-f7ae-4778-83d9-1b412ed97225\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rag_correctness_avg_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f4466d18-f7ae-4778-83d9-1b412ed97225 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('rag_correctness_avg_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "rag_correctness_avg_df",
              "summary": "{\n  \"name\": \"rag_correctness_avg_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Super RAG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 9.0,\n        \"max\": 9.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 8.625,\n        \"max\": 8.625,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8.625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"groundedness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 5.875,\n        \"max\": 5.875,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6281227783750001,\n        \"max\": 0.6281227783750001,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6281227783750001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_judge_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 6.75,\n        \"max\": 6.75,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average CPU performance metrics:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       model  response_times  cpu_start_usages  cpu_end_usages  \\\n",
              "0  Super RAG         5.29875           3.10625          0.9625   \n",
              "\n",
              "   average_cpu_usages  average_gpu_usages  \n",
              "0            2.034375        11755.564453  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc9c4a4e-a337-420f-a713-cabdb5a496f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>response_times</th>\n",
              "      <th>cpu_start_usages</th>\n",
              "      <th>cpu_end_usages</th>\n",
              "      <th>average_cpu_usages</th>\n",
              "      <th>average_gpu_usages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Super RAG</td>\n",
              "      <td>5.29875</td>\n",
              "      <td>3.10625</td>\n",
              "      <td>0.9625</td>\n",
              "      <td>2.034375</td>\n",
              "      <td>11755.564453</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc9c4a4e-a337-420f-a713-cabdb5a496f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc9c4a4e-a337-420f-a713-cabdb5a496f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc9c4a4e-a337-420f-a713-cabdb5a496f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_972e6690-bb95-4c9b-bf73-1582a9c4da0f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cpu_performance_avg_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_972e6690-bb95-4c9b-bf73-1582a9c4da0f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cpu_performance_avg_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cpu_performance_avg_df",
              "summary": "{\n  \"name\": \"cpu_performance_avg_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Super RAG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_times\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 5.29875,\n        \"max\": 5.29875,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.29875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_start_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3.10625,\n        \"max\": 3.10625,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3.10625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_end_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9624999999999999,\n        \"max\": 0.9624999999999999,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9624999999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_cpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2.034375,\n        \"max\": 2.034375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2.034375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_gpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 11755.564453125,\n        \"max\": 11755.564453125,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          11755.564453125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User Interface"
      ],
      "metadata": {
        "id": "91tCZJ6aFExS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xAInXEVrFHbu",
        "outputId": "82aa51d0-d8d1-4516-cb0f-d18dc65b15aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, huggingface-hub, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.4 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 huggingface-hub-0.26.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.3 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "huggingface_hub"
                ]
              },
              "id": "cee706ba4276450985a1517feefefd18"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import os\n",
        "\n",
        "# Specify the path\n",
        "index_path = \"/content/drive/MyDrive/298B/faiss_index.idx\"\n",
        "\n",
        "# Attempt to load the FAISS index\n",
        "try:\n",
        "    # Ensure the file exists\n",
        "    if not os.path.exists(index_path):\n",
        "        raise FileNotFoundError(f\"The FAISS index file was not found at {index_path}\")\n",
        "\n",
        "    # Load the index\n",
        "    index = faiss.read_index(index_path)\n",
        "    print(\"FAISS index loaded successfully.\")\n",
        "\n",
        "    # Verify that the index can perform a search operation\n",
        "    if hasattr(index, 'search'):\n",
        "        print(\"The FAISS index is properly initialized and ready for searches.\")\n",
        "    else:\n",
        "        raise AttributeError(\"The loaded object does not have a 'search' attribute, indicating an incorrect index file.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading FAISS index: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gNUXtRXPQuy",
        "outputId": "4deb88a8-97c2-4d71-e0c3-56b92a800714"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index loaded successfully.\n",
            "The FAISS index is properly initialized and ready for searches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-P37k4LXOhe",
        "outputId": "12b3414c-ff93-4fca-e284-32e9764909d1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m81.9/232.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BOOpeoK3dVtA",
        "outputId": "d9c6393d-6e0f-40d2-c8a6-555557aea4f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, huggingface-hub, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.4 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 huggingface-hub-0.26.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.3 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "huggingface_hub"
                ]
              },
              "id": "2ab8e0dfdf654fd098bfd6d1315700cc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import faiss\n",
        "import pickle\n",
        "from PyPDF2 import PdfReader\n",
        "from hashlib import md5\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Hugging Face token (already set in the environment)\n",
        "token = \"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\"\n",
        "\n",
        "# Load the embedding model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', trust_remote_code=True)\n",
        "\n",
        "# Load FAISS index and text chunks\n",
        "index_path = \"/content/drive/MyDrive/298B/faiss_index.idx\"\n",
        "chunks_path = \"/content/drive/MyDrive/298B/merged_text_chunks_ml.pkl\"\n",
        "\n",
        "with open(chunks_path, 'rb') as f:\n",
        "    text_chunks = pickle.load(f)\n",
        "index = faiss.read_index(index_path)\n",
        "\n",
        "# Function to parse PDF and return its text content\n",
        "def parse_pdf(file_path):\n",
        "    pdf_reader = PdfReader(file_path)\n",
        "    pdf_text = \"\"\n",
        "    for page in pdf_reader.pages:\n",
        "        pdf_text += page.extract_text()\n",
        "    return pdf_text\n",
        "\n",
        "# Cache Management\n",
        "cache = {}\n",
        "def retrieve_from_cache(query):\n",
        "    query_hash = md5(query.encode()).hexdigest()\n",
        "    return cache.get(query_hash)\n",
        "\n",
        "def store_in_cache(query, response):\n",
        "    query_hash = md5(query.encode()).hexdigest()\n",
        "    cache[query_hash] = response\n",
        "\n",
        "# Function to retrieve relevant sections from FAISS index\n",
        "def retrieve_relevant_sections(question, top_k=3):\n",
        "    cached_response = retrieve_from_cache(question)\n",
        "    if cached_response:\n",
        "        return cached_response\n",
        "\n",
        "    query_embedding = embedding_model.encode(question)\n",
        "    query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
        "    distances, indices = index.search(np.array([query_embedding], dtype=np.float32), top_k)\n",
        "    relevant_docs = [text_chunks[idx] for idx in indices[0]]\n",
        "\n",
        "    results = []\n",
        "    for i, doc in enumerate(relevant_docs):\n",
        "        similarity_score = 1 - distances[0][i]\n",
        "        confidence_score = round(similarity_score, 2)\n",
        "        results.append({\n",
        "            \"id\": i,\n",
        "            \"confidence\": confidence_score,\n",
        "            \"relevant_text\": doc\n",
        "        })\n",
        "\n",
        "    results = sorted(results, key=lambda x: x[\"confidence\"], reverse=True)\n",
        "    store_in_cache(question, results)\n",
        "    return results\n",
        "\n",
        "# Function to generate an answer using LLM based on the context\n",
        "def answer_question_with_llama(question, context):\n",
        "    prompt = (\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Answer concisely based on the provided context:\"\n",
        "    )\n",
        "\n",
        "    # Generate the answer with refined settings\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    output = model.generate(\n",
        "        inputs.input_ids,\n",
        "        max_new_tokens=150,\n",
        "        repetition_penalty=3.0,\n",
        "        do_sample=False\n",
        "    )\n",
        "    final_response = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
        "\n",
        "    return final_response\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/Llama-3-8B-ProLong-64k-Base\", use_auth_token=token)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"princeton-nlp/Llama-3-8B-ProLong-64k-Base\",\n",
        "    quantization_config=BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16),\n",
        "    device_map=\"auto\",\n",
        "    use_auth_token=token\n",
        ")\n",
        "\n",
        "# Gradio function to handle PDF upload and question-answering\n",
        "def generate_response(pdf_file, question):\n",
        "    if pdf_file is None:\n",
        "        return \"Please upload a PDF file first.\"\n",
        "\n",
        "    # Parse PDF content\n",
        "    pdf_text = parse_pdf(pdf_file.name)\n",
        "\n",
        "    # Retrieve relevant sections based on the question\n",
        "    context_docs = retrieve_relevant_sections(question)  # Retrieve from FAISS index based on question\n",
        "    context = \"\\n\\n\".join([doc[\"relevant_text\"] for doc in context_docs[:3]])\n",
        "\n",
        "    # Generate answer with the model\n",
        "    answer = answer_question_with_llama(question, context)\n",
        "\n",
        "    # Combine context and answer for display\n",
        "    return f\"Context Used:\\n{context}\\n\\nAnswer:\\n{answer}\"\n",
        "\n",
        "# Gradio interface setup\n",
        "iface = gr.Interface(\n",
        "    fn=generate_response,\n",
        "    inputs=[\n",
        "        gr.File(label=\"Upload PDF file\", type=\"filepath\"),\n",
        "        gr.Textbox(label=\"Enter your question\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"SuperRAG Answer Generation\",\n",
        "    description=\"Upload a PDF file and enter a question. The system will retrieve relevant information and generate an answer.\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775,
          "referenced_widgets": [
            "feb712726ff3477f95c038732343cbaf",
            "c7f118a32f694991953234cc456bdc47",
            "44ed6236d41b48f1b0f330cc78a6d258",
            "41b24f3b5a4a4c35ab032b5cea15d764",
            "6dd713c6f1fa4f1d936ae244e35d2c8a",
            "0accdd61711440f0bfbbd6dc4c2c5d61",
            "4120d9b47daf46029d40481030293693",
            "536019cd57a149be9a60f3b7508063b7",
            "034738dc363d4abd8c041792c0b7a916",
            "372b2f6e2ce24a639850c32d34941d7d",
            "a65674fd5f3c43648128d67c14e832c8"
          ]
        },
        "id": "Fiw6sHurFEhr",
        "outputId": "91aba7a1-0216-41d2-f001-8d5ba37d3171"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:786: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "feb712726ff3477f95c038732343cbaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://67fce4be35053391f3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://67fce4be35053391f3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c66ead71b69a4b08a02b58f3449c4bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ebf90698b194153bd37330917f4502d",
              "IPY_MODEL_7001eb4df9fc479b9082d5ce01ba82a1",
              "IPY_MODEL_bdf84e6592484193a577a4d2afe1a5f2"
            ],
            "layout": "IPY_MODEL_47676085d2224b0c898c99f4bfe2daee"
          }
        },
        "1ebf90698b194153bd37330917f4502d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc706d6581f04f0fb01ca31265ebf309",
            "placeholder": "",
            "style": "IPY_MODEL_79d764042eb144c886730760f2e254d7",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "7001eb4df9fc479b9082d5ce01ba82a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa88cba86b0744b4928905cc8c4171a7",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1e32dd4122441939c41b5abd2d67bd7",
            "value": 7
          }
        },
        "bdf84e6592484193a577a4d2afe1a5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cc7d62e3e8e424abd7a87c1edd7d992",
            "placeholder": "",
            "style": "IPY_MODEL_9c0340254fc241698f8ddc214a104230",
            "value": "7/7[02:49&lt;00:00,24.70s/it]"
          }
        },
        "47676085d2224b0c898c99f4bfe2daee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc706d6581f04f0fb01ca31265ebf309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79d764042eb144c886730760f2e254d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa88cba86b0744b4928905cc8c4171a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e32dd4122441939c41b5abd2d67bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cc7d62e3e8e424abd7a87c1edd7d992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c0340254fc241698f8ddc214a104230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e93b012cf9fc4f0a937bc0d35b4c7d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fc97069c18b4908b156cae76f48a2e5",
              "IPY_MODEL_6784aceb44a74735a283d25e7dffdf34",
              "IPY_MODEL_b755437ef147497c9611c61fdda33fb9"
            ],
            "layout": "IPY_MODEL_5f5186b78173457f8c5706e77af4491c"
          }
        },
        "7fc97069c18b4908b156cae76f48a2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52bb3b49cc154ecbba5fcef29e6ef01b",
            "placeholder": "",
            "style": "IPY_MODEL_e3dfaeb40e234f929118654bc89f82d0",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "6784aceb44a74735a283d25e7dffdf34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdb9b84eb70b47209c694c73935f6042",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4680ba71c9384ed9adc55e9f896bfcc3",
            "value": 7
          }
        },
        "b755437ef147497c9611c61fdda33fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f811dfe87a244f1b21d6a33794161fb",
            "placeholder": "",
            "style": "IPY_MODEL_4f4369cdb8654db6aac4010050286b4a",
            "value": "7/7[02:03&lt;00:00,19.14s/it]"
          }
        },
        "5f5186b78173457f8c5706e77af4491c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52bb3b49cc154ecbba5fcef29e6ef01b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3dfaeb40e234f929118654bc89f82d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdb9b84eb70b47209c694c73935f6042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4680ba71c9384ed9adc55e9f896bfcc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f811dfe87a244f1b21d6a33794161fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f4369cdb8654db6aac4010050286b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63cb2adfd9674dc28d28ae42b3b76584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7411da092bd459bb6e1a68fbd69dde1",
              "IPY_MODEL_2b4012ce7ed143fca27963d3f49185a8",
              "IPY_MODEL_2ddb8cbec77b49a8b987d04955f92629"
            ],
            "layout": "IPY_MODEL_f56e221f096b4e1a8df2ce320ea5cd3b"
          }
        },
        "c7411da092bd459bb6e1a68fbd69dde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a929cfd551e34a7d828f8ba8abbbfcc6",
            "placeholder": "",
            "style": "IPY_MODEL_8cc9b31a99e24aaf9c852436a11ebe84",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "2b4012ce7ed143fca27963d3f49185a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b267dffac0e347149d80096230bf5725",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bebab8c1155e47fb9c03552460c36f82",
            "value": 7
          }
        },
        "2ddb8cbec77b49a8b987d04955f92629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d06cfd32ee1244fb99d7308a24631bff",
            "placeholder": "",
            "style": "IPY_MODEL_37519f3a788549f8bb8e40997767a0a2",
            "value": "7/7[02:25&lt;00:00,18.63s/it]"
          }
        },
        "f56e221f096b4e1a8df2ce320ea5cd3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a929cfd551e34a7d828f8ba8abbbfcc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc9b31a99e24aaf9c852436a11ebe84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b267dffac0e347149d80096230bf5725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bebab8c1155e47fb9c03552460c36f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d06cfd32ee1244fb99d7308a24631bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37519f3a788549f8bb8e40997767a0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feb712726ff3477f95c038732343cbaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7f118a32f694991953234cc456bdc47",
              "IPY_MODEL_44ed6236d41b48f1b0f330cc78a6d258",
              "IPY_MODEL_41b24f3b5a4a4c35ab032b5cea15d764"
            ],
            "layout": "IPY_MODEL_6dd713c6f1fa4f1d936ae244e35d2c8a"
          }
        },
        "c7f118a32f694991953234cc456bdc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0accdd61711440f0bfbbd6dc4c2c5d61",
            "placeholder": "",
            "style": "IPY_MODEL_4120d9b47daf46029d40481030293693",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "44ed6236d41b48f1b0f330cc78a6d258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_536019cd57a149be9a60f3b7508063b7",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_034738dc363d4abd8c041792c0b7a916",
            "value": 7
          }
        },
        "41b24f3b5a4a4c35ab032b5cea15d764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_372b2f6e2ce24a639850c32d34941d7d",
            "placeholder": "",
            "style": "IPY_MODEL_a65674fd5f3c43648128d67c14e832c8",
            "value": "7/7[02:22&lt;00:00,18.16s/it]"
          }
        },
        "6dd713c6f1fa4f1d936ae244e35d2c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0accdd61711440f0bfbbd6dc4c2c5d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4120d9b47daf46029d40481030293693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "536019cd57a149be9a60f3b7508063b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "034738dc363d4abd8c041792c0b7a916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "372b2f6e2ce24a639850c32d34941d7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a65674fd5f3c43648128d67c14e832c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}