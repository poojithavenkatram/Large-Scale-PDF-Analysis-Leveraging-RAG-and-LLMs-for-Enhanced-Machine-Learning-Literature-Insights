{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5af6508b2b6242c09a74c778026426c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ccc6bd5917b64defbc531ce1bc3cb662","IPY_MODEL_5d4ebffc7f344e369e0652fd51aa7cd2","IPY_MODEL_6f96bd9626574cc1a16cebf5d29c1656"],"layout":"IPY_MODEL_021570548da84292be1726eacc64afcf"}},"ccc6bd5917b64defbc531ce1bc3cb662":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5187f3b4689a4b268ea78ea2dff54e18","placeholder":"​","style":"IPY_MODEL_53e607d10654494a86b0b005c89512c2","value":"Loading checkpoint shards: 100%"}},"5d4ebffc7f344e369e0652fd51aa7cd2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c31f2c458db842cfa701706100dbe32e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4767cd68ae841ecb656223d9a307bab","value":2}},"6f96bd9626574cc1a16cebf5d29c1656":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b3b4e964b794595bd5f4d7dfdca0b90","placeholder":"​","style":"IPY_MODEL_e0851700aacd46158fa9390b194d30a4","value":" 2/2 [01:04&lt;00:00, 29.53s/it]"}},"021570548da84292be1726eacc64afcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5187f3b4689a4b268ea78ea2dff54e18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53e607d10654494a86b0b005c89512c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c31f2c458db842cfa701706100dbe32e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4767cd68ae841ecb656223d9a307bab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b3b4e964b794595bd5f4d7dfdca0b90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0851700aacd46158fa9390b194d30a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"snM7gR7vUdL6","executionInfo":{"status":"ok","timestamp":1713037633445,"user_tz":420,"elapsed":218037,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"07ef5980-860b-444a-9ae9-632a0e84ab67"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/817.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/817.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/817.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m809.0/817.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n","  Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n","  Downloading langchain_core-0.1.42-py3-none-any.whl (287 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n","  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.47-py3-none-any.whl (113 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.0\n","    Uninstalling packaging-24.0:\n","      Successfully uninstalled packaging-24.0\n","Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.32 langchain-core-0.1.42 langchain-text-splitters-0.0.1 langsmith-0.1.47 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n","Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n","Collecting sentence_transformers\n","  Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence_transformers-2.6.1\n","Collecting llama-cpp-python\n","  Downloading llama_cpp_python-0.2.61.tar.gz (37.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.4/37.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.11.0)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n","Collecting diskcache>=5.6.1 (from llama-cpp-python)\n","  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n","Building wheels for collected packages: llama-cpp-python\n","  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.61-cp310-cp310-manylinux_2_35_x86_64.whl size=3002210 sha256=8911f4df8d00710815ef2570c1cae3968ed8eb178839564489645b304fa6f5a6\n","  Stored in directory: /root/.cache/pip/wheels/a4/d4/bc/483ff5c198ee745418fb35b59055591eeae2bc6ff69680537f\n","Successfully built llama-cpp-python\n","Installing collected packages: diskcache, llama-cpp-python\n","Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.61\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.11.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"]}],"source":["!pip install langchain\n","!pip install PyPDF2\n","!pip install sentence_transformers\n","!pip install llama-cpp-python\n","!pip install huggingface_hub"]},{"cell_type":"code","source":["\n","!pip install accelerate==0.21.0 transformers==4.31.0 tokenizers==0.13.3\n","!pip install bitsandbytes==0.40.0 einops==0.6.1\n","!pip install xformers==0.0.22.post7\n","!pip install langchain==0.1.4\n","!pip install sentence_transformers"],"metadata":{"id":"Sf38_cVXi1-H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713037805801,"user_tz":420,"elapsed":162018,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"ac340ef8-9127-4e6b-e565-803f757abacd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting accelerate==0.21.0\n","  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers==4.31.0\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers==0.13.3\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.20.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2.31.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.21.0) (12.4.127)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n","Installing collected packages: tokenizers, transformers, accelerate\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.15.2\n","    Uninstalling tokenizers-0.15.2:\n","      Successfully uninstalled tokenizers-0.15.2\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.38.2\n","    Uninstalling transformers-4.38.2:\n","      Successfully uninstalled transformers-4.38.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 2.6.1 requires transformers<5.0.0,>=4.32.0, but you have transformers 4.31.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.21.0 tokenizers-0.13.3 transformers-4.31.0\n","Collecting bitsandbytes==0.40.0\n","  Downloading bitsandbytes-0.40.0-py3-none-any.whl (91.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops==0.6.1\n","  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes, einops\n","Successfully installed bitsandbytes-0.40.0 einops-0.6.1\n","Collecting xformers==0.0.22.post7\n","  Downloading xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl (211.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.22.post7) (1.25.2)\n","Collecting torch==2.1.0 (from xformers==0.0.22.post7)\n","  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.13.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.0.106)\n","Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->xformers==0.0.22.post7)\n","  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n","Collecting triton==2.1.0 (from torch==2.1.0->xformers==0.0.22.post7)\n","  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->xformers==0.0.22.post7) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->xformers==0.0.22.post7) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->xformers==0.0.22.post7) (1.3.0)\n","Installing collected packages: triton, nvidia-nccl-cu12, torch, xformers\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.2.0\n","    Uninstalling triton-2.2.0:\n","      Successfully uninstalled triton-2.2.0\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.19.3\n","    Uninstalling nvidia-nccl-cu12-2.19.3:\n","      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.2.1+cu121\n","    Uninstalling torch-2.2.1+cu121:\n","      Successfully uninstalled torch-2.2.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 2.6.1 requires transformers<5.0.0,>=4.32.0, but you have transformers 4.31.0 which is incompatible.\n","torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n","torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n","torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.18.1 torch-2.1.0 triton-2.1.0 xformers-0.0.22.post7\n","Collecting langchain==0.1.4\n","  Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (2.0.29)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (3.9.3)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (4.0.3)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (0.6.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (1.33)\n","Requirement already satisfied: langchain-community<0.1,>=0.0.14 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (0.0.32)\n","Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (0.1.42)\n","Collecting langsmith<0.1,>=0.0.83 (from langchain==0.1.4)\n","  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (1.25.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (2.6.4)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (8.2.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.9.4)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.4) (3.21.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.4) (0.9.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.4) (2.4)\n","INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n","Collecting langchain-community<0.1,>=0.0.14 (from langchain==0.1.4)\n","  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_community-0.0.30-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_community-0.0.26-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n","  Downloading langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_community-0.0.23-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_community-0.0.22-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_community-0.0.21-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n","Collecting langchain-core<0.2,>=0.1.16 (from langchain==0.1.4)\n","  Downloading langchain_core-0.1.41-py3-none-any.whl (278 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.4/278.4 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.40-py3-none-any.whl (276 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.39-py3-none-any.whl (276 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.38-py3-none-any.whl (279 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.2/279.2 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.37-py3-none-any.whl (274 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.6/274.6 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.36-py3-none-any.whl (273 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.35-py3-none-any.whl (273 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.0/273.0 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n","  Downloading langchain_core-0.1.34-py3-none-any.whl (271 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain==0.1.4) (3.7.1)\n","  Downloading langchain_core-0.1.32-py3-none-any.whl (260 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.31-py3-none-any.whl (258 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading langchain_core-0.1.29-py3-none-any.whl (252 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.6/252.6 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.27-py3-none-any.whl (250 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.26-py3-none-any.whl (246 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.25-py3-none-any.whl (242 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.24-py3-none-any.whl (241 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.3/241.3 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain==0.1.4)\n","  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain==0.1.4) (23.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.4) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.4) (2.16.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.4) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.4) (3.0.3)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain==0.1.4) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain==0.1.4) (1.2.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.4) (1.0.0)\n","Installing collected packages: langsmith, langchain-core, langchain-community, langchain\n","  Attempting uninstall: langsmith\n","    Found existing installation: langsmith 0.1.47\n","    Uninstalling langsmith-0.1.47:\n","      Successfully uninstalled langsmith-0.1.47\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.1.42\n","    Uninstalling langchain-core-0.1.42:\n","      Successfully uninstalled langchain-core-0.1.42\n","  Attempting uninstall: langchain-community\n","    Found existing installation: langchain-community 0.0.32\n","    Uninstalling langchain-community-0.0.32:\n","      Successfully uninstalled langchain-community-0.0.32\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.1.16\n","    Uninstalling langchain-0.1.16:\n","      Successfully uninstalled langchain-0.1.16\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","langchain-text-splitters 0.0.1 requires langchain-core<0.2.0,>=0.1.28, but you have langchain-core 0.1.23 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-0.1.4 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.6.1)\n","Collecting transformers<5.0.0,>=4.32.0 (from sentence_transformers)\n","  Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.18.1)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.127)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n","Collecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.32.0->sentence_transformers)\n","  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.3\n","    Uninstalling tokenizers-0.13.3:\n","      Successfully uninstalled tokenizers-0.13.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.31.0\n","    Uninstalling transformers-4.31.0:\n","      Successfully uninstalled transformers-4.31.0\n","Successfully installed tokenizers-0.15.2 transformers-4.39.3\n"]}]},{"cell_type":"code","source":["!pip install pypdf\n","!pip install rank_bm25\n","!pip install chromadb\n","!pip install bitsandbytes>=0.41.3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69vKRR8IyJkW","executionInfo":{"status":"ok","timestamp":1713037862508,"user_tz":420,"elapsed":41357,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"ec87f7e8-126a-4ccd-e8fe-8e9ef1c1dd5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rank_bm25\n","  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.25.2)\n","Installing collected packages: rank_bm25\n","Successfully installed rank_bm25-0.2.2\n","Collecting chromadb\n","  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n","Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.4)\n","Collecting chroma-hnswlib==0.7.3 (from chromadb)\n","  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n","  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n","  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n","Collecting posthog>=2.4.0 (from chromadb)\n","  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.11.0)\n","Collecting pulsar-client>=3.1.0 (from chromadb)\n","  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n","  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n","  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n","Collecting pypika>=0.48.9 (from chromadb)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n","Collecting overrides>=7.3.1 (from chromadb)\n","  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n","Collecting bcrypt>=4.0.1 (from chromadb)\n","  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.4)\n","Collecting kubernetes>=28.1.0 (from chromadb)\n","  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n","Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n","Collecting mmh3>=4.0.1 (from chromadb)\n","  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.0)\n","Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n","Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n","  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n","Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n","Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n","Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n","Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n","  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n","Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n","Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (3.7.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.2.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n","Building wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=a8da2c27000ef6ccababaa0da263491cb932aa42bb2bdd57f5d8606f59305e31\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built pypika\n","Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, python-dotenv, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, importlib-metadata, humanfriendly, httptools, h11, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib_metadata 7.1.0\n","    Uninstalling importlib_metadata-7.1.0:\n","      Successfully uninstalled importlib_metadata-7.1.0\n","Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.1 h11-0.14.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-7.0.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.17.3 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.37.2 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y6vUYAysZPBH","executionInfo":{"status":"ok","timestamp":1713040982227,"user_tz":420,"elapsed":1429,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"03ef5340-7bbd-4a4e-8c43-04598170171a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# 1. Load the PDF using PdfReader"],"metadata":{"id":"c6AYc0m6bVfA"}},{"cell_type":"markdown","source":["# 2. Split the Text into chunks with chunk size of 100 and overlap of 200"],"metadata":{"id":"klZ5bz0Vb9Pw"}},{"cell_type":"code","source":["!pip install pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nkcg3OYX07q9","executionInfo":{"status":"ok","timestamp":1713038016382,"user_tz":420,"elapsed":6652,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"76d298aa-1ab0-4c41-dbfa-79c2da640f59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pypdf\n","  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m286.7/290.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n","Installing collected packages: pypdf\n","Successfully installed pypdf-4.2.0\n"]}]},{"cell_type":"code","source":["!pip install chromadb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VEkJegy1XYW","executionInfo":{"status":"ok","timestamp":1713034884716,"user_tz":420,"elapsed":30063,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"f941bed6-8cb3-4cc9-8806-96922dc791ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting chromadb\n","  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n","Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.4)\n","Collecting chroma-hnswlib==0.7.3 (from chromadb)\n","  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n","  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n","  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n","Collecting posthog>=2.4.0 (from chromadb)\n","  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.11.0)\n","Collecting pulsar-client>=3.1.0 (from chromadb)\n","  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n","  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n","  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n","Collecting pypika>=0.48.9 (from chromadb)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n","Collecting overrides>=7.3.1 (from chromadb)\n","  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n","Collecting bcrypt>=4.0.1 (from chromadb)\n","  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.4)\n","Collecting kubernetes>=28.1.0 (from chromadb)\n","  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n","Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n","Collecting mmh3>=4.0.1 (from chromadb)\n","  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.0)\n","Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n","Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n","  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n","Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n","Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n","Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n","Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n","  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n","Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (3.7.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.2.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n","Building wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=3de9b8d1b6f8da3c55062e172ab83d234f7d7a4e141b8c31586f18f16027adfd\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built pypika\n","Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, uvicorn, python-dotenv, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, importlib-metadata, humanfriendly, httptools, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib_metadata 7.1.0\n","    Uninstalling importlib_metadata-7.1.0:\n","      Successfully uninstalled importlib_metadata-7.1.0\n","Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.1 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-7.0.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.17.3 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.37.2 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"]}]},{"cell_type":"code","source":["!pip install bitsandbytes>=0.41.3"],"metadata":{"id":"pa0uMAsl77pd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","from os import walk\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain_core.documents import Document\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain_community.vectorstores import Chroma\n","from langchain.retrievers import BM25Retriever, EnsembleRetriever\n","from langchain.retrievers import ContextualCompressionRetriever\n","from langchain.retrievers.document_compressors import CohereRerank\n","from google.colab import userdata\n","import torch\n","import transformers\n","\n","def docs_retriever(question, k=5):\n","    \"\"\"\n","    Load original documents and retrieve relevant documents\n","    \"\"\"\n","\n","    # load documents\n","    file_path = \"/content/drive/MyDrive/298A/PDFs/\"\n","    f = []\n","    for (dirpath, dirnames, filenames) in walk(file_path):\n","        f.extend(filenames)\n","        break\n","    loaders = []\n","    for filename in f:\n","        loaders.append(PyPDFLoader(file_path + filename))\n","    docs = []\n","    for loader in loaders:\n","        docs.extend(loader.load())\n","\n","    # semantic search\n","    # split loaded docs to chunks\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size = 500,\n","        chunk_overlap = 100\n","    )\n","    splits = text_splitter.split_documents(docs)\n","\n","    # embedding chunks\n","    # embedding models can change to other models,\n","    # e.g., 'sentence-transformers/all-mpnet-base-v2'\n","    embeddings = HuggingFaceEmbeddings(\n","    model_name=\"thenlper/gte-large\",\n","    model_kwargs={\"device\": \"cuda\"},\n","    encode_kwargs={\"normalize_embeddings\": True},\n",")\n","\n","    # create vector database for retrieval\n","    vectordb = Chroma.from_documents(\n","                    documents=splits,\n","                    embedding=embeddings)\n","    # search for top k and search type as maximum marginal relevance\n","    sm_retriever = vectordb.as_retriever(search_kwargs={\"k\": k},\n","                                         search_type=\"mmr\")\n","\n","   # keyword search\n","    keyword_retriever = BM25Retriever.from_documents(docs,\n","                         search_kwargs={\"k\": k})\n","\n","   # ensemble semantic search and keyword search\n","    ensemble_retriever = EnsembleRetriever(retrievers=[keyword_retriever,\n","                           sm_retriever], weights=[0.3, 0.7])\n","\n","\n","    # return sm_retriever\n","    return ensemble_retriever"],"metadata":{"id":"eiRtzw6GoGFB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Setting up HuggingFace Environment"],"metadata":{"id":"i2RhZdHBcKm8"}},{"cell_type":"code","source":["import os\n","os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""],"metadata":{"id":"QTErSxLAcX1B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.llms import LlamaCpp\n","from langchain.callbacks.manager import CallbackManager\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n","from huggingface_hub import hf_hub_download\n","from langchain.chains.question_answering import load_qa_chain"],"metadata":{"id":"zuxtL38oi_Ap"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Llama"],"metadata":{"id":"Hgs6swxlpK6j"}},{"cell_type":"code","source":["model_id = 'meta-llama/Llama-2-7b-chat-hf'\n","hf_auth = \"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\""],"metadata":{"id":"4K_1QAtFM81f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import cuda, bfloat16\n","import transformers\n","\n","model_id = 'meta-llama/Llama-2-7b-chat-hf'\n","\n","device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n","\n","# set quantization configuration to load large model with less GPU memory\n","# this requires the `bitsandbytes` library\n","bnb_config = transformers.BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type='nf4',\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=bfloat16\n",")\n","\n","# begin initializing HF items, you need an access token\n","hf_auth = \"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\"\n","model_config = transformers.AutoConfig.from_pretrained(\n","    model_id,\n","    use_auth_token=hf_auth\n",")\n","\n","model = transformers.AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    trust_remote_code=True,\n","    config=model_config,\n","    quantization_config=bnb_config,\n","    device_map='auto',\n","    use_auth_token=hf_auth\n",")\n","\n","# enable evaluation mode to allow model inference\n","model.eval()\n","\n","print(f\"Model loaded on {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":712,"referenced_widgets":["5af6508b2b6242c09a74c778026426c1","ccc6bd5917b64defbc531ce1bc3cb662","5d4ebffc7f344e369e0652fd51aa7cd2","6f96bd9626574cc1a16cebf5d29c1656","021570548da84292be1726eacc64afcf","5187f3b4689a4b268ea78ea2dff54e18","53e607d10654494a86b0b005c89512c2","c31f2c458db842cfa701706100dbe32e","e4767cd68ae841ecb656223d9a307bab","0b3b4e964b794595bd5f4d7dfdca0b90","e0851700aacd46158fa9390b194d30a4"]},"id":"CcDFY5aFWRlg","executionInfo":{"status":"ok","timestamp":1713041145326,"user_tz":420,"elapsed":75938,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"3321c208-c569-45b3-ef1e-9c809c629d34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py:1123: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","===================================BUG REPORT===================================\n","Welcome to bitsandbytes. For bug reports, please run\n","\n","python -m bitsandbytes\n","\n"," and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n","================================================================================\n","bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda122_nocublaslt.so\n","CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n","CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n","CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n","CUDA SETUP: Detected CUDA version 122\n","CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda122_nocublaslt.so...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('//172.28.0.1'), PosixPath('8013')}\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-v100-s-nl4vcvhxxxef --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n","  warn(msg)\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n","  warn(msg)\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5af6508b2b6242c09a74c778026426c1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"]},{"output_type":"stream","name":"stdout","text":["Model loaded on cuda:0\n"]}]},{"cell_type":"code","source":["tokenizer = transformers.AutoTokenizer.from_pretrained(\n","    model_id,\n","    use_auth_token=hf_auth\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nz21pHcjhYVG","executionInfo":{"status":"ok","timestamp":1713041552556,"user_tz":420,"elapsed":800,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"654347c3-c66a-49d4-c88d-96e6db44e375"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:732: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["stop_list = ['\\nHuman:', '\\n```\\n']\n","\n","stop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\n","stop_token_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A9kQD-d7hb5p","executionInfo":{"status":"ok","timestamp":1713041555934,"user_tz":420,"elapsed":740,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"477f7422-9c0d-42e6-ea90-034e03628ac9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 29871, 13, 29950, 7889, 29901], [1, 29871, 13, 28956, 13]]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import torch\n","\n","stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n","stop_token_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IGsoqjrVhf2M","executionInfo":{"status":"ok","timestamp":1713041557667,"user_tz":420,"elapsed":4,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"0b630d20-47b5-4421-957d-a8f0c54c11a7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([    1, 29871,    13, 29950,  7889, 29901], device='cuda:0'),\n"," tensor([    1, 29871,    13, 28956,    13], device='cuda:0')]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["from transformers import StoppingCriteria, StoppingCriteriaList\n","\n","# define custom stopping criteria object\n","class StopOnTokens(StoppingCriteria):\n","    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n","        for stop_ids in stop_token_ids:\n","            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n","                return True\n","        return False\n","\n","stopping_criteria = StoppingCriteriaList([StopOnTokens()])"],"metadata":{"id":"NxvP3bDRhjQz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_text = transformers.pipeline(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #return_full_text=True,  # langchain expects the full text\n","    task='text-generation',\n","    # we pass model parameters here too\n","    stopping_criteria=stopping_criteria,  # without this model rambles during chat\n","    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n","    max_new_tokens=1024,  # max number of tokens to generate in the output\n","    repetition_penalty=1.1  # without this output begins repeating\n",")"],"metadata":{"id":"uc-UOIiihm4X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","from langchain.chains import RetrievalQA\n","\n","    # Build prompt\n","template = \"\"\"\n","    [INST] <>\n","    Act as a helpful question answer assistant. Use the following information to answer the question at the end.\n","    <>\n","\n","    {context}\n","\n","    {question} [/INST]\n","\"\"\"\n","QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"],"metadata":{"id":"Iefaj__bCmyR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from langchain.llms import HuggingFacePipeline\n","\n","llm = HuggingFacePipeline(pipeline=generate_text)\n","query=\"what are the keywords mentioned in this paper\"\n","\n","    # build question answer chain\n","qa_chain = RetrievalQA.from_chain_type(\n","        llm,\n","        retriever=docs_retriever(query, k=10),\n","        chain_type=\"stuff\",\n","        return_source_documents=True,\n","        chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",")\n","\n","    # get answer and relevant documents\n","\n","result = qa_chain(query)\n","answer = result[\"result\"].strip()\n","rel_docs = result[\"source_documents\"]\n","\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cL__h-HD-rJv","executionInfo":{"status":"ok","timestamp":1713042257209,"user_tz":420,"elapsed":37743,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"81375762-e91e-478e-85fc-240e1fc36198"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The keywords mentioned in the paper are:\n","\n","1. Earthquake\n","2. Neural Network\n","3. Frequency\n","4. Structure\n","5. Building\n","\n","These keywords relate to the topic of the paper, which is the use of artificial neural networks to predict the response of structures subject to earthquake motions. The paper discusses how the neural network can be trained using a single real earthquake dataset and then used to simulate earthquakes with various intensities, and how the predicted responses can be used to evaluate the safety of structural systems in case of future earthquakes.\n"]}]},{"cell_type":"markdown","source":["# Questions and Answers"],"metadata":{"id":"3GTpubr71sLO"}},{"cell_type":"code","source":["questions = [\n","    \"What are the keywords mentioned in the paper titled Response Prediction of Structural System Subject to Earthquake Motions using Artificial Neural Network?\",\n","    \"What is the purpose of using Artificial Neural Networks in earthquake response prediction?\",\n","    \"How does the frequency of a building's natural frequency affect its response to an earthquake?\",\n","    \"What kind of neural network model is most frequently applied for modeling dynamic response of structures?\",\n","    \"How was the training of the ANN model conducted for predicting responses to various intensity earthquakes?\",\n","    \"What is the significance of the study's findings on predicting the safeness of structural systems?\"\n","]\n","\n","ground_truths = [\n","    \"The keywords written in the paper are: Earthquake, Neural Network, Frequency, Structure, Building.\",\n","    \"Artificial Neural Networks (ANNs) are used to compute the response of structural systems to Indian earthquakes and simulate various intensities of earthquakes. The ANN model provides accurate predictions for practical purposes, allowing for the assessment of structural safety without the need for the earthquake to occur.\",\n","    \"A building's response to an earthquake is dynamic and influenced by its natural frequency. If the ground shakes at the same frequency as the building's natural frequency, it causes resonance, leading to increased amplitude of sway and potential collapse due to the strain on building components.\",\n","    \"The most frequently applied neural network model for modeling the dynamic response of structures is the feedforward, multilayer, supervised neural network with error backpropagation algorithm, known as the BPN.\",\n","    \"The ANN model was trained using real earthquake data from the Chamoli and Uttarkashi earthquakes. The training involved using ground motion data to compute structural responses, which were then used to adjust the weights of the ANN for accurate future predictions.\",\n","    \"The study's findings demonstrate the ability of the trained ANN architecture to simulate and predict the response of a structural system to future earthquakes. This can be crucial in predicting the safety of structures and in taking pre-emptive measures to mitigate earthquake damage.\"\n","]\n","\n","contexts = []\n","\n","rag_answers = []\n","\n","possible_questions = [[]]"],"metadata":{"id":"TvjAQ_NG-ehy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from langchain.llms import HuggingFacePipeline\n","\n","llm = HuggingFacePipeline(pipeline=generate_text)\n","\n","for query in questions:\n","# build question answer chain\n","    qa_chain = RetrievalQA.from_chain_type(\n","            llm,\n","            retriever=docs_retriever(query, k=10),\n","            chain_type=\"stuff\",\n","            return_source_documents=True,\n","            chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n","    )\n","\n","        # get answer and relevant documents\n","\n","    result = qa_chain(query)\n","    answer = result[\"result\"].strip()\n","    rag_answers.append(answer)\n","    rel_docs = result[\"source_documents\"]\n","    rel_doc=[]\n","    for c in rel_docs:\n","        rel_doc.append(c.page_content)\n","    contexts.append(rel_doc)"],"metadata":{"id":"UL-Kh5jrRr01"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for query in questions:\n","    print(f\"\\n\\Question : {query}\")\n","    context=retrive_context(query)\n","    contexts.append(context)\n","    answer = chain.run(input_documents=retrieve_and_format_documents(query), question=query)\n","    rag_answers.append(answer)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9OWZB6Jk_RGr","executionInfo":{"status":"ok","timestamp":1713030775540,"user_tz":420,"elapsed":89942,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"d4f14343-f16e-46d7-da9d-017e187db339"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\\Question : What are the keywords mentioned in the paper titled Response Prediction of Structural System Subject to Earthquake Motions using Artificial Neural Network?\n","\n","\\Question : What is the purpose of using Artificial Neural Networks in earthquake response prediction?\n","\n","\\Question : How does the frequency of a building's natural frequency affect its response to an earthquake?\n","\n","\\Question : What kind of neural network model is most frequently applied for modeling dynamic response of structures?\n","\n","\\Question : How was the training of the ANN model conducted for predicting responses to various intensity earthquakes?\n","\n","\\Question : What is the significance of the study's findings on predicting the safeness of structural systems?\n"]}]},{"cell_type":"code","source":["possible_questions = [\n","    [\n","        \"What are the key keywords mentioned in the paper?\",\n","        \"Can you list the main topics or subject areas covered in the paper?\",\n","        \"What technical terms or concepts are referenced in the paper's keywords?\",\n","        \"Are there any notable keywords missing that you would expect to see in a paper on this topic?\",\n","        \"How do the keywords indicate the focus of the research presented in the paper?\"\n","    ],\n","    [\n","        \"What is the main purpose of using Artificial Neural Networks in this research?\",\n","        \"How are the ANN models trained and used to predict structural responses?\",\n","        \"What are the key capabilities of the ANN models described in the paper?\",\n","        \"How can the trained ANN models be used to assess the safety of structural systems?\",\n","        \"What are the benefits of using ANN-based approaches for earthquake response prediction?\"\n","    ],\n","    [\n","        \"How does a building's natural frequency affect its response to an earthquake?\",\n","        \"What happens when the ground shaking frequency is in resonance with the building's natural frequency?\",\n","        \"What factors determine a building's natural frequency?\",\n","        \"Why can resonance between ground shaking and building frequency lead to increased risk of damage or collapse?\",\n","        \"What is the relationship between a building's natural frequency and its response to earthquake motions?\"\n","    ],\n","    [\n","        \"What type of neural network model is most commonly used for modeling the dynamic response of structures?\",\n","        \"Can you describe the Back-Propagation Neural Network (BPN) and its application in this context?\",\n","        \"Why is the BPN model particularly well-suited for modeling the dynamic response of structures?\",\n","        \"Are there any other neural network architectures that have been explored for this application?\",\n","        \"What are the key advantages of the BPN model for predicting structural responses to earthquakes?\"\n","    ],\n","    [\n","        \"What data was used to train the ANN model for predicting earthquake responses?\",\n","        \"How was the ANN model trained and validated for different earthquake intensities?\",\n","        \"Can you describe the process of using the trained ANN architecture to predict structural responses over time?\",\n","        \"What were the key findings regarding the accuracy of the ANN model's predictions?\",\n","        \"Why is the Artificial Neural Network considered a powerful soft computing technique for this application?\"\n","    ],\n","    [\n","        \"What are the key implications of the study's findings on using ANN models for predicting structural safety?\",\n","        \"How does the training of the ANN model on Indian earthquake data contribute to its potential for accurate predictions?\",\n","        \"What are the benefits of being able to predict the safeness of structural systems in advance of an earthquake?\",\n","        \"How can the trained ANN model be used to simulate different earthquake intensities and study structural behavior?\",\n","        \"Why do the study's findings represent a promising approach for ensuring the safety of buildings and structures during earthquakes?\"\n","    ]\n","]"],"metadata":{"id":"ygvAfyhY5JRl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# To dict\n","data = {\n","    \"question\": questions,\n","    \"ground_truth\": ground_truths,\n","    \"rag_answer\": rag_answers,\n","    \"context\": contexts,\n","    \"possible_questions\": possible_questions\n","}\n","\n","# Convert dict to pandas df\n","dataset = pd.DataFrame(data)\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":342},"id":"O9b49FrsBC3A","executionInfo":{"status":"ok","timestamp":1713044231883,"user_tz":420,"elapsed":299,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"35d3335e-35d1-4b0a-8a4d-64af871b74f0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            question  \\\n","0  What are the keywords mentioned in the paper t...   \n","1  What is the purpose of using Artificial Neural...   \n","2  How does the frequency of a building's natural...   \n","3  What kind of neural network model is most freq...   \n","4  How was the training of the ANN model conducte...   \n","5  What is the significance of the study's findin...   \n","\n","                                        ground_truth  \\\n","0  The keywords written in the paper are: Earthqu...   \n","1  Artificial Neural Networks (ANNs) are used to ...   \n","2  A building's response to an earthquake is dyna...   \n","3  The most frequently applied neural network mod...   \n","4  The ANN model was trained using real earthquak...   \n","5  The study's findings demonstrate the ability o...   \n","\n","                                          rag_answer  \\\n","0  The keywords mentioned in the paper are:\\n\\n1....   \n","1  According to the text, the purpose of using Ar...   \n","2  When an earthquake occurs, the ground beneath ...   \n","3  According to the text, the most frequently app...   \n","4  The training of the ANN model for predicting r...   \n","5  The study's findings on predicting the safenes...   \n","\n","                                             context  \\\n","0  [Response Prediction of Structural System Subj...   \n","1  [intensities and it was found that the predict...   \n","2  [buildings have a \"natural frequency\" associat...   \n","3  [Neural Networks for seismic damage prediction...   \n","4  [intensities and it was found that the predict...   \n","5  [properties (mass and stiffness) of the struct...   \n","\n","                                  possible_questions  \n","0  [What are the key keywords mentioned in the pa...  \n","1  [What is the main purpose of using Artificial ...  \n","2  [How does a building's natural frequency affec...  \n","3  [What type of neural network model is most com...  \n","4  [What data was used to train the ANN model for...  \n","5  [What are the key implications of the study's ...  "],"text/html":["\n","  <div id=\"df-916cd617-5274-41b5-a7eb-784131c42d55\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>ground_truth</th>\n","      <th>rag_answer</th>\n","      <th>context</th>\n","      <th>possible_questions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What are the keywords mentioned in the paper t...</td>\n","      <td>The keywords written in the paper are: Earthqu...</td>\n","      <td>The keywords mentioned in the paper are:\\n\\n1....</td>\n","      <td>[Response Prediction of Structural System Subj...</td>\n","      <td>[What are the key keywords mentioned in the pa...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What is the purpose of using Artificial Neural...</td>\n","      <td>Artificial Neural Networks (ANNs) are used to ...</td>\n","      <td>According to the text, the purpose of using Ar...</td>\n","      <td>[intensities and it was found that the predict...</td>\n","      <td>[What is the main purpose of using Artificial ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>How does the frequency of a building's natural...</td>\n","      <td>A building's response to an earthquake is dyna...</td>\n","      <td>When an earthquake occurs, the ground beneath ...</td>\n","      <td>[buildings have a \"natural frequency\" associat...</td>\n","      <td>[How does a building's natural frequency affec...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What kind of neural network model is most freq...</td>\n","      <td>The most frequently applied neural network mod...</td>\n","      <td>According to the text, the most frequently app...</td>\n","      <td>[Neural Networks for seismic damage prediction...</td>\n","      <td>[What type of neural network model is most com...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>How was the training of the ANN model conducte...</td>\n","      <td>The ANN model was trained using real earthquak...</td>\n","      <td>The training of the ANN model for predicting r...</td>\n","      <td>[intensities and it was found that the predict...</td>\n","      <td>[What data was used to train the ANN model for...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>What is the significance of the study's findin...</td>\n","      <td>The study's findings demonstrate the ability o...</td>\n","      <td>The study's findings on predicting the safenes...</td>\n","      <td>[properties (mass and stiffness) of the struct...</td>\n","      <td>[What are the key implications of the study's ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-916cd617-5274-41b5-a7eb-784131c42d55')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-916cd617-5274-41b5-a7eb-784131c42d55 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-916cd617-5274-41b5-a7eb-784131c42d55');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-12e8dd79-61b2-4831-8b34-692e220ae70c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12e8dd79-61b2-4831-8b34-692e220ae70c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-12e8dd79-61b2-4831-8b34-692e220ae70c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_5e3e0550-995f-43bb-8472-9756380be912\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_5e3e0550-995f-43bb-8472-9756380be912 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('dataset');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"dataset","summary":"{\n  \"name\": \"dataset\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"What are the keywords mentioned in the paper titled Response Prediction of Structural System Subject to Earthquake Motions using Artificial Neural Network?\",\n          \"What is the purpose of using Artificial Neural Networks in earthquake response prediction?\",\n          \"What is the significance of the study's findings on predicting the safeness of structural systems?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"The keywords written in the paper are: Earthquake, Neural Network, Frequency, Structure, Building.\",\n          \"Artificial Neural Networks (ANNs) are used to compute the response of structural systems to Indian earthquakes and simulate various intensities of earthquakes. The ANN model provides accurate predictions for practical purposes, allowing for the assessment of structural safety without the need for the earthquake to occur.\",\n          \"The study's findings demonstrate the ability of the trained ANN architecture to simulate and predict the response of a structural system to future earthquakes. This can be crucial in predicting the safety of structures and in taking pre-emptive measures to mitigate earthquake damage.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rag_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"The keywords mentioned in the paper are:\\n\\n1. Earthquake\\n2. Neural Network\\n3. Frequency\\n4. Structure\\n5. Building\\n\\nThese keywords relate to the topic of the paper, which is the use of artificial neural networks to predict the response of structural systems subject to earthquake motions.\",\n          \"According to the text, the purpose of using Artificial Neural Networks (ANNs) in earthquake response prediction is to:\\n\\n1. Model the problem of dynamic response of a structure to strong earthquake ground motion.\\n2. Assess damage in structures using ANNs.\\n3. Predict the dynamic response of a structure for any other earthquake for a particular structure.\\n4. Identify the responses of a structural system well when the ANN is trained by a part of the ground motion data.\\n5. Evaluate the time period and the corresponding maximum response of a building for an earthquake.\\n6. Test the trained time period versus maximum response ANN model for real earthquake data of other places.\\n\\nBy using ANNs, researchers can predict the response of a structure to earthquakes without waiting for the earthquake to occur, which can help in predicting the safety of structural systems in case of future earthquakes.\",\n          \"The study's findings on predicting the safeness of structural systems using artificial neural networks (ANNs) have significant implications for the field of civil engineering and earthquake engineering. Here are some of the key takeaways:\\n\\n1. Accurate predictions: The study shows that ANNs can accurately predict the responses of structural systems to earthquakes, even when trained on a single real earthquake dataset. This suggests that ANNs can be a reliable tool for predicting the safeness of structural systems in the face of uncertain ground motions.\\n2. Time-efficient predictions: By training ANNs on a single earthquake dataset, the study demonstrates that it is possible to make predictions about the responses of structural systems to other earthquakes without waiting for the actual earthquake to occur. This can help engineers to make informed decisions about the safety of structural systems in a timely manner.\\n3. Robustness to variations: The study shows that ANNs can handle variations in the ground motion data and still produce accurate predictions of the structural system's response. This suggests that ANNs can provide robust predictions of structural system behavior under different earthquake scenarios.\\n4. Scalability: The study demonstrates that ANNs can be applied to small, medium, and large-scale structural systems, making them a versatile tool for predicting the safeness of structural systems across different scales.\\n5. Cost-effective: ANNs can provide cost-effective solutions for predicting the safeness of structural systems compared to traditional analytical methods, which often require extensive computational resources and expertise.\\n\\nOverall, the study's findings suggest that ANNs have the potential to revolutionize the field of earthquake engineering by providing fast, accurate, and cost-effective predictions of structural system behavior under different earthquake scenarios. These predictions can help engineers to design safer and more resilient structures, ultimately saving lives and reducing economic losses during earthquakes.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"possible_questions\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["contexts[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-2T9oEW8VyJu","executionInfo":{"status":"ok","timestamp":1713044243682,"user_tz":420,"elapsed":478,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"6fce120f-8371-4a4d-8aad-f83daa823ba8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Response Prediction of Structural System Subject to  Earthquake \\nMotions using Artificial Neural Network \\n \\nS. Chakraverty*,  T. Marwala** , Pallavi Gupta* and  Thando Tettey**  \\n \\n*B.P.P.P. Division, Central Building Research Institu te \\nRoorkee-247 667, Uttaranchal, India \\ne-mail :sne_chak@yahoo.com \\n \\n** School of Electrical and Information Engineering, \\nUniversity of the Witwatersrand, Private Bag 3 \\nWits, 2050,Republic of South Africa  \\n  \\nAbstract',\n"," 'Response Prediction of Structural System Subject to  Earthquake \\nMotions using Artificial Neural Network \\n \\nS. Chakraverty*,  T. Marwala** , Pallavi Gupta* and  Thando Tettey**  \\n \\n*B.P.P.P. Division, Central Building Research Institu te \\nRoorkee-247 667, Uttaranchal, India \\ne-mail :sne_chak@yahoo.com \\n \\n** School of Electrical and Information Engineering, \\nUniversity of the Witwatersrand, Private Bag 3 \\nWits, 2050,Republic of South Africa  \\n  \\nAbstract \\nThis paper uses Artificial Neural Network (ANN) models to compute response of \\nstructural system subject to Indian earthquakes at Chamoli and Uttarkashi \\nground motion data. The system is first trained for a si ngle real earthquake data. \\nThe trained ANN architecture is then used to simulate e arthquakes with various \\nintensities and it was found that the predicted responses given by ANN model \\nare accurate for practical purposes. When the ANN is trai ned by a part of the \\nground motion data, it can also identify the responses of the structural system \\nwell. In this way the safeness of the structural systems ma y be predicted in case \\nof future earthquakes without waiting for the earthq uake to occur for the lessons. \\nTime period and the corresponding maximum response of t he building for an \\nearthquake has been evaluated, which is again trained to predict the maximum \\nresponse of the building at different time periods. T he trained time period versus \\nmaximum response ANN model is also tested for real earth quake data of other \\nplace, which was not used in the training and was found to be in good \\nagreement.  \\n \\nKeywords : Earthquake, Neural Network, Frequency, Structure, Buil ding. \\n ',\n"," '[10] J .Zhao, J.N. Ivan, J.T. DeWolf, Structural damage  detection using artificial \\nneural networks. Journal of Infrastructure Systems (ASCE)  Vol.4, No.(3) \\n(1998) 93 – 101. \\n[11] Krystyna KuZniar, Zenon Waszczyszyn, Neural Simulat ion of Dynamic \\nResponse of Prefabricated Buildings Subjected to Parase ismic Excitations, \\nComputers and Structures,Vol. 81, No. 24-25 (2003) 235 3-2360 \\n[12] M.F. Elkordy, K.C. Chang, G.C. Lee, Neural netw orks trained by analytically \\nsimulated damage states. Journal of Computing in Civil Engineering (ASCE) \\nVol. 7, No.2 (1993) 130 – 145. \\n[13] N.S. Hadi Muhammad, Neural Networks Applications i n Concrete \\nStructures, Computers and Structures, Vol.81, No. 6 (20 03) 373-381 \\n[14] P.C. Pandey, S.V. Barai, Multilayer perceptron in damage detection of \\nbridge structures. Computers and Structures Vol. 54, No.4  (1995) 597- 608. \\n[15] Q. Chen, Y.W. Chan, K. Worden, Structural Fault  Diagnosis and Isolation \\nusing Neural Network Based on Response Only Data, Vol . 81, No. 22-23 \\n(2003) 2165 -2172 \\n[16] S.F. Masri, A.W. Smyth, A.G. Chassiakos, T.K. Caug hey, N.F. Hunter, \\nApplication of Neural networks for detection of changes i n nonlinear \\nsystems. Journal of Engineering Mechanics (ASCE), Vol. 126 , No.70 (2000) \\n666 – 676. \\n[17] S.L. Hung, C.Y. Kao, Structural Damage Detection  Using the Optimal \\nWeights of the Approximating Artificial Neural Networ ks, Earthquake \\nEngineering and Structural Dynamics,Vol. 31, No.2, (2 002) 217-  \\n[18] V.K. Mathur, S. Chakraverty and Pallavi Gupta,  Response Prediction of \\nTypical Rural House Subject to Earthquake Motions Using Artificial Neural \\nNetworks. Journal of Indian Building Congress, Vol.11, No.2 (2004) 99-105. \\n \\n \\n \\n ',\n"," \"applied a counter-propagation NN to locate damage in beams and frames. \\nKuZniar and Waszczyszyn [11] simulated the dynamic response for prefabricated \\nbuilding using ANN. Elkordy et al.[12] used a back-propa gation neural network \\nwith modal shapes in the input layer  to detect the sim ulated damage of \\nstructures. Muhammad [13] gives certain ANN applications in concrete \\nstructures. Pandey and Barai [14] detected damage in a bridge truss by applying \\nANN of multilayer perceptron architectures to numericall y simulated data. Some \\nstudies such as [15]-[17] used artificial neural network f or structural damage \\ndetection and system identification.  \\n \\nIn the present paper, the Chamoli earthquake ground acceleration at Barkot (NE) \\nand Uttarkashi earthquake ground acceleration recorded a t Barkot (NE and NW)  \\nhave been considered based on the authors' previous stud y [18]. From their \\nground acceleration the responses are computed using the u sual procedure. \\nThen the ground acceleration and the corresponding re sponse are trained using \\nArtificial Neural Network (ANN) with and without damp ing. After training the \\nnetwork with one earthquake, the converged weight mat rices are stored. In order \\nto show the power of these converged (trained) networ ks other earthquakes are \\nused as input to predict the direct response of the structu re without using any \\nmathematical analysis of the response prediction. Simi larly, the various time \\nperiods of one earthquake and its corresponding maximu m responses are \\ntrained. Then the converged weights are used to predict  the maximum response \\ndirectly to the corresponding time period. Various othe r results related to use of \\nthese trained networks are discussed for future / other e arthquakes. \\n \\n2 Artificial Neural Network  \\n \\nArtificial neural systems are present day machines that ha ve great potential to \\nimprove the quality of our life. Advances have been made in applying such \\nsystems for problems found difficult for traditional co mputation. A neural network \\nis a parallel, distributed information processing structur e consists of processing \\nelements called neurons, which are interconnected and u nidirectional signal \",\n"," 'for the other problem of time period vs. maximum resp onse the input and output \\nlayer contain the time period and the corresponding ma ximum response \\nrespectively at each interval for the particular structur e. \\n \\n5 Numerical Results and Discussions \\n \\nFor the present study two Indian earthquakes viz. the Chamoli Earthquake (max. \\nground acceleration =0.16885 m/sec/sec) at Barkot in NE (north–east) direction \\nshown in Fig.2(a) and the Uttarkashi earthquake  (maxi mum ground acceleration \\n= 0.931 m/sec/sec) at Barkot in NE (north–east) and NW ( north-west) direction \\nas given in Figs. 2(b) and 2(c) have been considered for  training and testing. \\n \\nInitially, the system without damping is studied and fo r that the ground \\nacceleration of Chamoli earthquake at Barkot (NE) was use d to compute the \\nresponse for single storey structure using usual procedure  from Eq.(3). The \\nobtained response and the ground acceleration is traine d first for the assumed \\nfrequency parameters ω=0.5 and ω=0.01 for time range 0 to 14.92 sec.(748 data \\npoints) for the mentioned earthquake. Simulations have  been done for different \\nhidden layer nodes and it was seen that the response re sult is almost same and \\ngood for 5 to 20 nodes in the hidden layer. However,  10 hidden layer nodes are \\nused here to generate further results. \\n \\nAfter training ground acceleration and response data fo r Chamoli earthquake at \\nBarkot (NE) for 10 nodes in hidden layer, the weights are stored and they are \\nused to predict responses for various intensity earthquakes.  The plot in Fig. 3(a) \\nshows response comparison between neural and desired for t he 80% of Chamoli \\nearthquake at Barkot (NE) for ω=0.01(maximum response=0.135079m/sec/sec). \\nSimilarly, the response comparison for 120% Chamoli ear thquake at Barkot (NE) \\nfor ω=0.5 (Maximum response=0.20260 m/sec/sec) is shown in Fig 3(b). \\n \\nNext, a part of the ground acceleration is used for the  training and it will be \\nshown that the present ANN can predict the whole perio d of the response using \\nthe trained ANN by the part of the data.  So, the g round acceleration and ']"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["dataset.to_csv('/content/drive/MyDrive/298A/m3_hybrid_rag_llama_output.csv', index=False)"],"metadata":{"id":"oflM9u9Pl-hx"},"execution_count":null,"outputs":[]}]}