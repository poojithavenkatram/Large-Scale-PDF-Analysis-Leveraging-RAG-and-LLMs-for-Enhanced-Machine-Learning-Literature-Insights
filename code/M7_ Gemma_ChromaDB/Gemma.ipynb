{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b3025dbaca5f4bf894bb1bf8d64984d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be1921f936ba4876ad3c5399ac5e1ade","IPY_MODEL_928c37b77d2a4be8bb645b1f712f6a16","IPY_MODEL_d271db2fc6bb4c57ac30c56bd0cc2b35"],"layout":"IPY_MODEL_41352b533e9445088378751b7bde8bae"}},"be1921f936ba4876ad3c5399ac5e1ade":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e7fef9e68a8409bb1bac83beda78a19","placeholder":"​","style":"IPY_MODEL_fc033489313a48b399d7c18a49b854df","value":"modules.json: 100%"}},"928c37b77d2a4be8bb645b1f712f6a16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_703020aa122340ddabf54e5d4a48fb56","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a9e2f1ac0764eebb34479542cf77d74","value":349}},"d271db2fc6bb4c57ac30c56bd0cc2b35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ace980795164adcaa1a14acec3ecef0","placeholder":"​","style":"IPY_MODEL_769ffca6c23c4c50bee23b50b50760b5","value":" 349/349 [00:00&lt;00:00, 20.1kB/s]"}},"41352b533e9445088378751b7bde8bae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e7fef9e68a8409bb1bac83beda78a19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc033489313a48b399d7c18a49b854df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"703020aa122340ddabf54e5d4a48fb56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a9e2f1ac0764eebb34479542cf77d74":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ace980795164adcaa1a14acec3ecef0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"769ffca6c23c4c50bee23b50b50760b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17472a3ba61248dbb41a23992f50cda8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bcc4a9c97b12450189d52948596f53e0","IPY_MODEL_a9fb91ea2b7643d4b8ec52bdbf27f2b3","IPY_MODEL_4546f29bff3f441d9f72e0bb5facd60a"],"layout":"IPY_MODEL_0a4b4ff2665d475e85f98a46503d2530"}},"bcc4a9c97b12450189d52948596f53e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49a710c7a333406682372c69042592f8","placeholder":"​","style":"IPY_MODEL_be51170574cc4473b8d6a1c2b1c9d9e7","value":"config_sentence_transformers.json: 100%"}},"a9fb91ea2b7643d4b8ec52bdbf27f2b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48be880bb38440ada70d4cbb0cb5608c","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffc5d234fe964bb19c66aac4a48dba1c","value":116}},"4546f29bff3f441d9f72e0bb5facd60a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d3c012f1ce343e78c9e64db86960805","placeholder":"​","style":"IPY_MODEL_71d50cd38f5f43daadc48b2c5d42b3b1","value":" 116/116 [00:00&lt;00:00, 8.54kB/s]"}},"0a4b4ff2665d475e85f98a46503d2530":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49a710c7a333406682372c69042592f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be51170574cc4473b8d6a1c2b1c9d9e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48be880bb38440ada70d4cbb0cb5608c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffc5d234fe964bb19c66aac4a48dba1c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d3c012f1ce343e78c9e64db86960805":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71d50cd38f5f43daadc48b2c5d42b3b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"058da4eba0d448a88b6597143150f4e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc7a34270c5d4a9eab6e7b1a01348b9e","IPY_MODEL_b573ae3747cc44748c31c388f3728d94","IPY_MODEL_1632ac9942d74534a07edf1b6d857fbc"],"layout":"IPY_MODEL_c98dc926a1fc4507945d4b20318dfb7f"}},"bc7a34270c5d4a9eab6e7b1a01348b9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b73708acb1e49ffa9bdfbb0b9d0b6fd","placeholder":"​","style":"IPY_MODEL_59e161804d0440aea288f3dff7147781","value":"README.md: 100%"}},"b573ae3747cc44748c31c388f3728d94":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b03b1c014994bda91a4c91300cbcb5c","max":10659,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04cd4ee58fb7401f98daae0c6ea759cb","value":10659}},"1632ac9942d74534a07edf1b6d857fbc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f40d43b67134bf3b0e753829c9ee7ba","placeholder":"​","style":"IPY_MODEL_fe97f7414628479c9c49bf564409c144","value":" 10.7k/10.7k [00:00&lt;00:00, 693kB/s]"}},"c98dc926a1fc4507945d4b20318dfb7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b73708acb1e49ffa9bdfbb0b9d0b6fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59e161804d0440aea288f3dff7147781":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b03b1c014994bda91a4c91300cbcb5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04cd4ee58fb7401f98daae0c6ea759cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f40d43b67134bf3b0e753829c9ee7ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe97f7414628479c9c49bf564409c144":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0cd2eed017b45bf855e96f0f53a0292":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f4ba4625e6d4109b81b1720cb183887","IPY_MODEL_8365601e5bff455db732d2d730d124e8","IPY_MODEL_eeb128ea61794f479ccd4b308c5fd089"],"layout":"IPY_MODEL_d0db0f7d4bd642bb9b59e1d0d3efdc05"}},"6f4ba4625e6d4109b81b1720cb183887":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12532b78d51a446a81fbcc43c6642c7e","placeholder":"​","style":"IPY_MODEL_86ed47ea1e1a46118875d0fe8c1ecefc","value":"sentence_bert_config.json: 100%"}},"8365601e5bff455db732d2d730d124e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba2b2f3134d447f4b4194b882641f968","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be8bef16954b4373bc15ad4fbce31409","value":53}},"eeb128ea61794f479ccd4b308c5fd089":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aedab3d50c74428a8d230eb1962cb787","placeholder":"​","style":"IPY_MODEL_8adc09eeb1414f97a144fd7b7fe686c3","value":" 53.0/53.0 [00:00&lt;00:00, 3.80kB/s]"}},"d0db0f7d4bd642bb9b59e1d0d3efdc05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12532b78d51a446a81fbcc43c6642c7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86ed47ea1e1a46118875d0fe8c1ecefc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba2b2f3134d447f4b4194b882641f968":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be8bef16954b4373bc15ad4fbce31409":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aedab3d50c74428a8d230eb1962cb787":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8adc09eeb1414f97a144fd7b7fe686c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b24ad2060a94ac5b7174e3f274082e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e26af0e5bda24d109d416769af678153","IPY_MODEL_8837983869a549c3b0d26098d40be568","IPY_MODEL_f7ce366a694944cd966329e40388731a"],"layout":"IPY_MODEL_47c18ce0df064ff0a67f83197a78c9bd"}},"e26af0e5bda24d109d416769af678153":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8188962d7a9b4332ab855a90dc386918","placeholder":"​","style":"IPY_MODEL_99dcbfaad7024d128ac3dbfcc6b6729d","value":"config.json: 100%"}},"8837983869a549c3b0d26098d40be568":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e14f3686ebfe4b248192ddeb54f90109","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7548f920290b4bb3a7f65059a4098323","value":612}},"f7ce366a694944cd966329e40388731a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2855ae198b1d4dc7a7b1823e7a4dc4b2","placeholder":"​","style":"IPY_MODEL_b74dfc5f7aa64508b01d1812ad1837d5","value":" 612/612 [00:00&lt;00:00, 42.8kB/s]"}},"47c18ce0df064ff0a67f83197a78c9bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8188962d7a9b4332ab855a90dc386918":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99dcbfaad7024d128ac3dbfcc6b6729d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e14f3686ebfe4b248192ddeb54f90109":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7548f920290b4bb3a7f65059a4098323":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2855ae198b1d4dc7a7b1823e7a4dc4b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b74dfc5f7aa64508b01d1812ad1837d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99cb4a6abb5c4f32b6b56556e221d374":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c597f2bf2c144388cb935b7fc98886d","IPY_MODEL_1d3c254c2300459aba27a2f12cdd2d61","IPY_MODEL_5376c197a69d43a8a47ed178b4e9ca39"],"layout":"IPY_MODEL_bd08b95150d54bada0202a7ab62a75aa"}},"0c597f2bf2c144388cb935b7fc98886d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e0980252cb14e2da54bfd4f0694617f","placeholder":"​","style":"IPY_MODEL_7c68cbf0f736417eadd5abe0981c1952","value":"model.safetensors: 100%"}},"1d3c254c2300459aba27a2f12cdd2d61":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_778fc6bd62df48d7bed33eebdc0618cb","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3c6f3f55f544c7085f658d6b9cb1f1b","value":90868376}},"5376c197a69d43a8a47ed178b4e9ca39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_792e548b09bc4196b21115f231ac9904","placeholder":"​","style":"IPY_MODEL_69911dea616f4ddbb78052716be8ece0","value":" 90.9M/90.9M [00:00&lt;00:00, 315MB/s]"}},"bd08b95150d54bada0202a7ab62a75aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e0980252cb14e2da54bfd4f0694617f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c68cbf0f736417eadd5abe0981c1952":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"778fc6bd62df48d7bed33eebdc0618cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3c6f3f55f544c7085f658d6b9cb1f1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"792e548b09bc4196b21115f231ac9904":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69911dea616f4ddbb78052716be8ece0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"641a01e61f3443ffa12e7d21c74cb4bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c950bb131c2d487190fae502caf75383","IPY_MODEL_ab48a4b0e7074985a4a46e0f93c5f4c0","IPY_MODEL_b5ad7dacd493488a88ca190aa8e4cdc1"],"layout":"IPY_MODEL_983fa0feac364be785b2cc0a3c7820a6"}},"c950bb131c2d487190fae502caf75383":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8087f30a5b3c43c9b2f3241bc134a9ce","placeholder":"​","style":"IPY_MODEL_17abc01f4d0248fb8e49911d518fab5d","value":"tokenizer_config.json: 100%"}},"ab48a4b0e7074985a4a46e0f93c5f4c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67402070b81f405780082b8af43fc956","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8984ee17c075402894b25a323aea6f21","value":350}},"b5ad7dacd493488a88ca190aa8e4cdc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4c0267483db455aa96be6252ffce1d2","placeholder":"​","style":"IPY_MODEL_db0a652a3846467f85eb9415cb9daa3d","value":" 350/350 [00:00&lt;00:00, 22.4kB/s]"}},"983fa0feac364be785b2cc0a3c7820a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8087f30a5b3c43c9b2f3241bc134a9ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17abc01f4d0248fb8e49911d518fab5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67402070b81f405780082b8af43fc956":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8984ee17c075402894b25a323aea6f21":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4c0267483db455aa96be6252ffce1d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db0a652a3846467f85eb9415cb9daa3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66d30ba0497644ffbe3e23e142b6d745":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9476ace05a044cb296d7e64f3748665e","IPY_MODEL_dc549af18f4d43a29d25a176cfad9ee6","IPY_MODEL_8093d38e474d4de481dc1d8307f5ecba"],"layout":"IPY_MODEL_b13092dadf9f460fa87880e95144aec9"}},"9476ace05a044cb296d7e64f3748665e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_093682a704e14c94b05f8bfa7a90cef5","placeholder":"​","style":"IPY_MODEL_e1468519cd4f482699163164f80e2e82","value":"vocab.txt: 100%"}},"dc549af18f4d43a29d25a176cfad9ee6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b07c28415b8d4bd59b5db234978e1441","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a3d364932ee4af98c86144928fe547d","value":231508}},"8093d38e474d4de481dc1d8307f5ecba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81b50a71ac024e0eaa33ae4ff1a9719d","placeholder":"​","style":"IPY_MODEL_256aaed596ee4e258fc83aa9077d9d96","value":" 232k/232k [00:00&lt;00:00, 583kB/s]"}},"b13092dadf9f460fa87880e95144aec9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"093682a704e14c94b05f8bfa7a90cef5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1468519cd4f482699163164f80e2e82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b07c28415b8d4bd59b5db234978e1441":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a3d364932ee4af98c86144928fe547d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"81b50a71ac024e0eaa33ae4ff1a9719d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"256aaed596ee4e258fc83aa9077d9d96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90d0e65b1eea472ca9c02f586c2c1a6d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa0b38d3d27748eeaaef3dfef0f0434e","IPY_MODEL_208c6e8414ee4fd08bfa729fc2606824","IPY_MODEL_4853b219a469482489c55859bdea57b6"],"layout":"IPY_MODEL_f612b9f6ac394c8599ad9595c0d0b8a9"}},"aa0b38d3d27748eeaaef3dfef0f0434e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32da0d8745d540b09f8949e49ea6173e","placeholder":"​","style":"IPY_MODEL_cf3893afbfcd4cc98aa88f07b920f37c","value":"tokenizer.json: 100%"}},"208c6e8414ee4fd08bfa729fc2606824":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5c5a026a75645d79442a0cc002ae5d5","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_487bc3ab287e4c68b7113c424ef70d9b","value":466247}},"4853b219a469482489c55859bdea57b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_393fc7b11f204b63b5881c905c34da68","placeholder":"​","style":"IPY_MODEL_dde47311ef7f43678e7e15b4a2e0f713","value":" 466k/466k [00:00&lt;00:00, 780kB/s]"}},"f612b9f6ac394c8599ad9595c0d0b8a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32da0d8745d540b09f8949e49ea6173e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf3893afbfcd4cc98aa88f07b920f37c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5c5a026a75645d79442a0cc002ae5d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"487bc3ab287e4c68b7113c424ef70d9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"393fc7b11f204b63b5881c905c34da68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dde47311ef7f43678e7e15b4a2e0f713":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e043c69c16e64aab9d351ee9c9d218af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea202f1aed8a47ccb8250251c31ad0ff","IPY_MODEL_a114f6e3d0424d58b4fb8bd9e7b60a8a","IPY_MODEL_37248f38e29942e28a3fd123885d3f2e"],"layout":"IPY_MODEL_cddfa46e8dd5416fb046b7ab284e8a38"}},"ea202f1aed8a47ccb8250251c31ad0ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b8e56ab1bf14d82a7aedd25fe26befe","placeholder":"​","style":"IPY_MODEL_4675e9b25a554d1fb4516cc1a7231c37","value":"special_tokens_map.json: 100%"}},"a114f6e3d0424d58b4fb8bd9e7b60a8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc79a35675c847d1b33a4807c243f819","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0260d2bdbf3d49f8a8706e7806119063","value":112}},"37248f38e29942e28a3fd123885d3f2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b129cfedc74f4ac78f7d89d7f6efc1ea","placeholder":"​","style":"IPY_MODEL_5b91991a8caa41848dfabc4f66fb7387","value":" 112/112 [00:00&lt;00:00, 9.47kB/s]"}},"cddfa46e8dd5416fb046b7ab284e8a38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b8e56ab1bf14d82a7aedd25fe26befe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4675e9b25a554d1fb4516cc1a7231c37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc79a35675c847d1b33a4807c243f819":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0260d2bdbf3d49f8a8706e7806119063":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b129cfedc74f4ac78f7d89d7f6efc1ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b91991a8caa41848dfabc4f66fb7387":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0154561a5bca4ed0807784b9ec819cb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e136781afa6c4d72be73adc84ed02840","IPY_MODEL_9dc908f3ff87487183bad33ed5316652","IPY_MODEL_db638c934e1848159e4c69066c211c61"],"layout":"IPY_MODEL_8f969fd7427245c7ac76759600578555"}},"e136781afa6c4d72be73adc84ed02840":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7883ab05e178497f8bdd0f0a0dda9421","placeholder":"​","style":"IPY_MODEL_39dab1edc0be44139358b4799931963d","value":"1_Pooling/config.json: 100%"}},"9dc908f3ff87487183bad33ed5316652":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c13fd168c36449d9942b282c4556081a","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_058d4db5c7794ad2adeeaca2cc427ac5","value":190}},"db638c934e1848159e4c69066c211c61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bfff8132fff44cfa329d1362fd2acfb","placeholder":"​","style":"IPY_MODEL_f45c1e7317d34102946fb04d261f6a57","value":" 190/190 [00:00&lt;00:00, 9.17kB/s]"}},"8f969fd7427245c7ac76759600578555":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7883ab05e178497f8bdd0f0a0dda9421":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39dab1edc0be44139358b4799931963d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c13fd168c36449d9942b282c4556081a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"058d4db5c7794ad2adeeaca2cc427ac5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1bfff8132fff44cfa329d1362fd2acfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f45c1e7317d34102946fb04d261f6a57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AfEW4xYu7dzZ","outputId":"153b4d46-01da-459c-b660-fdf01ca8af99"},"outputs":[{"output_type":"stream","name":"stdout","text":[">>> Downloading ollama...\n","############################################################################################# 100.0%\n",">>> Installing ollama to /usr/local/bin...\n",">>> Adding ollama user to video group...\n",">>> Adding current user to ollama group...\n",">>> Creating ollama systemd service...\n","WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",">>> The Ollama API is now available at 127.0.0.1:11434.\n",">>> Install complete. Run \"ollama\" from the command line.\n"]}],"source":["!curl -fsSL https://ollama.com/install.sh|sh"]},{"cell_type":"code","source":["!pip install langchain_community"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2KNijLs70VC","outputId":"fb6080bf-b962-4cf1-9afd-f210a7742c75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain_community\n","  Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.29)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n","Collecting langchain-core<0.2.0,>=0.1.41 (from langchain_community)\n","  Downloading langchain_core-0.1.42-py3-none-any.whl (287 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n","  Downloading langsmith-0.1.46-py3-none-any.whl (111 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.5/111.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.2.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.41->langchain_community)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.41->langchain_community)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.41->langchain_community) (2.6.4)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n","  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.11.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.41->langchain_community)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.41->langchain_community) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.41->langchain_community) (2.16.3)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain_community\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.0\n","    Uninstalling packaging-24.0:\n","      Successfully uninstalled packaging-24.0\n","Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.42 langchain_community-0.0.32 langsmith-0.1.46 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","source":["from langchain_community.llms import Ollama"],"metadata":{"id":"hNC1L9rE9vs1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm = Ollama(model=\"gemma:7b\")"],"metadata":{"id":"TzvMESBc95S9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm.invoke(\"Whats an AI\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"EDEK_UtW-HjG","outputId":"0cc1bd32-e8ea-46c3-fa7b-bc38a6c1d112"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'**AI (Artificial Intelligence)** is the ability of a computer or machine to perform tasks that typically require human intelligence, such as:\\n\\n* Learning and adapting from experience\\n* Understanding and generating language\\n* Solving problems and making decisions\\n* Performing tasks that require creativity or physical interaction\\n\\n**Key characteristics of AI include:**\\n\\n* **Learning:** AI systems can gather and analyze data to improve their performance over time.\\n* **Adaptability:** AI systems can adjust to changing situations and environments.\\n* **Reasoning:** AI systems can analyze information and make logical conclusions.\\n* **Creativity:** AI systems can generate new ideas and solutions to problems.\\n* **Reactivity:** AI systems can respond to changes in the environment and interact with users.\\n\\n**Types of AI:**\\n\\n* **Narrow AI:** Designed for specific tasks, such as playing chess or recognizing faces.\\n* **General AI:** Aims to mimic human intelligence in all its aspects.\\n* **Super AI:** Hypotheothetical AI that surpasses human intelligence in all areas.\\n\\n**Applications of AI:**\\n\\n* Healthcare: Disease diagnosis, drug discovery, personalized medicine\\n* Finance: Fraud detection, risk assessment, automated trading\\n* Education: Personalized tutoring, language translation\\n* Transportation: Autonomous vehicles, traffic optimization\\n* Customer service: Chatbots, virtual assistants\\n\\n**Advantages of AI:**\\n\\n* Increased efficiency and productivity\\n* Automation of tasks, freeing humans for more creative and strategic work\\n* Improved decision-making\\n* Personalized and tailored experiences\\n* Continuous learning and adaptation\\n\\n**Disadvantages of AI:**\\n\\n* Job displacement concerns\\n* Ethical and privacy issues\\n* Bias and discrimination in algorithms\\n* Lack of human understanding and empathy\\n* Potential for unintended consequences'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["#Prev Coding part"],"metadata":{"id":"BuTLVQql-O3m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pymupdf  # For PDF processing with PyMuPDF (fitz)\n","!pip install sentence-transformers  # For converting text to vectors\n","!pip install faiss-cpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwJDH3MS-lqX","outputId":"b1239da6-f11c-43e6-f82e-003cb8087e8d","executionInfo":{"status":"ok","timestamp":1713412571228,"user_tz":420,"elapsed":90034,"user":{"displayName":"Sourabh Suresh Kumar","userId":"10736442423101870194"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pymupdf\n","  Downloading PyMuPDF-1.24.2-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyMuPDFb==1.24.1 (from pymupdf)\n","  Downloading PyMuPDFb-1.24.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\n","Successfully installed PyMuPDFb-1.24.1 pymupdf-1.24.2\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.7.0\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n","Installing collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.8.0\n"]}]},{"cell_type":"code","source":["!pip install -q -U torch immutabledict sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"giMiEytc-3yV","outputId":"27a5ece8-f97b-4f54-be0f-5e43e140f09e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\n","torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\n","torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["\n","import PyPDF2\n","\n","\n","pdf_path = '/content/paper_185.pdf'\n","\n","# Open the PDF file\n","try:\n","    with open(pdf_path, 'rb') as file:\n","        reader = PyPDF2.PdfReader(file)\n","\n","        # Initialize a list to hold the text of each page\n","        pdf_text = []\n","\n","        # Iterate over each page in the PDF\n","        for page in reader.pages:\n","            text = page.extract_text()\n","            if text:\n","                pdf_text.append(text)\n","            else:\n","                pdf_text.append(\"\")  # Append an empty string if no text is found\n","\n","        # Optionally print or process the extracted text\n","        for page_text in pdf_text:\n","            print(page_text)\n","\n","except FileNotFoundError:\n","    print(\"The file was not found. Check your file path.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljIxGNxc_A7H","outputId":"1ea3cb77-044a-4170-f6db-4cbc5e88bb88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Journal of Machine Learning Research 22 (2021) 1-30 Submitted 9/20; Revised 3/21; Published 5/21\n","Finite-sample Analysis\n","of Interpolating Linear Classi\fers\n","in the Overparameterized Regime\n","Niladri S. Chatterji chatterji@berkeley.edu\n","University of California, Berkeley, 366 LeConte Hall, Berkeley, CA 94720\n","Philip M. Long plong@google.com\n","Google, 1600 Amphitheatre Parkway, Mountain View, CA 94043\n","Editor: Samory Kpotufe\n","Abstract\n","We prove bounds on the population risk of the maximum margin algorithm for two-class\n","linear classi\fcation. For linearly separable training data, the maximum margin algorithm\n","has been shown in previous work to be equivalent to a limit of training with logistic loss\n","using gradient descent, as the training error is driven to zero. We analyze this algorithm\n","applied to random data including misclassi\fcation noise. Our assumptions on the clean\n","data include the case in which the class-conditional distributions are standard normal\n","distributions. The misclassi\fcation noise may be chosen by an adversary, subject to a\n","limit on the fraction of corrupted labels. Our bounds show that, with su\u000ecient over-\n","parameterization, the maximum margin algorithm trained on noisy data can achieve nearly\n","optimal population risk.\n","Keywords: high-dimensional statistics, classi\fcation, class-conditional Gaussians, \fnite-\n","sample analysis, risk bounds\n","1. Introduction\n","A surprising statistical phenomenon has emerged in modern machine learning: highly com-\n","plex models can interpolate training data while still generalizing well to test data, even\n","in the presence of label noise. This is rather striking as it the goes against the grain of\n","the classical statistical wisdom which dictates that predictors that generalize well should\n","trade o\u000b between the \ft to the training data and the some measure of the complexity\n","or smoothness of the predictor. Many estimators like neural networks, kernel estimators,\n","nearest neighbour estimators, and even linear models have been shown to demonstrate this\n","phenomenon (see, Zhang et al., 2017; Belkin et al., 2019a, among others).\n","This phenomenon has recently inspired intense theoretical research. One line of work\n","(Soudry et al., 2018; Ji and Telgarsky, 2019; Gunasekar et al., 2017; Nacson et al., 2019;\n","Gunasekar et al., 2018b,a) formalized the argument (Neyshabur et al., 2014; Neyshabur,\n","2017) that, even when there is no explicit regularization that is used in training these rich\n","models, there is nevertheless implicit regularization encoded in the choice of the optimization\n","method used. For example, in the setting of linear classi\fcation, Soudry et al. (2018), Ji\n","and Telgarsky (2019) and Nacson et al. (2019) show that learning a linear classi\fer using\n","gradient descent on the unregularized logistic or exponential loss asymptotically leads the\n","c\r2021 Niladri S. Chatterji and Philip M. Long.\n","License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/ . Attribution requirements are provided\n","athttp://jmlr.org/papers/v22/20-974.html .\n","Chatterji and Long\n","solution to converge to the maximum `2-margin classi\fer. More concretely, given nlinearly\n","separable samples ( xi;yi)n\n","j=1, wherexi2Rpare the features and yi2f\u0000 1;1g, the iterates\n","of gradient descent (initialized at the origin) are given by,\n","v(t+1):=v(t)\u0000\u000brRlog(v(t)) whereRlog(v) :=nX\n","i=1log (1 + exp (\u0000yi(v\u0001xi))):\n","They show that in the large- tlimit the normalized predictor obtained by gradient descent\n","v(t)=kv(t)kconverges to w=kwkwhere,\n","w= argmin\n","u2Rpkuk; (1)\n","such that, yi(u\u0001xi)\u00151;for alli2[n]:\n","That is,wis the maximum `2-margin classi\fer over the training data.\n","The question still remains, though, why do these maximum margin classi\fers generalize\n","well beyond the training set, despite the fact that they \\\ft the noise\"? The fact that p>n\n","renders traditional distribution-free bounds (Cover, 1965; Vapnik, 1982) vacuous. Due to\n","the presence of label noise, margin bounds (Vapnik, 1995; Shawe-Taylor et al., 1998) are\n","also not an obvious answer.\n","In this paper, we prove an upper bound on the misclassi\fcation test error for the max-\n","imum margin linear classi\fer, and therefore on the the limit of gradient descent on the\n","training error without any complexity penalty. Our analysis holds under a natural and\n","fairly general generative model for the data. One special case is where adversarial label\n","noise (see Kearns et al., 1994; Kalai et al., 2008; Klivans et al., 2009; Awasthi et al., 2017;\n","Talwar, 2020) is added to data in which the positive examples are distributed as N(\u0016;I)\n","and the negative examples are distributed N(\u0000\u0016;I). Ifk\u0016kis not too small, the clean\n","data will consist of overlapping but largely separate clouds of points. Our assumptions are\n","weaker than this, however (see Section 2 for the details). They are satis\fed by the case\n","in which misclassi\fcation noise is added to the generative model underlying Fisher's linear\n","discriminant (see Duda et al., 2012; Hastie et al., 2009) (except that, to make the analysis\n","cleaner, the distribution is shifted so that the origin is halfway between the class-conditional\n","means). They also include as special cases the rare-weak model (Donoho and Jin, 2008; Jin,\n","2009) and a Boolean variant (Helmbold and Long, 2012). We study the overparameterized\n","regime, when the dimension pis signi\fcantly greater than the number nof samples. For a\n","precise statement of our main result see Theorem 1. After its statement, we give examples\n","of its consequences, including cases in which sof thepvariables are relevant, but weakly\n","associated with the class designations. In some cases where s,pandnare polynomially\n","related, the risk of the maximum-margin algorithm approaches the Bayes-optimal risk as\n","e\u0000n\u001c, for\u001c >0.\n","Analysis of classi\fcation is hindered by the fact that, in contrast to regression, there is\n","no known simple expression for the parameters as a function of the training data. Our anal-\n","ysis leverages recent results, mentioned above, that characterize the weight vector obtained\n","by minimizing the logistic loss on training data (Soudry et al., 2018; Ji and Telgarsky,\n","2019; Nacson et al., 2019). We use this result not only to motivate the analysis of the\n","maximum margin algorithm, but also in our proofs, to get a handle on the relationship\n","2\n","Interpolating Linear Classifiers\n","Figure 1: Plot of the test error (solid, blue) and train error (dashed, red) versus the di-\n","mension of the covariates p. The number of samples n= 100 is kept \fxed. The\n","dimensionpis varied in the interval [100 ;3000]. The data is generated according\n","to the Boolean noisy rare-weak model (see Section 2). First, a clean label ~ yis\n","drawn by randomly \ripping a fair coin. The covariates xare drawn conditioned\n","on ~y. The \frst 100 attributes, ( x1;:::;x 100) are equal to the clean label ~ ywith\n","probability 0 :7, the remaining attributes ( x101;:::;xp) are either\u00001 or 1 with\n","equal probability. The noisy label sample yis generated by \ripping the true label\n","~ywith probability \u0011= 0:05. The classi\fer is the maximum `2-margin classi\fer\n","de\fned in Equation (1). The plot is generated by averaging over 500 draws of\n","the samples. The train error on all runs was always 0.\n","of this solution to the training data. When learning in the presence of label noise, algo-\n","rithms that minimize a convex loss face the hazard that mislabeled examples can exert an\n","outsized in\ruence. However, we show that in the over-parameterized regime this e\u000bect is\n","ameliorated. In particular, we show that the ratio between the (exponential) losses of any\n","two examples is bounded above by an absolute constant. One special case of our upper\n","bounds is where there are relatively few relevant variables, and many irrelevant variables.\n","In this case, classi\fcation using only parameters that correctly classify the clean examples\n","with a large margin leads to large loss on examples with noisy class labels. However, the\n","training process can use the parameters on irrelevant variables to play a role akin to slack\n","variables, allowing the algorithm to correctly classify incorrectly labeled training examples\n","with limited harm on independent test data. On the other hand, if there are too many\n","irrelevant variables, accurate classi\fcation is impossible (Jin, 2009). Our bounds re\rect\n","3\n","Chatterji and Long\n","this reality|if the number of irrelevant variables increases while the number and quality of\n","the relevant variables remains \fxed, ultimately our bounds degrade.\n","In simulation experiments, we see a decrease in population risk with the increase of p\n","beyondn, as observed in previous double-descent papers, but this is followed by an increase.\n","As mentioned above, Jin (2009) showed that, under certain conditions, if the number pof\n","attributes and the number sof relevant attributes satisfy p\u0015s2, then, in a sense, learning\n","is impossible. Our experiments suggest that interpolation with logistic loss can succeed\n","close to this boundary, despite the lack of explicit regularization or feature selection.\n","1.1 Related Work\n","A number of recent papers have focused on bounding the asymptotic error of overparam-\n","eterized decision rules. Hastie et al. (2019) and Muthukumar et al. (2020b) studied the\n","asymptotic squared error of the interpolating ordinary least squares estimator for the prob-\n","lem of overparameterized linear regression. This was followed by Mei and Montanari (2019)\n","who characterize the asymptotic error of the OLS estimator in the random features model.\n","As we do, Montanari et al. (2019) studied linear classi\fcation, calculating a formula for the\n","asymptotic test error of the maximum margin classi\fer in the overparameterized setting\n","when the features are generated from a Gaussian distribution and the labels are generated\n","from a logistic link function. This was followed by the work of Liang and Sur (2020) who\n","calculate a formula for the asymptotic test error of the maximum `1-margin classi\fer in the\n","same setting. Deng et al. (2020) independently obtained related results, including analysis\n","of the case where the marginal distribution over the covariates is a mixture of Gaussians,\n","one for each class. Previously, Cand\u0012 es and Sur (2020); Sur and Cand\u0012 es (2019) studied the\n","asymptotic test error for this problem in the underparameterized regime (when p<n ). In\n","contrast with this previous work, we provide \fnite-sample bounds.\n","There has also been quite a bit of work on the non-asymptotic analysis of interpolating\n","estimators. Liang and Rakhlin (2020) provided a \fnite-sample upper bound the expected\n","squared error for kernel \\ridgeless\" regressor, which interpolates the training data. Kobak\n","et al. (2020) provided an analysis of linear regression that emphasized the role of irrele-\n","vant variables as providing placeholders for learning parameters that play the role of slack\n","variables. Belkin et al. (2020) provided a \fnite-sample analysis of interpolating least-norm\n","regression with feature selection. They showed that, beyond the point where the number\n","of features included in the model exceeds the number of training examples, the excess risk\n","decreases with the number of included features. This analysis considered the case that the\n","covariates have a standard normal distribution. They also obtained similar results for a\n","\\random features\" model. Bartlett et al. (2020) provided non-asymptotic upper and lower\n","bounds on the squared error for the OLS estimator; their analysis emphasized the e\u000bect\n","of the covariance structure of the independent variables on the success or failure of this\n","estimator. This earlier work studied regression; here we consider classi\fcation. Study of\n","regression is facilitated by the fact that the OLS parameter vector has a simple closed-form\n","expression as a function of the training data. Belkin et al. (2018) studied the generalization\n","error for a simplicial interpolating nearest neighbor rule. Belkin et al. (2019b) provided\n","bounds on the generalization error for the Nadaraya-Watson regression estimator applied\n","to a singular kernel, a method that interpolates the training data. Liang et al. (2020) pro-\n","4\n","Interpolating Linear Classifiers\n","vided upper bounds on the population risk for the least-norm interpolant applied to a class\n","of kernels including the Neural Tangent Kernel.\n","In concurrent independent work, Muthukumar et al. (2020a) studied the generalization\n","properties of the maximum margin classi\fer in the case where the marginal distribution on\n","the covariates is a single Gaussian, rather than a Gaussian per class. They showed that, in\n","this setting, if there is enough overparameterization, every example is a support vector, so\n","that the maximum margin algorithm outputs the same parameters as the OLS algorithm.\n","They also showed that the accuracy of the model, measured using the 0-1 test loss, can be\n","much better than its accuracy with respect to the quadratic loss.\n","Additional related work is described in Section 6.\n","2. De\fnitions, Notation and Assumptions\n","Throughout this section, C > 0 and 0< \u0014 < 1 denote absolute constants. We will show\n","that any choice Cthat is large enough relative to 1 =\u0014will work.\n","We study learning from independent random examples ( x;y)2Rp\u0002f\u0000 1;1gsampled\n","from a joint distribution P. This distribution may be viewed as a noisy variant of another\n","distribution ~Pwhich we now describe. A sample from ~Pmay be generated by the following\n","process.\n","1. First, a clean label ~ y2f\u0000 1;1gis generated by \ripping a fair coin.\n","2. Next,q2Rpis sampled from Q:=Q1\u0002\u0001\u0001\u0001\u0002 Qp, which is an arbitrary product\n","distribution over Rp\n","\u000fwhose marginals are all zero-mean sub-Gaussians with sub-Gaussian norm at\n","most 1 (see De\fnition 12), and\n","\u000fsuch that Eq\u0018Q[kqk2]\u0015\u0014p.\n","3. For an arbitrary unitary matrix Uand\u00162Rp,x=Uq+ ~y\u0016. This ensures that the\n","mean ofxis\u0016when ~y= 1 and is\u0000\u0016when ~y=\u00001.\n","4. Finally, noise is modeled as follows. For 0 \u0014\u0011\u00141=C,Pis an arbitrary distribution\n","overRp\u0002f\u0000 1;1g\n","\u000fwhose marginal distribution on Rpis the same as ~P, and\n","\u000fsuch thatdTV(P;~P)\u0014\u0011.\n","Note that this de\fnition includes the special case where yis obtained from ~ yby\n","\ripping it with probability \u0011.\n","Choosing a bound of 1 on the sub-Gaussian norm of the components of Q\fxes the scale of\n","the data. This simpli\fes the proofs without materially a\u000becting the analysis, since rescaling\n","the data does not a\u000bect the accuracy of the maximum margin algorithm.\n","Let (x1;y1);:::; (xn;yn) bentraining examples drawn according to P. Let\n","S:=f(x1;y1);:::; (xn;yn)g:\n","5\n","Chatterji and Long\n","WhenSis linearly separable, let w2Rpminimizekwksubject toy1(w\u0001x1)\u00151;:::;yn(w\u0001\n","xn)\u00151. (In the setting that we analyze, we will show that, with high probability, Sis\n","linearly separable. When it is not, wmay be chosen arbitrarily.)\n","We will provide bounds on the misclassi\fcation probability of the classi\fer parameterized\n","bywthat can be achieved with probability 1 \u0000\u000eover the draw of the samples.\n","We make the following assumptions on the parameters of the problem:\n","(A.1) the failure probability satis\fes 0 \u0014\u000e<1=C,\n","(A.2) number of samples satis\fes n\u0015Clog(1=\u000e),\n","(A.3) the dimension satis\fes p\u0015Cmaxfk\u0016k2n;n2log(n=\u000e)g,\n","(A.4) the norm of the mean satis\fes k\u0016k2\u0015Clog(n=\u000e).\n","Here are some examples of generative models that fall within our framework.\n","Example 1 (Gaussian class-conditional model) The clean labels ~yare drawn by \rip-\n","ping a fair coin. The distribution on x, after conditioning on the value of ~y, isN(~y\u0016;\u0006),\n","for\u0006withk\u0006k\u00141andk\u0006\u00001k\u00141=\u0014(herek\u0006kis the matrix operator norm).\n","Example 2 (Noisy rare-weak model) A special case of the model described above is\n","when \u0006 =Iand the mean vector \u0016is such that only scomponents are non-zero and all\n","non-zero entries are equal to \r2R.\n","Donoho and Jin (2008) studied this model in the noise-free case (i.e. where \u0011= 0).\n","Example 3 (Boolean noisy rare-weak model) Our assumptions are also satis\fed1by\n","the following setting with Boolean attributes.\n","\u000f~y2f\u0000 1;1gis generated \frst, by \ripping a fair coin.\n","\u000fFor\r2(0;1=2), the components of x2Rpare conditionally independent given ~y:\n","x1;:::;xsare equal to ~ywith probability 1=2 +\r,xs+1;:::;xpare equal to ~ywith\n","probability 1=2.\n","\u000fyis obtained from ~yby \ripping it with probability \u0011.\n","The noiseless setting of this model was studied by Helmbold and Long (2012).\n","3. Main Result and Its Consequences\n","Our main result is a \fnite-sample bound on the misclassi\fcation error of the maximum\n","margin classi\fer.\n","Theorem 1 For all 0< \u0014 < 1, there is an absolute constant c >0such that, under the\n","assumptions of Section 2, for all large enough C, with probability 1\u0000\u000e, training onS\n","produces a maximum margin classi\fer wsatisfying\n","P(x;y)\u0018P[sign(w\u0001x)6=y]\u0014\u0011+ exp\u0012\n","\u0000ck\u0016k4\n","p\u0013\n",":\n","1. Strictly speaking, xneeds to be scaled down to make the sub-Gaussian norm less than 1 for this to be\n","true, but this does not a\u000bect the accuracy of the maximum margin classi\fer.\n","6\n","Interpolating Linear Classifiers\n","Consider the scenario where the number of samples nis a constant, but where the\n","number of dimensions pandk\u0016kare growing. Then our assumptions require k\u0016k2=O(p).2\n","But, for the misclassi\fcation error to decrease we need k\u0016k4=!(p). Thus if,k\u0016k=\n","\u0002(p\f) for any\f2(1=4;1=2] then asp!1 , the misclassi\fcation error asymptotically will\n","approach the noise level \u0011.\n","Here are the implications of our results in the noisy rare-weak model. Recall that in\n","this model \u0016is non-zero only on scoordinates and the non-zero coordinates of \u0016are equal\n","to some\r. Therefore,k\u0016k2=\r2s.\n","Corollary 2 There is an absolute constant c>0such that, under the assumptions of Sec-\n","tion 2, in the noisy rare-weak model, for any \r\u00150and all large enough C, with probability\n","1\u0000\u000e, training onSproduces a maximum margin classi\fer wsatisfying\n","P(x;y)\u0018P[sign(w\u0001x)6=y]\u0014\u0011+ exp\u0012\n","\u0000c\r4s2\n","p\u0013\n",":\n","Next, let us examine the implications of our results in the Boolean noisy rare-weak model.\n","Here,k\u0016k2= 4\r2s.\n","Corollary 3 There is an absolute constant c > 0such that, under the assumptions of\n","Section 2, in the Boolean noisy rare-weak model for any 0<\r < 1=2and all large enough\n","C, with probability 1\u0000\u000e, training onSproduces a maximum margin classi\fer wsatisfying\n","P(x;y)\u0018P[sign(w\u0001x)6=y]\u0014\u0011+ exp\u0012\n","\u0000c\r4s2\n","p\u0013\n",":\n","To gain some intuition let us explore the scaling of the misclassi\fcation error in these\n","problems in di\u000berent scaling limits for the parameters in both these problems.\n","Consider a case where, \u000e,\randnare constants and sandpgrow. Our assumptions hold\n","ifk\u0016k2=\r2s=O(p). But for the misclassi\fcation error to decrease we need s2=!(p). So\n","ifs= \u0002(p\f) where,\f2(1=2;1] then the misclassi\fcation error scales as \u0011+ exp(\u0000cp2\f\u00001)\n","and asymptotically approaches \u0011.\n","Jin (2009) showed that for the noiseless rare-weak model learning is impossible when\n","s=O(pp) andnis a constant. Our upper bounds show that, in a sense, the maximum\n","margin classi\fer succeeds arbitrarily close to this threshold.\n","Another interesting scenario is when \u000eand\rare constants while both sandpgrow as a\n","function of the number of samples n. Letp= \u0002(n2+\u001a) ands= \u0002(n1+\u0015), for positive \u001aand\n","\u0015. Our assumptions are satis\fed if \u001a>\u0015 for large enough n, while, for the misclassi\fcation\n","error to reduce with nwe need 2\u0015>\u001a . Asngets larger the bound on the misclassi\fcation\n","error scales as \u0011+exp(\u0000cn2\u0015\u0000\u001a) and gets arbitrarily close to \u0011for large enough n. Informally,\n","if the adversary fully expends its noise budget, the Bayes error rate will be at least \u0011; this\n","is true in particular in the case where labels are \ripped with probability \u0011. In such cases,\n","even if one could prove that the training data likely to be separated by a large margin,\n","the bound of Theorem 1 approaches the Bayes error rate faster than the standard margin\n","bounds (Vapnik, 1995; Shawe-Taylor et al., 1998).\n","2. The de\fnitions of \\big Oh notation\", i.e. O(\u0001),!(\u0001), \u0002( \u0001);\n","( \u0001), may be found in (Cormen et al., 2009).\n","7\n","Chatterji and Long\n","4. Proof of Theorem 1\n","First, we may assume without loss of generality that U=I. To see this, note that\n","\u000fifwis the maximum margin classi\fer for ( x1;y1);:::; (xn;yn) thenUwis the maxi-\n","mum margin classi\fer for ( Ux1;y1);:::; (Uxn;yn), and\n","\u000fthe probability that y(w\u0001x)<0 is the same as the probability that y(Uw\u0001Ux)<0.\n","Let us assume from now on that U=I.\n","Our \frst lemma is an immediate consequence of the coupling lemma (Lindvall, 2002;\n","Daskalakis, 2011) that allows us to handle the noise in the samples.\n","Lemma 4 There is a joint distribution on ((x;y);(~x;~y))such that\n","\u000fthe marginal on (x;y)isP,\n","\u000fthe marginal on (~x;~y)is~P,\n","\u000fP[x= ~x] = 1 , and\n","\u000fP[y6= ~y]\u0014\u0011.\n","De\fnition 5 Let(x1;y1;~y1);:::; (xn;yn;~yn)beni.i.d. draws from the coupling of Lemma 4,\n","with the redundant ~x1;:::; ~xnthrown out. Let Nbe the setfk:yk6= ~ykgof indices of\n","\\noisy\" examples, and C=fk:yk= ~ykgbe the indices of \\clean\" examples.\n","Note that Lemma 4 implies that ( x1;y1);:::; (xn;yn) areni.i.d. draws from P, as before.\n","The next lemma is bound on the misclassi\fcation error in terms of the expected value\n","of the margin on clean points, E(x;~y)\u0018P[~y(w\u0001x)] =\u0016\u0001w, and the norm of the classi\fer w.\n","Lemma 6 There is an absolute positive constant csuch that\n","P(x;y)\u0018P[sign(w\u0001x)6=y]\u0014\u0011+ exp\u0012\n","\u0000c(\u0016\u0001w)2\n","kwk2\u0013\n",":\n","Proof Observe that\n","P(x;y)\u0018P[sign(w\u0001x)6=y] =P(x;y)\u0018P[y(w\u0001x)<0]:\n","For a draw x;y;~yfrom the coupling of Lemma 4, we have\n","P[y(w\u0001x)<0]\u0014\u0011+P[y(w\u0001x)<0 andy= ~y]\n","=\u0011+P[~y(w\u0001x)<0]:\n","Fori\u0014p, theith component of ~ yxis distributed as a \u0016i+qi, where the qi\u0018Qiis a mean\n","zero random variable. Thus E[~y(w\u0001x)] =w\u0001\u0016, so\n","P[~y(w\u0001x)<0] =P[~y(w\u0001x)\u0000E[~y(w\u0001x)]<\u0000\u0016\u0001w]\n","=P[w\u0001(~yx\u0000E[~yx])<\u0000\u0016\u0001w]:\n","An application of the general Hoe\u000bding's inequality (see Theorem 13) upper bounds this\n","probability and completes the proof.\n","In light of the previous lemma, next we prove a high probability lower bound on the expected\n","margin on a clean point, \u0016\u0001w.\n","8\n","Interpolating Linear Classifiers\n","Lemma 7 For all 0<\u0014< 1, there is an absolute positive constant csuch that, for all large\n","enoughC, with probability 1\u0000\u000eover the random choice of S, it is linearly separable, and\n","the maximum margin weight vector wsatis\fes,\n","\u0016\u0001w\u0015kwkk\u0016k2\n","cpp:\n","Given these two main lemmas above, the main theorem follows immediately.\n","Proof (of Theorem 1): Combine the result of Lemma 6 with the lower bound on ( \u0016\u0001w)\n","established in Lemma 7.\n","It remains to prove Lemma 7, a lower bound on the expected margin on clean points\n","(\u0016\u0001w). This crucial lemma is proved through a series of auxiliary lemmas, which use a\n","characterization of the maximum margin classi\fer win terms of iterates fv(t)g1\n","t=1of gradient\n","descent on the exponential loss. Denote the risk associated with the exponential loss3as\n","R(v) :=nX\n","k=1exp (\u0000ykv\u0001xk):\n","Then the iterates of gradient descent are de\fned as follows:\n","\u000fv(0):= 0, and\n","\u000fv(t+1):=v(t)\u0000\u000brR(v(t)),\n","where\u000bis a constant step-size.\n","Lemma 8 (Soudry et al., 2018, Theorem 3) For any linearly separable Sand for all\n","small enough step-sizes \u000b, we have\n","w\n","kwk= lim\n","t!1v(t)\n","kv(t)k:\n","De\fnition 9 For each index kof an example, let zk:=ykxk.\n","Most of the argument required to prove Lemma 6 is deterministic apart from some standard\n","concentration arguments, which are gathered in the following lemma. (Recall that, since\n","we are in the process of proving Theorem 1, the assumptions of Section 2 are in scope.)\n","Lemma 10 For all\u0014 >0, there is a c\u00151such that, for all c0>0, for all large enough\n","C, with probability 1\u0000\u000eover the draw of the samples the following events simultaneously\n","3. We could also work with the logistic loss here, but the proofs are simpler if we work with the exponential\n","loss without changing the conclusions.\n","9\n","Chatterji and Long\n","occur:\n","For allk2[n];p\n","c\u0014kzkk2\u0014cp: (2)\n","For alli6=j2[n];jzi\u0001zjj<c(k\u0016k2+p\n","plog(n=\u000e)): (3)\n","For allk2C;j\u0016\u0001zk\u0000k\u0016k2j<k\u0016k2=2: (4)\n","For allk2N;j\u0016\u0001zk\u0000(\u0000k\u0016k2)j<k\u0016k2=2: (5)\n","The number of noisy samples satis\fes jNj\u0014 (\u0011+c0)n: (6)\n","The samples are linearly separable. (7)\n","The proof of this lemma is in Appendix A.\n","From here on, we will assume that Ssatis\fes all the conditions shown to hold with high\n","probability in Lemma 10.\n","A concern is that, late in training, noisy examples will have outsized e\u000bect on the\n","classi\fer learned. Lemma 11 below limits the extent to which this can be true. It shows\n","that throughout the training process the loss on any one example is at most a constant\n","factor larger than the loss on any other example. This is su\u000ecient since the gradient of the\n","exponential loss\n","rR(v) =\u0000nX\n","k=1zkexp(\u0000zk\u0001v);\n","is the sum of the \u0000zkvalues weighted by their losses. We also know that with high prob-\n","abilityp=c\u0014kzkk\u0014cp, therefore, showing that the loss on a sample is within a constant\n","factor of the loss of any other sample controls the in\ruence that any one point can have on\n","the learning process. We formalize this intuition in the proof of Lemma 7 in the sequel.\n","As will be clear in the proof of Lemma 11, the high dimensionality of the classi\fer ( p\n","being larger than k\u0016k2nandn2log(n=\u000e)) is crucial in showing that the ratio of the losses\n","between any pair of points is bounded. Here is some rough intuition why this is the case.\n","For the sake of intuition consider the extreme scenario where all the vectors zkare\n","mutually orthogonal and kzik=p, for alli2[n]. Then in this case, the change in the loss\n","of a sample i2[n] due to each gradient descent update will be independent of any other\n","samplej6=i2[n] and all the losses will decrease exactly at the same rate. Lemma 10\n","implies that, when pis large enough relative to k\u0016k, thezkvectors are nearly pairwise\n","orthogonal. In this case, the losses remain within a constant factor of one another.\n","Lemma 11 There is an absolute constant csuch that, for all large enough C, and all small\n","enough step sizes \u000b, for all iterations t\u00150,\n","Amax\n","t:= max\n","k;`2S(\n","exp(\u0000v(t)\u0001zk)\n","exp(\u0000v(t)\u0001z`))\n","\u0014c:\n","ProofAmax\n","tis the maximum ratio between a pair of samples at iteration t. Letc1be the\n","constantc\u00151 from Lemma 10. We will prove that Amax\n","t\u00144c2\n","1for allt\u00150 by using an\n","inductive argument over the iterations t.\n","10\n","Interpolating Linear Classifiers\n","Let us begin by establishing this for the base case, when t= 0. Since the gradient descent\n","algorithm is initialized at the origin, the loss for any sample j2[n] is exp(\u00000\u0001zj) = 1.\n","Therefore,Amax\n","0= 1<4c2\n","1.\n","Assume that the inductive hypothesis holds for some iteration t, we shall now prove\n","that then it must also hold at iteration t+ 1.\n","To simplify notation we shall analyze the ratio between the losses on the \frst and the\n","second sample but a similar analysis holds for any distinct pair. Let Gtbe the loss on\n","samplez1and letHtbe the loss on sample z2at thetthiteration. De\fne At:=Gt=Htto\n","be the ratio of the losses at iteration t.\n","By the de\fnition of v(t+1)as the gradient descent iterate\n","At+1=exp\u0000\n","\u0000v(t+1)\u0001z1\u0001\n","exp\u0000\n","\u0000v(t+1)\u0001z2\u0001\n","=exp\u0000\n","\u0000(v(t)\u0000\u000brR(v(t)))\u0001z1\u0001\n","exp\u0000\n","\u0000(v(t)\u0000\u000brR(v(t)))\u0001z2\u0001\n","=exp\u0000\n","\u0000v(t)\u0001z1\u0001\n","exp\u0000\n","\u0000v(t)\u0001z2\u0001\u0001exp(\u000brR(v(t))\u0001z1)\n","exp(\u000brR(v(t))\u0001z2)\n","=At\u0001exp(\u0000\u000bP\n","j2[n]zj\u0001z1exp(\u0000v(t)\u0001zj))\n","exp(\u0000\u000bP\n","j2[n]zj\u0001z2exp(\u0000v(t)\u0001zj))\n","=At\u0001exp(\u0000\u000bkz1k2Gt)\n","exp(\u0000\u000bkz2k2Ht)exp(\u0000\u000bP\n","j>1zj\u0001z1exp(\u0000v(t)\u0001zj))\n","exp(\u0000\u000bP\n","j6=2zj\u0001z2exp(\u0000v(t)\u0001zj)):\n","Recalling that c1is the constant cfrom Lemma 10, by (2), we have\n","p\n","c1\u0014kzik2\u0014c1p; for alli2[n];\n","and (3) gives\n","jzi\u0001zjj<c1(k\u0016k2+p\n","plog(n=\u000e));for alli6=j2[n]:\n","These, combined with the the expression for At+1above, give\n","At+1\n","=At\u0001exp(\u0000\u000bkz1k2Gt+\u000bkz2k2Ht)\u0001exp(\u0000\u000bP\n","j>1zj\u0001z1exp(\u0000v(t)\u0001zj))\n","exp(\u0000\u000bP\n","j6=2zj\u0001z2exp(\u0000v(t)\u0001zj))\n","\u0014Atexp\u0012\n","\u0000\u000bp\u0012Gt\n","c1\u0000c1Ht\u0013\u0013\n","exp0\n","@2\u000bc1(k\u0016k2+p\n","plog(n=\u000e))X\n","j2[n]exp(\u0000v(t)\u0001zj)1\n","A\n","which implies\n","At+1\n","\u0014Atexp\u0012\n","\u0000\u000bHtp\n","c1\u0000\n","At\u0000c2\n","1\u0001\u0013\n","exp0\n","@2\u000bc1(k\u0016k2+p\n","plog(n=\u000e))X\n","j2[n]exp(\u0000v(t)\u0001zj)1\n","A:(8)\n","11\n","Chatterji and Long\n","Consider two disjoint cases.\n","Case 1 (At\u00142c2\n","1):Using Inequality (8)\n","At+1\u0014Atexp\u0012\n","\u0000\u000bHtp\n","c1(At\u0000c2\n","1)\u0013\n","exp0\n","@2\u000bc1(k\u0016k2+p\n","plog(n=\u000e))X\n","j2[n]exp(\u0000v(t)\u0001zj)1\n","A\n","\u0014Atexp (c1\u000bHtp) exp0\n","@2\u000bc1(k\u0016k2+p\n","plog(n=\u000e))X\n","j2[n]exp(\u0000v(t)\u0001zj)1\n","A\n","(i)\n","\u0014Atexp (c1\u000bpn) exp\u0010\n","2\u000bc1(k\u0016k2+p\n","plog(n=\u000e))n\u0011\n","=Atexp\u0010\n","\u000b(c1p+ 2c1(k\u0016k2+p\n","plog(n=\u000e)))n\u0011\n","(ii)\n","\u00142c2\n","1exp(1=8)<4c2\n","1\n","where (i) follows since the sum of the losses on all samples is always smaller than the initial\n","loss which is n(see Lemma 22) and Ht\u0014n, while, (ii) follows as the step-size may be\n","chosen to be at most (8 c1(p+ 2(k\u0016k2+p\n","plog(n=\u000e))k\u0016k2)n)\u00001.\n","Case 2 (At>2c2\n","1) :Reusing Inequality (8),\n","At+1\u0014Atexp\u0012\n","\u0000\u000bHtp\n","c1\u0000\n","At\u0000c2\n","1\u0001\u0013\n","exp0\n","@2\u000bc1(k\u0016k2+p\n","plog(n=\u000e))X\n","j2[n]exp(\u0000v(t)\u0001zj)1\n","A\n","=Atexp\u0012\n","\u0000\u000bHtp\n","c1\u0000\n","At\u0000c2\n","1\u0001\u0013\n","exp0\n","@2\u000bc1(k\u0016k2+p\n","plog(n=\u000e))HtX\n","j2[n]exp(\u0000v(t)\u0001zj)\n","Ht1\n","A\n","\u0014Atexp\u0012\n","\u0000\u000bHtp\n","c1\u0000\n","At\u0000c2\n","1\u0001\u0013\n","exp\u0010\n","8\u000bc3\n","1(k\u0016k2+p\n","plog(n=\u000e))Htn\u0011\n","(by the IH)\n","=Atexp\u0012\n","\u0000\u000bHt\u0012p\n","c1\u0000\n","At\u0000c2\n","1\u0001\n","\u00008c3\n","1(k\u0016k2+p\n","plog(n=\u000e))n\u0013\u0013\n","\u0014Atexp\u0010\n","\u0000\u000bHt\u0010\n","c1p\u00008c3\n","1(k\u0016k2+p\n","plog(n=\u000e))n\u0011\u0011\n",":\n","Sincep > Ck\u0016k2andp > Cn2log(n=\u000e), and noting that Lemma 10 is consistent with C\n","being arbitrarily large while c1remains \fxed, we have that, in this case, At+1\u0014At(as the\n","term in the exponent is non-positive). This completes the proof of the inductive step in\n","this case, and therefore the entire proof.\n","4.1 Proof of Lemma 7\n","Armed with Lemma 11, we now prove Lemma 7.\n","Let us proceed assuming that the event de\fned in Lemma 10 occurs, and, in this proof,\n","letc1be the constant cfrom that lemma. We know that this event occurs with probability\n","at least 1\u0000\u000e.\n","12\n","Interpolating Linear Classifiers\n","We have\n","\u0016\u0001v(t+1)=\u0016\u0001v(t)+\u000bnX\n","k=1(\u0016\u0001zk) exp\u0010\n","\u0000v(t)\u0001zk\u0011\n",":\n","Dividing the sum into the clean and noisy examples, we have\n","\u0016\u0001v(t+1)=\u0016\u0001v(t)+\u000bX\n","k2C(\u0016\u0001zk) exp\u0010\n","\u0000v(t)\u0001zk\u0011\n","(9)\n","+\u000bX\n","k2N(\u0016\u0001zk) exp\u0010\n","\u0000v(t)\u0001zk\u0011\n",":\n","Combining (4), (5) and (9) we infer\n","\u0016\u0001v(t+1)\u0015\u0016\u0001v(t)+k\u0016k2\u000b\n","2X\n","k2Cexp\u0010\n","\u0000v(t)\u0001zk\u0011\n","\u00003k\u0016k2\u000b\n","2X\n","k2Nexp\u0010\n","\u0000v(t)\u0001zk\u0011\n","=\u0016\u0001v(t)+k\u0016k2\n","2\u000bR(v(t))\u00002k\u0016k2\u000bX\n","k2Nexp\u0010\n","\u0000v(t)\u0001zk\u0011\n",": (10)\n","SincejNj\u0014 (\u0011+c0)n, wherec0is an arbitrarily small constant, if c2is the constant from\n","Lemma 11, we have\n","X\n","k2Nexp\u0010\n","\u0000v(t)\u0001zk\u0011\n","\u0014c2(\u0011+c0)nmin\n","kexp\u0010\n","\u0000v(t)\u0001zk\u0011\n","\u0014c2(\u0011+c0)R(v(t))\u0014R(v(t))=4;\n","since\u0011\u00141=C. Thus Inequality (10) implies\n","\u0016\u0001v(t+1)\u0015\u0016\u0001v(t)+k\u0016k2\u000b\n","4R(v(t)):\n","Unrolling this via an induction yields\n","\u0016\u0001v(t+1)\u0015\u000bk\u0016k2\n","4tX\n","m=0R(v(m)) (since v(0)= 0).\n","Now let us multiply both sides by kwk=kvt+1k\n","kwk\u0016\u0001v(t+1)\n","kv(t+1)k\u0015kwk\u000bk\u0016k2Pt\n","m=0R(v(m))\n","4kv(t+1)k:\n","Next, let us take the large- tlimit. Applying Lemma 8 to the left hand side,\n","\u0016\u0001w\u0015\u000bkwkk\u0016k2lim\n","t!1Pt\n","m=0R(v(m))\n","4kv(t+1)k: (11)\n","13\n","Chatterji and Long\n","By de\fnition of the gradient descent iterates\n","kv(t+1)k=\r\r\r\r\rtX\n","m=0\u000brR(v(m))\r\r\r\r\r\n","\u0014\u000btX\n","m=0krR(v(m))k\n","=\u000btX\n","m=0\r\r\r\r\rnX\n","k=1zkexp(\u0000v(m)\u0001zk)\r\r\r\r\r\n","\u0014\u000btX\n","m=0nX\n","k=1exp(\u0000v(m)\u0001zk)kzkk\n","\u0014\u000bc1pptX\n","m=0R(v(m)):\n","This together with Inequality (11) yields\n","\u0016\u0001w\u0015kwkk\u0016k2\n","4c1pp;\n","completing the proof.\n","5. Simulations\n","We experimentally study the behavior of the maximum margin classi\fer in the overparame-\n","terized regime on synthetic data generated according to the Boolean noisy rare-weak model.\n","Recall that this is a model where the clean label ~ y2f\u0000 1;1gis \frst generated by \ripping a\n","fair coin. Then the covariate xis drawn from a distribution conditioned on ~ ysuch thatsof\n","the coordinates of xare equal to ~ ywith probability 1 =2 +\rand the other p\u0000scoordinates\n","are random and independent of the true label. The noisy label yis obtained by \ripping\n","~ywith probability \u0011. In this section the \ripping probability \u0011is always 0 :1. In all our\n","experiments the number of samples nis kept constant at 100.\n","In the \frst experiment in Figure 2 we hold nand the number of relevant attributes s\n","constant and vary the dimension pfor di\u000berent values of \r. We \fnd that after an initial\n","dip in the test error (for \r= 0:2;0:3) the test error starts to rise slowly with p, as in our\n","upper bounds.\n","Next, in Figure 3 we explore the scaling of the test error with the number of relevant\n","attributesswhennandpare held constant. As we would expect, the test error decreases\n","assgrows for all the di\u000berent values of \r.\n","Finally, in Figure 4 we study how the test error changes when both pandsare increasing\n","whennand\rare held constant. Our results (see Corollary 3) do not guarantee learning\n","whens= \u0002(pp) (and Jin (2009) proved that learning is impossible in a related setting,\n","even in the absence of noise); we \fnd that the test error remains constant in our experiment\n","in this setting. In the cases when s=p0:55and whens=p0:65, slightly beyond this thresh-\n","old, the test error approaches the Bayes-optimal error as pgets large in our experiment.\n","14\n","Interpolating Linear Classifiers\n","Figure 2: Plot of the test error versus the dimension of the covariates pfor di\u000berent values\n","of\r. The number of samples n= 100 and the number of relevant variables s= 50\n","are both kept \fxed. The dimension pis varied in the interval [100 ;3000]. The data\n","is generated according to the Boolean noisy rare-weak model. The dotted olive\n","green line represents the noise level (10%). The plot is generated by averaging\n","over 500 draws of the samples. The train error on all runs was always 0.\n","This provides experimental evidence that the maximum margin algorithm, without explicit\n","regularization or feature selection, even in the presence of noise, learns with using a number\n","of relevant variables near the theoretical limit of what is possible for any algorithm. (Note\n","that, as emphasized by Helmbold and Long, 2012, the fraction of relevant variables is going\n","to zero aspincreases in these experiments.)\n","6. Additional Related Work\n","Ng and Jordan (2002) compared the Naive Bayes algorithm, which builds a classi\fer from es-\n","timates of class-conditional distributions using conditional independence assumptions, with\n","discriminative training of a logistic regressor. Their main point is that Naive Bayes con-\n","verges faster. Our analysis provides a counterpoint to theirs, showing that, for a reasonable\n","data distribution that includes label noise, in the overparameterized regime, unregularized\n","discriminative training with a commonly used loss function learns a highly accurate classi\fer\n","from a constant number of examples.\n","Analysis of learning with class-conditional Gaussians with the same covariance structure\n","has been extensively studied in the case that the number nof training examples is greater\n","than the number pof parameters (see Anderson, 2003). When p\u001dn, Bickel and Levina\n","(2004) showed that, even when the class-conditional distributions do not have diagonal\n","covariance matrices, behaving as if they are can lead to improved classi\fcation accuracy.\n","15\n","Chatterji and Long\n","Figure 3: Plot of the test error versus the number of relevant attributes sfor di\u000berent values\n","of\r. The number of samples n= 100 and the dimension p= 500 are both kept\n","\fxed. The dimension sis varied in the interval [100 ;500]. The data is generated\n","according to the Boolean noisy rare-weak model. The dotted olive green line\n","represents the noise level (10%). The plot is generated by averaging over 500\n","draws of the samples. The train error on all runs was always 0.\n","The model that we use is a generalization of the rare-weak model studied by Donoho and Jin\n","(2008) (see Section 2 for details of our set-up). The class-conditional distributions studied\n","there have a standard multivariate normal distribution, while our results hold for a more\n","general class of sub-Gaussian class-conditional distributions. More importantly, in order to\n","address the experimental \fndings of Zhang et al. (2017), we have have also supplemented\n","the rare-weak model to include label noise. Finite-sample bounds for algorithms using `1\n","penalties, again, in the absence of label noise have been obtained (Cai and Liu, 2011; Li\n","et al., 2015; Li and Jia, 2017; Cai and Zhang, 2019). Dobriban and Wager (2018) studied\n","regularized classi\fcation in the asymptotic framework where pandngo to in\fnity together.\n","Fan and Fan (2008) and Jin (2009) proved that learning with class-conditional Gaussians is\n","impossible when too few variables are associated with the class designations. Our analysis\n","shows that, even in the presence of misclassi\fcation noise, in a sense, the maximum-margin\n","algorithm succeeds up to the edge of the frontier established by one of the results by\n","Jin (2009). Nagarajan and Kolter (2019) used a data distribution like the distributions\n","considered here, but to analyze limitations of uniform convergence tools.\n","The framework studied here also includes as a special case the setting studied by Helm-\n","bold and Long (2012), with Boolean attributes; again, a key modi\fcation is the addition\n","of misclassi\fcation noise. Also, while the upper bounds of Helmbold and Long (2012) are\n","for algorithms that perform unweighted votes over selected attributes, here we consider the\n","maximum margin algorithm. A more re\fned analysis of learning with conditionally indepen-\n","16\n","Interpolating Linear Classifiers\n","Figure 4: Plot of the test error versus the dimension (p) for di\u000berent scalings of swithp.\n","The number of samples n= 100 and\r= 0:1 are both held \fxed. The dimension\n","pis varied in the interval [100 ;3000]. The data is generated according to the\n","Boolean noisy rare-weak model. The dotted olive green line represents the noise\n","level (10%). The plot is generated by averaging over 500 draws of the samples.\n","The train error on all runs was always 0.\n","dent Boolean attributes was carried out by Berend and Kontorovich (2015). Kleindessner\n","and Awasthi (2018) studied learning with conditionally independent Boolean attributes in\n","the presence of noise|they analyzed tasks other than classi\fcation, including estimating\n","the degree of association between the attributes (viewed in that work as experts) and the\n","true class designations.\n","As mentioned above, we consider the case that the data is corrupted with label noise.\n","We consider adversarial label noise (Kearns et al., 1994; Kalai et al., 2008; Klivans et al.,\n","2009; Awasthi et al., 2017; Talwar, 2020). In this model, an adversary is allowed to change\n","the classi\fcations of an arbitrary subset of the domain whose probability is \u0011, while leaving\n","the marginal distribution on the covariates unchanged. It includes as a special case the\n","heavily studied situation in which classi\fcations are randomly \ripped with probability \u0011\n","(Angluin and Laird, 1988; Kearns, 1998; Cesa-Bianchi et al., 1999; Servedio, 1999; Kalai\n","and Servedio, 2005; Long and Servedio, 2010; Van Rooyen et al., 2015) along with variants\n","that allow limited dependence of the probability that a label is corrupted on the clean\n","example (Lugosi, 1992; Natarajan et al., 2013; Scott et al., 2013; Cannings et al., 2020).\n","Adversarial label noise allows for the possibility that noise is concentrated in a part of the\n","domain, where noisy examples have greater potential to coordinate their e\u000bects; it is a\n","weaker assumption than even Massart noise (Massart and N\u0013 ed\u0013 elec, 2006; Blanchard et al.,\n","2008; Awasthi et al., 2015; Diakonikolas et al., 2019), which requires a separate limit on the\n","conditional probability of an incorrect label, given any clean example. We show that, with\n","17\n","Chatterji and Long\n","su\u000ecient overparameterization, even in the absence of regularity in the noise, the algorithm\n","that simply minimizes the standard softmax loss without any explicit regularization enjoys\n","surprisingly strong noise tolerance.\n","After a preliminary version of this paper was posted on arXiv (Chatterji and Long,\n","2020), some related work was published (Wang and Thrampoulidis, 2020; Hsu et al., 2021;\n","Liang and Recht, 2021).\n","7. Discussion\n","Even in the presence of misclassi\fcation noise, with su\u000ecient overparameterization, unreg-\n","ularized minimization of the logistic loss produces accurate classi\fers when the clean data\n","has well-separated sub-Gaussian class-conditional distributions.\n","We have analyzed the case of a linear classi\fer without a bias term. In the setting\n","studied here, the Bayes-optimal classi\fer has a bias term of zero, and adding analysis\n","of a bias term in the maximum margin classi\fer would complicate the analysis without\n","signi\fcantly changing the results.\n","In the noisy rare-weak model, when pandsscale favorably with n, and\ris a constant,\n","the excess risk of the maximum margin algorithm decreases very rapidly with n. One\n","contributing cause is a \\wisdom of the crowds\" e\u000bect that is present when classifying with\n","conditionally independent attributes: a classi\fer can be very accurate, even when the angle\n","between its normal vector and the optimum is not very small. For example, if 100 experts\n","each predict a binary class, and they are correct independently with probability 3 =4, a vote\n","over their predictions remains over 95% accurate even if we \rip the votes of 25 of them.\n","(Note that, even in some cases where Lemma 7 implies accuracy very close to optimal, it\n","may not imply that the cosine of the angle between \u0016andwis anywhere near 1.) On the\n","other hand, the concentration required for successful generalization is robust to departures\n","from the conditional independence assumption. Our assumptions already allow substantial\n","class-conditional dependence among the attributes, but it may be interesting to explore\n","even weaker assumptions.\n","We note that a bound on the accuracy of the maximum margin classi\fer with respect\n","to the distribution ~Pwithout any label noise is implicit in our analysis. (The bound is the\n","same as Theorem 1, but without the \u0011.)\n","Our bounds show that the maximum margin classi\fer approaches the Bayes risk as\n","the parameters go to in\fnity in various ways. It would be interesting to characterize the\n","conditions under which this happens. A related question is to prove lower bounds in terms\n","of the parameters of the problem. Another is to prove bounds for \fnite pandnunder\n","weaker conditions.\n","We assume that the distributions of x\u0000\u0016andx\u0000(\u0000\u0016) are the same. This is useful in\n","particular for simplifying the analysis of dot products between examples of opposite classes.\n","It should not be di\u000ecult to extend the analysis meaningfully to remove this assumption|we\n","use this assumption in this paper to keep the analysis as simple and clean as possible.\n","The distribution of x\u0000~y\u0016comes from a sub-Gaussian distribution obtained by applying\n","a unitary transformation to a latent variable with a product distribution. Concentration\n","theorems have been proved under many conditions weaker than independence (see Schmidt\n","18\n","Interpolating Linear Classifiers\n","et al., 1995; Dubhashi and Ranjan, 1998; Pemmaraju, 2001). Our analysis can be straight-\n","forwardly extended using these weaker assumptions.\n","The assumption that the latent variable qsatis\fes Eq\u0018Q[kqk2]\u0015\u0014pformalizes the\n","notion that, in a sense, these variables are truly used, which is required for concentration.\n","We believe that smaller values of Eq\u0018Q[kqk2] are compatible with successful learning. We\n","chose this assumption to facilitate a simple and clean analysis, but an analysis that separates\n","the dependence on Eq\u0018Q[kqk2] is a potential subject for future work.\n","The lower bounds on pare needed for concentration, as described earlier. We suspect\n","that the requirement that p= \n","(n2log(n=\u000e)) can be improved. The bottleneck is in the\n","proof of Lemma 11. (As we mentioned earlier, a larger value of ppromotes the property\n","that the loss on an example can be reduced by gradient descent without increasing the loss\n","on other examples very much.)\n","The lower bound on k\u0016k2allows us to focus on the case where most clean examples are\n","classi\fed correctly by a large margin, which is the case that we want to focus on. This\n","could potentially be weakened or removed through a case analysis, exploiting the fact that\n","a weaker bound is needed in the case that k\u0016kis small.\n","Using the generalized Hoe\u000bding bound (Theorem 13) it is not hard to show (see Helm-\n","bold and Long, 2012, Theorem 1) that, in our setting, the Bayes optimal classi\fer has error\n","at most\u0011+exp(\u0000ck\u0016k2) for an absolute constant c, and Slud's Lemma gives a similar lower\n","bound (see Anthony and Bartlett, 2009) (see also Helmbold and Long, 2012, Inequality (8)).\n","Our upper bound of \u0011+exp(\u0000c0k\u0016k4=p) for the maximum margin algorithm applied to \fnite\n","training data is worse than this by a factor of k\u0016k2=pin the exponent.\n","Implicit regularization lemmas like the one that was so helpful to us have been obtained\n","for other problems (see Gunasekar et al., 2017, 2018b; Woodworth et al., 2020; Azulay et al.,\n","2021). We hope that further advances in implicit regularization research could be combined\n","with the techniques of this paper to prove generalization guarantees for interpolating clas-\n","si\fers using richer model classes, including neural networks.\n","Acknowledgments\n","We thank anonymous reviewers for their valuable comments and suggestions. NC gratefully\n","acknowledges the support of the NSF through grants IIS-1619362 and IIS-1909365.\n","Appendix A. Concentration Inequalities\n","In this section we begin by presenting a de\fnition of sub-Gaussian and sub-exponential\n","random variables in terms of Orlicz norms. Then we state a version of Hoe\u000bding's inequality\n","and a version of Bernstein's inequality. Finally, we prove Lemma 10 which implies that a\n","good event which our proofs rely on holds with high probability.\n","For an excellent reference of sub-Gaussian and sub-exponential concentration inequali-\n","ties we refer the reader to Vershynin (2018, Chapter 2).\n","19\n","Chatterji and Long\n","De\fnition 12 (sub-Gaussian random variable) A random variable \u0012is sub-Gaussian\n","if\n","k\u0012k 2:= inf\b\n","t>0 :E[exp(\u00122=t2)]<2\t\n","is bounded. Further, k\u0012k 2is de\fned to be its sub-Gaussian norm.\n","We now state general Hoe\u000bding's inequality (see Vershynin, 2018, Theorem 2.6.3) a\n","concentration inequality for a weighted sum of independent sub-Gaussian random variables.\n","Theorem 13 (General Hoe\u000bding's inequality) Let\u00121;:::;\u0012mbe independent mean-\n","zero sub-Gaussian random variables and a= (a1;:::;am)2Rm. Then, for every t>0, we\n","have\n","P\"\f\f\fmX\n","i=1ai\u0012i\f\f\f\u0015t#\n","\u00142 exp\u0012\n","\u0000c2t2\n","K2kak2\u0013\n",";\n","whereK= maxik\u0012ik 2andc2is an absolute constant.\n","A one-sided version of this theorem (upper/lower deviation bound) holds without the factor\n","of 2 multiplying the exponent on the right hand side.\n","De\fnition 14 (sub-exponential random variable) A random variable \u0012is said to be\n","sub-exponential if\n","k\u0012k 1:= infft>0 :E[exp(j\u0012j=t)<2]g\n","is bounded. Further, k\u0012k 1is de\fned to be its sub-exponential norm.\n","We shall also use Bernstein's inequality (see Vershynin, 2018, Theorem 2.8.1) a concen-\n","tration inequality for a sum of independent sub-exponential random variables.\n","Theorem 15 (Bernstein's inequality) For independent mean-zero sub-exponential ran-\n","dom variables \u00121;:::;\u0012m, for every t>0, we have\n","P\"\f\f\fmX\n","i=1\u0012i\f\f\f\u0015t#\n","\u00142 exp \n","\u0000c1min(\n","t2\n","Pm\n","i=1k\u0012ik2\n"," 1;t\n","maxik\u0012ik 1)!\n",";\n","wherec1is an absolute constant.\n","Again note that a one-sided version of this inequality holds without the factor of 2 multi-\n","plying the exponent on the right hand side.\n","We break the proof of Lemma 10 into di\u000berent parts, which are proved in separate\n","lemmas. Lemma 10 then follows by a union bound.\n","Lemma 16 For all\u0014>0, there is ac\u00151such that, for all large enough C, with probability\n","at least 1\u0000\u000e=6, for allk2[n],p\n","c\u0014kzkk2\u0014cp:\n","20\n","Interpolating Linear Classifiers\n","Proof For any clean samplezi, the random variables ( zij\u0000\u0016j)2are sub-exponential with\n","norm\n","k(zij\u0000\u0016j)2k 1\u0014kzij\u0000\u0016jk2\n"," 2\u00141:\n","After centering, the sub-exponential norm of the zero-mean random variable ( zij\u0000\u0016j)2\u0000\n","E[(zij\u0000\u0016j)2] is at most a constant (see Vershynin, 2018, Exercise 2.7.10). Therefore, by\n","Bernstein's inequality, there is an absolute constant c0such that\n","P[jkzi\u0000\u0016k2\n","2\u0000E[kzi\u0000\u0016k2\n","2]j\u0015t]\u00142 exp\u0012\n","\u0000c0min\u001at2\n","p;t\u001b\u0013\n",":\n","By settingt=\u0014p=2\n","P[jkzi\u0000\u0016k2\n","2\u0000E[kzi\u0000\u0016k2\n","2]j\u0015\u0014p=2]\u0014\u000e\n","6n;\n","sincep\u0015Clog(n=\u000e) for a large constant C. Recall that by assumption, \u0014p\u0014E[kzi\u0000\u0016k2\n","2]\u0014\n","3p, where the upper bound follows from the assumption that the components of qhave sub-\n","Gaussian norm at most 1. Recalling that \u0014\u00141,\n","\u0014p\n","2\u0014kzi\u0000\u0016k2\u00144p (12)\n","with probability at least 1 \u0000\u000e=(6n).\n","By Young's inequality for products, kzi\u0000\u0016k2\u00142kzik2+ 2k\u0016k2. Also recall that by\n","assumptionk\u0016k2< p=C . Combining this with the left hand side in the display above, for\n","large enough C, we have\n","kzik2\u00151\n","2\u0010\u0014p\n","2\u00002k\u0016k2\u0011\n",">\u0014p\n","8:\n","Again by Young's inequality kzik2=kzi\u0000\u0016+\u0016k2\u00142kzi\u0000\u0016k2+ 2k\u0016k2. Therefore,\n","kzik2\u00142kzi\u0000\u0016k2+ 2k\u0016k2\u00148p+ 2k\u0016k2<10p;\n","with the same probability.\n","A similar argument also holds for all noisy samples by considering the random variables\n","(zk\u0000(\u0000\u0016)). Hence, by taking a union bound over all samples completes the proof.\n","Lemma 17 There is a c\u00151such that, for all large enough C, with probability at least\n","1\u0000\u000e=6, for alli6=j2[n],\n","jzi\u0001zjj<c(k\u0016k2+p\n","plog(n=\u000e)):\n","Proof First, let us condition on the division of f1;:::;nginto clean points Cand noisy\n","pointsN. After this, for each i2C,E[zi] =\u0016(where the expectation is conditioned on zi\n","21\n","Chatterji and Long\n","being clean), and for each i2N,E[zi] =\u0000\u0016. For each i, let\u0018i:=zi\u0000E[zi]. The same\n","logic that proved (12), together with a union bound, yields\n","P[9i2[n];k\u0018jk>2pp]\u0014\u000e\n","24: (13)\n","For any pair i;j2[n] of indices of examples, we have\n","P[j\u0018i\u0001\u0018jj\u0015t]\u0014P\u0002\n","j\u0018i\u0001\u0018jj\u0015t\f\fk\u0018jk\u00142pp\u0003\n","+P[k\u0018jk>2pp]: (14)\n","If we regard \u0018jas \fxed, and only \u0018ias random, Theorem 13 gives\n","P\u0002\n","j\u0018i\u0001\u0018jj\u0015t\u0003\n","\u00142 exp\u0012\n","\u0000c2t2\n","k\u0018jk2\u0013\n",":\n","Thus,\n","P\u0002\n","j\u0018i\u0001\u0018jj\u0015t\f\fk\u0018jk\u00142pp\u0003\n","\u00142 exp\u0012\n","\u0000c2t2\n","4p\u0013\n","= 2 exp\u0012\n","\u0000c3t2\n","p\u0013\n","forc3=c2=4. Substituting into Inequality (14), we infer\n","P[j\u0018i\u0001\u0018jj\u0015t]\u00142 exp\u0012\n","\u0000c3t2\n","p\u0013\n","+P[k\u0018jk>2pp]:\n","Taking a union bound over all pairs for the \frst term, and all individuals for the second\n","term, we get\n","P[9i6=j2[n];j\u0018i\u0001\u0018jj\u0015t]\u00142n2exp\u0012\n","\u0000c3t2\n","p\u0013\n","+P[9j2[n];k\u0018jk>2pp]:\n","Choosingt=cp\n","plog(n=\u000e) for a large enough value of c, we have\n","Ph\n","9i6=j2[n];j\u0018i\u0001\u0018jj\u0015cp\n","plog(n=\u000e)i\n","\u0014\u000e\n","24+P[9j2[n];k\u0018jk>2pp]:\n","Applying (13), we get\n","Ph\n","9i6=j2[n];j\u0018i\u0001\u0018jj\u0015cp\n","plog(n=\u000e)i\n","\u0014\u000e\n","12: (15)\n","For anyi, clean or noisy, Hoe\u000bding's inequality implies\n","P\u0002\n","j\u0016\u0001zij>2k\u0016k2\u0003\n","<2 exp\u0012\n","\u0000c24k\u0016k4\n","k\u0016k2\u0013\n","= 2 exp\u0000\n","\u00004c2c2k\u0016k2\u0001\n",":\n","Sincek\u0016k2\u0015Clog(n=\u000e), this implies\n","P\u0002\n","j\u0016\u0001zij>2k\u0016k2\u0003\n","<\u000e\n","12n:\n","Therefore, by taking a union bound over all i2f1;:::;ng\n","P\u0002\n","9i;j\u0016\u0001zij>2k\u0016k2\u0003\n","<\u000e=12: (16)\n","22\n","Interpolating Linear Classifiers\n","Both the events in (15) and (16) will simultaneously hold with probability at most \u000e=6.\n","Assume that the event complementary to this bad event occurs, then for any distinct pair\n","ziandzj\n","jzi\u0001zjj=\f\f(zi\u0000E[zi])\u0001(zj\u0000E[zj]) +E[zi]\u0001E[zj] +\u0016\u0001zi+\u0016\u0001zj\f\f\n","=j\u0018i\u0001\u0018j+E[zi]\u0001E[zj] +\u0016\u0001zi+\u0016\u0001zjj\n","\u0014j\u0018i\u0001\u0018jj+k\u0016k2+j\u0016\u0001zij+j\u0016\u0001zjj\n","\u00145k\u0016k2+cp\n","plog(n=\u000e);\n","which completes our proof.\n","Lemma 18 For all large enough C, with probability at least 1\u0000\u000e=6,\n","for allk2C;j\u0016\u0001zk\u0000k\u0016k2j<k\u0016k2=2:\n","Proof Ifzkis a clean point then, E[zkjk2 C] =\u0016. Therefore the random variable\n","j\u0016\u0001zk\u0000k\u0016k2j=j\u0016\u0001(zk\u0000\u0016)jhas sub-Gaussian norm at most k\u0016k. By applying Hoe\u000bding's\n","inequality,\n","P[j\u0016\u0001zk\u0000k\u0016k2j\u0015k\u0016k2=2]\u0014\u000e\n","6n;\n","sincek\u0016k2>Clog(n=\u000e). Taking a union bound over all clean points establishes the claim.\n","Lemma 19 For all large enough C, with probability at least 1\u0000\u000e=6,\n","for allk2N;j\u0016\u0001zk\u0000(\u0000k\u0016k2)j<k\u0016k2=2:\n","Proof The proof is the same as the proof of Lemma 18, except that for any noisy sample,\n","zk, the conditional mean E[zkjk2 N ] =\u0000\u0016.\n","Lemma 20 For allc0>0, for all large enough C, with probability 1\u0000\u000e=6the number of\n","noisy samples satis\fes jNj\u0014 (\u0011+c0)n.\n","Proof Sincen\u0015Clog(1=\u000e), this follows from a Hoe\u000bding bound.\n","Lemma 21 If(2)and(3)hold, then, if Cis large enough, (x1;y1);:::; (xn;yn)are linearly\n","separable.\n","23\n","Chatterji and Long\n","Proof Letv:=Pn\n","k=1zk. For eachkand any\u000e>0,\n","ykv\u0001xk=X\n","iyiykxi\u0001xk\n","\u0015p=c1\u0000X\n","i6=kyiykxi\u0001xk\n","\u0015p=c1\u0000c1n(k\u0016k2+p\n","plog(n=\u000e))\n",">0\n","forp\u0015Cmaxfk\u0016k2n;n2log(n=\u000e)g, completing the proof.\n","Appendix B. Decreasing Loss\n","Lemma 22 For all small enough step sizes \u000b, for all iterations t,R(v(t))\u0014n.\n","Proof SinceR(v(0)) =P\n","j2[n]exp (0\u0001zj) =n, it su\u000eces to prove that, for all t,R(v(t+1))\u0014\n","R(v(t)). Toward showing this, note that, if c1is the constant cfrom Lemma 10, the operator\n","norm of the Hessian at any solution vmay be bound as follows:\n","kr2R(v)k=\r\r\r\r\rX\n","kzkz>\n","kexp(\u0000vzk)\r\r\r\r\r\n","\u0014X\n","k\r\r\rzkz>\n","k\r\r\rexp(\u0000vzk)\n","\u0014c1pX\n","kexp(\u0000vzk)\n","=c1pR(v):\n","This implies that Risc1pn-smooth over those vsuch thatR(v)\u0014n. This implies that, for\n","\u000b\u0014(c1pn)\u00001, ifR(v(t))\u0014nthenR(v(t+1))\u0014R(v(t))\u0014n(this can be seen, for example,\n","by mirroring the argument used in Lemma B.2 in Ji and Telgarsky, 2019). The lemma then\n","follows using induction.\n","References\n","T.W. Anderson. An introduction to multivariate statistical analysis . Wiley Series in Prob-\n","ability and Statistics. Wiley, 2003.\n","Dana Angluin and Philip Laird. Learning from noisy examples. Machine Learning , 2(4):\n","343{370, 1988.\n","Martin Anthony and Peter L Bartlett. Neural network learning: Theoretical foundations .\n","Cambridge University Press, 2009.\n","24\n","Interpolating Linear Classifiers\n","Pranjal Awasthi, Maria-Florina Balcan, Nika Haghtalab, and Ruth Urner. E\u000ecient learning\n","of linear separators under bounded noise. In Conference on Learning Theory , pages 167{\n","190, 2015.\n","Pranjal Awasthi, Maria Florina Balcan, and Philip M Long. The power of localization for\n","e\u000eciently learning linear separators with noise. Journal of the ACM (JACM) , 63(6):1{27,\n","2017.\n","Shahar Azulay, Edward Moroshko, Mor Shpigel Nacson, Blake Woodworth, Nathan Srebro,\n","Amir Globerson, and Daniel Soudry. On the implicit bias of initialization shape: Beyond\n","in\fnitesimal mirror descent. arXiv preprint arXiv:2102.09769 , 2021.\n","Peter L Bartlett, Philip M Long, G\u0013 abor Lugosi, and Alexander Tsigler. Benign over\ftting in\n","linear regression. Proceedings of the National Academy of Sciences , 117(48):30063{30070,\n","2020.\n","Mikhail Belkin, Daniel J Hsu, and Partha Mitra. Over\ftting or perfect \ftting? Risk bounds\n","for classi\fcation and regression rules that interpolate. In Advances in Neural Information\n","Processing Systems , pages 2300{2311, 2018.\n","Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal. Reconciling modern machine-\n","learning practice and the classical bias{variance trade-o\u000b. Proceedings of the National\n","Academy of Sciences , 116(32):15849{15854, 2019a.\n","Mikhail Belkin, Alexander Rakhlin, and Alexandre B Tsybakov. Does data interpolation\n","contradict statistical optimality? In International Conference on Arti\fcial Intelligence\n","and Statistics , pages 1611{1619, 2019b.\n","Mikhail Belkin, Daniel Hsu, and Ji Xu. Two models of double descent for weak features.\n","SIAM Journal on Mathematics of Data Science , 2(4):1167{1180, 2020.\n","Daniel Berend and Aryeh Kontorovich. A \fnite sample analysis of the Naive Bayes classi\fer.\n","Journal of Machine Learning Research , 16(44):1519{1545, 2015.\n","Peter J Bickel and Elizaveta Levina. Some theory for Fisher's linear discriminant function,\n","`naive Bayes', and some alternatives when there are many more variables than observa-\n","tions. Bernoulli , 10(6):989{1010, 2004.\n","Gilles Blanchard, Olivier Bousquet, and Pascal Massart. Statistical performance of support\n","vector machines. The Annals of Statistics , 36(2):489{531, 2008.\n","Tony Cai and Weidong Liu. A direct estimation approach to sparse linear discriminant\n","analysis. Journal of the American statistical association , 106(496):1566{1577, 2011.\n","Tony Cai and Linjun Zhang. High dimensional linear discriminant analysis: optimality,\n","adaptive algorithm and missing data. Journal of the Royal Statistical Society: Series B\n","(Statistical Methodology) , 81(4):675{705, 2019.\n","Emmanuel J Cand\u0012 es and Pragya Sur. The phase transition for the existence of the maximum\n","likelihood estimate in high-dimensional logistic regression. The Annals of Statistics , 48\n","(1):27{42, 2020.\n","25\n","Chatterji and Long\n","Timothy I Cannings, Yingying Fan, and Richard J Samworth. Classi\fcation with imperfect\n","training labels. Biometrika , 107(2):311{330, 2020.\n","Nicolo Cesa-Bianchi, Eli Dichterman, Paul Fischer, Eli Shamir, and Hans Ulrich Simon.\n","Sample-e\u000ecient strategies for learning in the presence of noise. Journal of the ACM\n","(JACM) , 46(5):684{719, 1999.\n","Niladri S Chatterji and Philip M Long. Finite-sample analysis of interpolating linear clas-\n","si\fers in the overparameterized regime. arXiv preprint arXiv:2004.12019 , 2020.\n","Thomas H Cormen, Charles E Leiserson, Ronald L Rivest, and Cli\u000bord Stein. Introduction\n","to algorithms . MIT Press, 2009.\n","Thomas M Cover. Geometrical and statistical properties of systems of linear inequalities\n","with applications in pattern recognition. IEEE transactions on electronic computers , (3):\n","326{334, 1965.\n","Constantinos Daskalakis. Probability and computation, lecture 3. http://people.csail.\n","mit.edu/costis/6896sp11/lec3s.pdf , 2011. Scribes: A. Chiesa and Z. Zhu. (Down-\n","loaded 4/13/20).\n","Zeyu Deng, Abla Kammoun, and Christos Thrampoulidis. A model of double descent for\n","high-dimensional logistic regression. In ICASSP , pages 4267{4271, 2020.\n","Ilias Diakonikolas, Themis Gouleakis, and Christos Tzamos. Distribution-independent PAC\n","learning of halfspaces with Massart noise. In Advances in Neural Information Processing\n","Systems , pages 4749{4760, 2019.\n","Edgar Dobriban and Stefan Wager. High-dimensional asymptotics of prediction: Ridge\n","regression and classi\fcation. The Annals of Statistics , 46(1):247{279, 2018.\n","David Donoho and Jiashun Jin. Higher criticism thresholding: Optimal feature selection\n","when useful features are rare and weak. Proceedings of the National Academy of Sciences ,\n","105(39):14790{14795, 2008.\n","Devdatt Dubhashi and Desh Ranjan. Balls and bins: A study in negative dependence.\n","Random Structures & Algorithms , 13(5):99{124, 1998.\n","Richard O Duda, Peter E Hart, and David G Stork. Pattern classi\fcation . John Wiley &\n","Sons, 2012.\n","Jianqing Fan and Yingying Fan. High dimensional classi\fcation using features annealed\n","independence rules. The Annals of Statistics , 36(6):2605, 2008.\n","Suriya Gunasekar, Blake E Woodworth, Srinadh Bhojanapalli, Behnam Neyshabur, and\n","Nathna Srebro. Implicit regularization in matrix factorization. In Advances in Neural\n","Information Processing Systems , pages 6151{6159, 2017.\n","Suriya Gunasekar, Jason Lee, Daniel Soudry, and Nathan Srebro. Characterizing implicit\n","bias in terms of optimization geometry. In International Conference on Machine Learning ,\n","pages 1832{1841, 2018a.\n","26\n","Interpolating Linear Classifiers\n","Suriya Gunasekar, Jason D Lee, Daniel Soudry, and Nathan Srebro. Implicit bias of gradient\n","descent on linear convolutional networks. In Advances in Neural Information Processing\n","Systems , pages 9461{9471, 2018b.\n","Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The elements of statistical learn-\n","ing: data mining, inference, and prediction . Springer Science & Business Media, 2009.\n","Trevor Hastie, Andrea Montanari, Saharon Rosset, and Ryan J Tibshirani. Surprises in\n","high-dimensional ridgeless least squares interpolation. arXiv preprint arXiv:1903.08560 ,\n","2019.\n","David P Helmbold and Philip M Long. On the necessity of irrelevant variables. Journal of\n","Machine Learning Research , 13(Jul):2145{2170, 2012.\n","Daniel Hsu, Vidya Muthukumar, and Ji Xu. On the proliferation of support vectors in high\n","dimensions. In International Conference on Arti\fcial Intelligence and Statistics , pages\n","91{99, 2021.\n","Ziwei Ji and Matus Telgarsky. The implicit bias of gradient descent on nonseparable data.\n","InConference on Learning Theory , pages 1772{1798, 2019.\n","Jiashun Jin. Impossibility of successful classi\fcation when useful features are rare and weak.\n","Proceedings of the National Academy of Sciences , 106(22):8859{8864, 2009.\n","Adam Tauman Kalai and Rocco A Servedio. Boosting in the presence of noise. Journal of\n","Computer and System Sciences , 71(3):266{290, 2005.\n","Adam Tauman Kalai, Adam R Klivans, Yishay Mansour, and Rocco A Servedio. Agnosti-\n","cally learning halfspaces. SIAM Journal on Computing , 37(6):1777{1805, 2008.\n","Michael Kearns. E\u000ecient noise-tolerant learning from statistical queries. Journal of the\n","ACM (JACM) , 45(6):983{1006, 1998.\n","Michael J Kearns, Robert E Schapire, and Linda M Sellie. Toward e\u000ecient agnostic learning.\n","Machine Learning , 17(2-3):115{141, 1994.\n","Matth aus Kleindessner and Pranjal Awasthi. Crowdsourcing with arbitrary adversaries. In\n","International Conference on Machine Learning , pages 2708{2717, 2018.\n","Adam R Klivans, Philip M Long, and Rocco A Servedio. Learning halfspaces with malicious\n","noise. Journal of Machine Learning Research , 10(Dec):2715{2740, 2009.\n","Dmitry Kobak, Jonathan Lomond, and Benoit Sanchez. The optimal ridge penalty for\n","real-world high-dimensional data can be zero or negative due to the implicit ridge regu-\n","larization. Journal of Machine Learning Research , 21(169):1{16, 2020.\n","Tianyang Li, Adarsh Prasad, and Pradeep K Ravikumar. Fast classi\fcation rates for high-\n","dimensional Gaussian generative models. In Advances in Neural Information Processing\n","Systems , pages 1054{1062, 2015.\n","27\n","Chatterji and Long\n","Yanfang Li and Jinzhu Jia. L1 least squares for sparse high-dimensional LDA. Electronic\n","Journal of Statistics , 11(1):2499{2518, 2017.\n","Tengyuan Liang and Alexander Rakhlin. Just interpolate: Kernel \\ridgeless\" regression\n","can generalize. The Annals of Statistics , 48(3):1329{1347, 2020.\n","Tengyuan Liang and Benjamin Recht. Interpolating classi\fers make few mistakes. arXiv\n","preprint arXiv:2101.11815 , 2021.\n","Tengyuan Liang and Pragya Sur. A precise high-dimensional asymptotic theory for boosting\n","and min-`1-norm interpolated classi\fers. arXiv preprint arXiv:2002.01586 , 2020.\n","Tengyuan Liang, Alexander Rakhlin, and Xiyu Zhai. On the multiple descent of minimum-\n","norm interpolants and restricted lower isometry of kernels. In Conference on Learning\n","Theory , pages 2683{2711, 2020.\n","Torgny Lindvall. Lectures on the coupling method . Courier Corporation, 2002.\n","Philip M Long and Rocco A Servedio. Random classi\fcation noise defeats all convex po-\n","tential boosters. Machine learning , 78(3):287{304, 2010.\n","Gabor Lugosi. Learning with an unreliable teacher. Pattern Recognition , 25(1):79{87, 1992.\n","Pascal Massart and \u0013Elodie N\u0013 ed\u0013 elec. Risk bounds for statistical learning. The Annals of\n","Statistics , 34(5):2326{2366, 2006.\n","Song Mei and Andrea Montanari. The generalization error of random features regression:\n","Precise asymptotics and double descent curve. arXiv preprint arXiv:1908.05355 , 2019.\n","Andrea Montanari, Feng Ruan, Youngtak Sohn, and Jun Yan. The generalization error\n","of max-margin linear classi\fers: High-dimensional asymptotics in the overparametrized\n","regime. arXiv preprint arXiv:1911.01544 , 2019.\n","Vidya Muthukumar, Adhyyan Narang, Vignesh Subramanian, Mikhail Belkin, Daniel Hsu,\n","and Anant Sahai. Classi\fcation vs regression in overparameterized regimes: Does the\n","loss function matter? arXiv preprint arXiv:2005.08054 , 2020a.\n","Vidya Muthukumar, Kailas Vodrahalli, Vignesh Subramanian, and Anant Sahai. Harmless\n","interpolation of noisy data in regression. IEEE Journal on Selected Areas in Information\n","Theory , 2020b.\n","Mor Shpigel Nacson, Nathan Srebro, and Daniel Soudry. Stochastic gradient descent on\n","separable data: Exact convergence with a \fxed learning rate. In International Conference\n","on Arti\fcial Intelligence and Statistics , pages 3051{3059, 2019.\n","Vaishnavh Nagarajan and J Zico Kolter. Uniform convergence may be unable to explain\n","generalization in deep learning. In Advances in Neural Information Processing Systems ,\n","pages 11615{11626, 2019.\n","28\n","Interpolating Linear Classifiers\n","Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learn-\n","ing with noisy labels. In Advances in neural information processing systems , pages 1196{\n","1204, 2013.\n","Behnam Neyshabur. Implicit regularization in deep learning. arXiv preprint\n","arXiv:1709.01953 , 2017.\n","Behnam Neyshabur, Ryota Tomioka, and Nathan Srebro. In search of the real inductive bias:\n","On the role of implicit regularization in deep learning. arXiv preprint arXiv:1412.6614 ,\n","2014.\n","Andrew Y Ng and Michael I Jordan. On discriminative vs. generative classi\fers: A compar-\n","ison of logistic regression and naive Bayes. In Advances in Neural Information Processing\n","Systems , pages 841{848, 2002.\n","Sriram V Pemmaraju. Equitable coloring extends Cherno\u000b-Hoe\u000bding bounds. In Approx-\n","imation, Randomization, and Combinatorial Optimization: Algorithms and Techniques ,\n","pages 285{296. Springer, 2001.\n","Jeanette P Schmidt, Alan Siegel, and Aravind Srinivasan. Cherno\u000b{Hoe\u000bding bounds for\n","applications with limited independence. SIAM Journal on Discrete Mathematics , 8(2):\n","223{250, 1995.\n","Clayton Scott, Gilles Blanchard, and Gregory Handy. Classi\fcation with asymmetric label\n","noise: Consistency and maximal denoising. In Conference on Learning Theory , pages\n","489{511, 2013.\n","Rocco A Servedio. On PAC learning using Winnow, Perceptron, and a Perceptron-like\n","algorithm. In Conference on Computational Learning Theory , pages 296{307, 1999.\n","John Shawe-Taylor, Peter L Bartlett, Robert C Williamson, and Martin Anthony. Structural\n","risk minimization over data-dependent hierarchies. IEEE transactions on Information\n","Theory , 44(5):1926{1940, 1998.\n","Daniel Soudry, Elad Ho\u000ber, Mor Shpigel Nacson, Suriya Gunasekar, and Nathan Srebro.\n","The implicit bias of gradient descent on separable data. Journal of Machine Learning\n","Research , 19(1):2822{2878, 2018.\n","Pragya Sur and Emmanuel J Cand\u0012 es. A modern maximum-likelihood theory for high-\n","dimensional logistic regression. Proceedings of the National Academy of Sciences , 116\n","(29):14516{14525, 2019.\n","Kunal Talwar. On the error resistance of hinge-loss minimization. In Advances in Neural\n","Information Processing Systems , volume 33, pages 4223{4234, 2020.\n","Brendan Van Rooyen, Aditya Menon, and Robert C Williamson. Learning with symmetric\n","label noise: The importance of being unhinged. In Advances in Neural Information\n","Processing Systems , pages 10{18, 2015.\n","29\n","Chatterji and Long\n","Vladimir Vapnik. Estimation of dependences based on empirical data . Springer-Verlag,\n","1982.\n","Vladimir N Vapnik. The nature of statistical learning theory . Springer-Verlag, 1995.\n","Roman Vershynin. High-dimensional probability: An introduction with applications in data\n","science , volume 47. Cambridge University Press, 2018.\n","Ke Wang and Christos Thrampoulidis. Benign over\ftting in binary classi\fcation of Gaussian\n","mixtures. arXiv preprint arXiv:2011.09148 , 2020.\n","Blake Woodworth, Suriya Gunasekar, Jason D Lee, Edward Moroshko, Pedro Savarese, Itay\n","Golan, Daniel Soudry, and Nathan Srebro. Kernel and rich regimes in overparametrized\n","models. In Conference on Learning Theory , pages 3635{3673, 2020.\n","Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Under-\n","standing deep learning requires rethinking generalization. In International Conference on\n","Learning Representations , 2017.\n","30\n"]}]},{"cell_type":"code","source":["!pip install -q chromadb\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHEryhPO_kXH","outputId":"259191b1-8606-4bac-c630-8eb83979ef0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import chromadb\n","from chromadb.utils import embedding_functions"],"metadata":{"id":"gAysf1K_AWHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Configure vector database\n","client = chromadb.Client() # initiate client\n","ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name = 'all-MiniLM-L6-v2') # Embedding function for documents\n","\n","# Create a vector database\n","collection = client.create_collection(\n","    name = 'ksolutions',\n","    embedding_function = ef ,\n","    metadata={\"hnsw:space\": \"l2\"}\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":493,"referenced_widgets":["b3025dbaca5f4bf894bb1bf8d64984d8","be1921f936ba4876ad3c5399ac5e1ade","928c37b77d2a4be8bb645b1f712f6a16","d271db2fc6bb4c57ac30c56bd0cc2b35","41352b533e9445088378751b7bde8bae","2e7fef9e68a8409bb1bac83beda78a19","fc033489313a48b399d7c18a49b854df","703020aa122340ddabf54e5d4a48fb56","2a9e2f1ac0764eebb34479542cf77d74","8ace980795164adcaa1a14acec3ecef0","769ffca6c23c4c50bee23b50b50760b5","17472a3ba61248dbb41a23992f50cda8","bcc4a9c97b12450189d52948596f53e0","a9fb91ea2b7643d4b8ec52bdbf27f2b3","4546f29bff3f441d9f72e0bb5facd60a","0a4b4ff2665d475e85f98a46503d2530","49a710c7a333406682372c69042592f8","be51170574cc4473b8d6a1c2b1c9d9e7","48be880bb38440ada70d4cbb0cb5608c","ffc5d234fe964bb19c66aac4a48dba1c","9d3c012f1ce343e78c9e64db86960805","71d50cd38f5f43daadc48b2c5d42b3b1","058da4eba0d448a88b6597143150f4e0","bc7a34270c5d4a9eab6e7b1a01348b9e","b573ae3747cc44748c31c388f3728d94","1632ac9942d74534a07edf1b6d857fbc","c98dc926a1fc4507945d4b20318dfb7f","5b73708acb1e49ffa9bdfbb0b9d0b6fd","59e161804d0440aea288f3dff7147781","1b03b1c014994bda91a4c91300cbcb5c","04cd4ee58fb7401f98daae0c6ea759cb","9f40d43b67134bf3b0e753829c9ee7ba","fe97f7414628479c9c49bf564409c144","b0cd2eed017b45bf855e96f0f53a0292","6f4ba4625e6d4109b81b1720cb183887","8365601e5bff455db732d2d730d124e8","eeb128ea61794f479ccd4b308c5fd089","d0db0f7d4bd642bb9b59e1d0d3efdc05","12532b78d51a446a81fbcc43c6642c7e","86ed47ea1e1a46118875d0fe8c1ecefc","ba2b2f3134d447f4b4194b882641f968","be8bef16954b4373bc15ad4fbce31409","aedab3d50c74428a8d230eb1962cb787","8adc09eeb1414f97a144fd7b7fe686c3","3b24ad2060a94ac5b7174e3f274082e4","e26af0e5bda24d109d416769af678153","8837983869a549c3b0d26098d40be568","f7ce366a694944cd966329e40388731a","47c18ce0df064ff0a67f83197a78c9bd","8188962d7a9b4332ab855a90dc386918","99dcbfaad7024d128ac3dbfcc6b6729d","e14f3686ebfe4b248192ddeb54f90109","7548f920290b4bb3a7f65059a4098323","2855ae198b1d4dc7a7b1823e7a4dc4b2","b74dfc5f7aa64508b01d1812ad1837d5","99cb4a6abb5c4f32b6b56556e221d374","0c597f2bf2c144388cb935b7fc98886d","1d3c254c2300459aba27a2f12cdd2d61","5376c197a69d43a8a47ed178b4e9ca39","bd08b95150d54bada0202a7ab62a75aa","9e0980252cb14e2da54bfd4f0694617f","7c68cbf0f736417eadd5abe0981c1952","778fc6bd62df48d7bed33eebdc0618cb","c3c6f3f55f544c7085f658d6b9cb1f1b","792e548b09bc4196b21115f231ac9904","69911dea616f4ddbb78052716be8ece0","641a01e61f3443ffa12e7d21c74cb4bc","c950bb131c2d487190fae502caf75383","ab48a4b0e7074985a4a46e0f93c5f4c0","b5ad7dacd493488a88ca190aa8e4cdc1","983fa0feac364be785b2cc0a3c7820a6","8087f30a5b3c43c9b2f3241bc134a9ce","17abc01f4d0248fb8e49911d518fab5d","67402070b81f405780082b8af43fc956","8984ee17c075402894b25a323aea6f21","c4c0267483db455aa96be6252ffce1d2","db0a652a3846467f85eb9415cb9daa3d","66d30ba0497644ffbe3e23e142b6d745","9476ace05a044cb296d7e64f3748665e","dc549af18f4d43a29d25a176cfad9ee6","8093d38e474d4de481dc1d8307f5ecba","b13092dadf9f460fa87880e95144aec9","093682a704e14c94b05f8bfa7a90cef5","e1468519cd4f482699163164f80e2e82","b07c28415b8d4bd59b5db234978e1441","3a3d364932ee4af98c86144928fe547d","81b50a71ac024e0eaa33ae4ff1a9719d","256aaed596ee4e258fc83aa9077d9d96","90d0e65b1eea472ca9c02f586c2c1a6d","aa0b38d3d27748eeaaef3dfef0f0434e","208c6e8414ee4fd08bfa729fc2606824","4853b219a469482489c55859bdea57b6","f612b9f6ac394c8599ad9595c0d0b8a9","32da0d8745d540b09f8949e49ea6173e","cf3893afbfcd4cc98aa88f07b920f37c","c5c5a026a75645d79442a0cc002ae5d5","487bc3ab287e4c68b7113c424ef70d9b","393fc7b11f204b63b5881c905c34da68","dde47311ef7f43678e7e15b4a2e0f713","e043c69c16e64aab9d351ee9c9d218af","ea202f1aed8a47ccb8250251c31ad0ff","a114f6e3d0424d58b4fb8bd9e7b60a8a","37248f38e29942e28a3fd123885d3f2e","cddfa46e8dd5416fb046b7ab284e8a38","9b8e56ab1bf14d82a7aedd25fe26befe","4675e9b25a554d1fb4516cc1a7231c37","fc79a35675c847d1b33a4807c243f819","0260d2bdbf3d49f8a8706e7806119063","b129cfedc74f4ac78f7d89d7f6efc1ea","5b91991a8caa41848dfabc4f66fb7387","0154561a5bca4ed0807784b9ec819cb1","e136781afa6c4d72be73adc84ed02840","9dc908f3ff87487183bad33ed5316652","db638c934e1848159e4c69066c211c61","8f969fd7427245c7ac76759600578555","7883ab05e178497f8bdd0f0a0dda9421","39dab1edc0be44139358b4799931963d","c13fd168c36449d9942b282c4556081a","058d4db5c7794ad2adeeaca2cc427ac5","1bfff8132fff44cfa329d1362fd2acfb","f45c1e7317d34102946fb04d261f6a57"]},"id":"i1Ly5QFUALli","outputId":"6b3aff5c-dffc-4b9f-c536-d318b0ceb3d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3025dbaca5f4bf894bb1bf8d64984d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17472a3ba61248dbb41a23992f50cda8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"058da4eba0d448a88b6597143150f4e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0cd2eed017b45bf855e96f0f53a0292"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b24ad2060a94ac5b7174e3f274082e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99cb4a6abb5c4f32b6b56556e221d374"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"641a01e61f3443ffa12e7d21c74cb4bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66d30ba0497644ffbe3e23e142b6d745"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90d0e65b1eea472ca9c02f586c2c1a6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e043c69c16e64aab9d351ee9c9d218af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0154561a5bca4ed0807784b9ec819cb1"}},"metadata":{}}]},{"cell_type":"code","source":["import PyPDF2\n","\n","def extract_text_from_pdf(pdf_path):\n","    with open(pdf_path, 'rb') as file:\n","        reader = PyPDF2.PdfReader(file)\n","        pdf_text = [page.extract_text() for page in reader.pages if page.extract_text()]\n","    return pdf_text\n","\n","# Read and extract text from PDF\n","pdf_path = '/content/paper_185.pdf'\n","pdf_text = extract_text_from_pdf(pdf_path)\n","total_entries = len(pdf_text)"],"metadata":{"id":"oQ5K2EKkArg5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["documents = pdf_text\n","ids = [str(i) for i in range(total_entries)]\n","metadatas = [{'page_number': i} for i in range(total_entries)]\n"],"metadata":{"id":"7dIvKqJWA4Zm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","writeup = query_database(user_prompt)\n","\n","# Generate the prompt for OLLaMA\n","prompt_template = [\n","    {\"role\": \"user\",\n","     \"content\": f\"You are teacher, explain the below content based on the instructions. Generate a response in simple to understand words ### instruction {user_prompt}  ### content {writeup}\"}\n","]\n","\n","# Assuming a function or method that prepares the chat prompt\n","prompt = apply_chat_template(prompt_template, tokenize=False, add_generation_prompt=True)\n","\n","# Assuming 'llm' is your initialized OLLaMA model variable\n","try:\n","    outputs = llm.generate_text(prompt)  # Generate text using OLLaMA\n","    display(Markdown(outputs[len(prompt)-2:]))  # Display the output in Markdown format\n","except Exception as e:\n","   print(f\"An error occurred while generating the text: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"Kjr23v2BA7I0","outputId":"80017554-af82-46cc-a306-8ac6111d0d8c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'query_database' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-70aab5d16607>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwriteup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Generate the prompt for OLLaMA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m prompt_template = [\n\u001b[1;32m      5\u001b[0m     {\"role\": \"user\", \n","\u001b[0;31mNameError\u001b[0m: name 'query_database' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"AIv8a1g1DCDo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def query_database(query):\n","    \"\"\"Function to query the vector database and fetch relevant document.\"\"\"\n","    results = collection.search(query=query, top_k=1)\n","    return results[0].text if results else \"No relevant information found.\"\n","\n","# Example usage\n","user_prompt = 'Explain the 12th place solution of Signal Search competition'\n","writeup = query_database(user_prompt)\n","\n","# Prepare the prompt for OLLaMA\n","prompt_template = [\n","    {\"role\": \"user\",\n","     \"content\": f\"You are a teacher, explain the below content based on the instructions. Generate a response in simple to understand words ### instruction {user_prompt}  ### content {writeup}\"}\n","]\n","\n","# Assuming a function or method that prepares the chat prompt\n","prompt = apply_chat_template(prompt_template, tokenize=False, add_generation_prompt=True)\n","\n","# Assuming 'llm' is your initialized OLLaMA model variable\n","try:\n","    outputs = llm.generate_text(prompt)  # Generate text using OLLaMA\n","    display(Markdown(outputs))  # Display the output in Markdown format\n","except Exception as e:\n","    print(f\"An error occurred while generating the text: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"h8crS_YcB5iN","outputId":"a4f71e23-ccbd-4440-9013-0fe41896691f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'Collection' object has no attribute 'search'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-2a7ddef4e996>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0muser_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Explain the 12th place solution of Signal Search competition'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mwriteup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Prepare the prompt for OLLaMA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-2a7ddef4e996>\u001b[0m in \u001b[0;36mquery_database\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquery_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Function to query the vector database and fetch relevant document.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"No relevant information found.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    765\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(self).__name__!r} object has no attribute {item!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Collection' object has no attribute 'search'"]}]},{"cell_type":"code","source":["# Ingest documnets into vector database\n","collection.add(\n","    documents = documents,\n","    ids = [str(i) for i in range(total_entries)],\n","    metadatas = metadatas\n",")"],"metadata":{"id":"Z7PE9cyNDqoA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def query_database(user_prompt):\n","    output = collection.query(\n","    query_texts=user_prompt,\n","    n_results=1\n","    )\n","    return output['documents'][0][0]"],"metadata":{"id":"zK7guuAqD-jX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_prompt = 'Summarize the paper'\n","writeup = query_database(user_prompt)\n","\n","# Prepare the prompt for OLLaMA\n","prompt = [\n","    {\"role\": \"user\",\n","     \"content\": f\"You are a teacher, explain the below content based on the instructions. Generate a response in simple to understand words ### instruction {user_prompt}  ### content {writeup}\"}\n","]\n","\n","# Assuming a function or method that prepares the chat prompt\n","\n","# Assuming 'llm' is your initialized OLLaMA model variable\n","try:\n","    outputs = llm.invoke(prompt) # Generate text using OLLaMA\n","    display(outputs)  # Display the output in Markdown format\n","except Exception as e:\n","    print(f\"An error occurred while generating the text: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"8H_fS1mWEKzw","outputId":"c1a59331-8214-4896-9dd4-cff9347d1aaa"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["'**Summary:**\\n\\nThe paper discusses a stochastic approximation technique called **chattering** for solving optimization problems. The technique involves iteratively updating a solution based on the current problem setting.\\n\\n**Key Findings:**\\n\\n* In the first case, when the current solution is not sufficiently good, the updated solution is simply the best achievable solution from the previous iteration.\\n* In the second case, when the current solution is already good enough, the updated solution is a weighted average of the current solution and the previous best solution.\\n* The paper proves that the chattering technique converges to the optimal solution under certain conditions.\\n\\n**Main Argument:**\\n\\nThe chattering technique provides a stochastic approximation of the optimal solution by iteratively updating the solution based on the problem setting. The technique is particularly useful when the optimal solution is difficult or impossible to find exactly.\\n\\n**Implications:**\\n\\n* The chattering technique can be used to solve various optimization problems in various fields, such as machine learning, signal processing, and engineering.\\n* The technique provides a practical way to find approximate solutions to complex optimization problems, even when exact solutions are unavailable.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"4fo7bdQJEQWs"},"execution_count":null,"outputs":[]}]}