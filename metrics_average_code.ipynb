{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1edO80One2OFlWHmOEkCrRqJZXITlefKD","authorship_tag":"ABX9TyPOd7O2lMPivDNLZ9islhiC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","# Mount Google Drive for file access\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"jY5Q75eQnyRe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731285004409,"user_tz":480,"elapsed":19353,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"44609909-c7d4-4da1-95c0-6dd684768213"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# Define the column names that match the expected structure of your metrics CSVs\n","column_names = ['question', 'ground_truth', 'rag_answer', 'contexts', 'response_times',\n","                'cpu_start_usages', 'cpu_end_usages', 'average_cpu_usages', 'average_gpu_usages',\n","                'context_relevance', 'answer_relevance', 'groundedness', 'answer_correctness',\n","                'human_judge_score']\n","\n","# Path to the directory containing the metric files\n","metrics_directory = '/content/drive/MyDrive/298A/search_engine/metrics'\n","\n","# List to store all the metric DataFrames\n","metrics_list = []\n","\n","# Loop through all CSV files in the directory and load them into DataFrames\n","for file in os.listdir(metrics_directory):\n","    if file.endswith('.csv'):  # Assuming the metrics files are CSVs\n","        file_path = os.path.join(metrics_directory, file)\n","        df = pd.read_csv(file_path, header=None, names=column_names)  # Load without headers and assign column names\n","        metrics_list.append(df)\n","\n","# Concatenate all DataFrames into one DataFrame\n","combined_df = pd.concat(metrics_list, ignore_index=True)\n","\n","import pandas as pd\n","pd.set_option('display.max_columns', None)  # Display all columns\n","pd.set_option('display.width', 1000)        # Increase the width to fit all columns\n","\n","\n","combined_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":660},"id":"C4QWyZceoOdm","executionInfo":{"status":"ok","timestamp":1731285536696,"user_tz":480,"elapsed":463,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"34935f4d-be88-4ba8-c0d0-8e6bee2ed9d5"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            question                                       ground_truth                                         rag_answer                                           contexts  response_times  cpu_start_usages  cpu_end_usages  average_cpu_usages  average_gpu_usages  context_relevance  answer_relevance  groundedness  answer_correctness  human_judge_score\n","0  What is the main purpose of L3Ms, or Lagrange ...  L3Ms are designed to customize large language ...  Distributed learning (DL) is a machine learnin...  machine learning.\\nKeywords Stochastic Gradien...           14.62               0.4             0.7                0.30               33.75           0.754237                 6      0.798171            0.616415                  8\n","1  How do L3Ms address the reliance on heuristics...  L3Ms use logarithmic barriers to enforce const...  The key optimization algorithm in deep learnin...  machine learning.\\nKeywords Stochastic Gradien...           12.20               0.4             0.5               13.95               36.90           0.190476                 7      0.879844            0.641738                  7\n","2  What is the main advantage of using L3Ms for a...  L3Ms enable tailored alignments by allowing co...  Compressed SGD is a technique used to accelera...  robustness of these techniques in distributed ...           14.64               0.8            16.9                0.52               36.90           0.010000                 7      0.925140            0.582782                  8\n","3  What approach is typically used to align LLMs ...  Existing methods usually align LLMs with heuri...  PowerSGD is a gradient compression technique u...  capturing the primary directions of the gradie...           12.37              10.8             8.9                0.37               36.90           0.044444                 8      0.904165            0.544810                  9\n","4  In the L3Ms framework, how are constraints app...  Constraints are enforced using a logarithmic b...  \\nTop-K SGD and PowerSGD differ in their compr...  gradient compression: PowerSGD uses low-rank a...           11.88              17.8             9.2                3.34               36.90           0.771084                 7      0.908933            0.568917                  8"],"text/html":["\n","  <div id=\"df-1930b020-0622-4873-a0ac-194aa31dba2b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>ground_truth</th>\n","      <th>rag_answer</th>\n","      <th>contexts</th>\n","      <th>response_times</th>\n","      <th>cpu_start_usages</th>\n","      <th>cpu_end_usages</th>\n","      <th>average_cpu_usages</th>\n","      <th>average_gpu_usages</th>\n","      <th>context_relevance</th>\n","      <th>answer_relevance</th>\n","      <th>groundedness</th>\n","      <th>answer_correctness</th>\n","      <th>human_judge_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What is the main purpose of L3Ms, or Lagrange ...</td>\n","      <td>L3Ms are designed to customize large language ...</td>\n","      <td>Distributed learning (DL) is a machine learnin...</td>\n","      <td>machine learning.\\nKeywords Stochastic Gradien...</td>\n","      <td>14.62</td>\n","      <td>0.4</td>\n","      <td>0.7</td>\n","      <td>0.30</td>\n","      <td>33.75</td>\n","      <td>0.754237</td>\n","      <td>6</td>\n","      <td>0.798171</td>\n","      <td>0.616415</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>How do L3Ms address the reliance on heuristics...</td>\n","      <td>L3Ms use logarithmic barriers to enforce const...</td>\n","      <td>The key optimization algorithm in deep learnin...</td>\n","      <td>machine learning.\\nKeywords Stochastic Gradien...</td>\n","      <td>12.20</td>\n","      <td>0.4</td>\n","      <td>0.5</td>\n","      <td>13.95</td>\n","      <td>36.90</td>\n","      <td>0.190476</td>\n","      <td>7</td>\n","      <td>0.879844</td>\n","      <td>0.641738</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>What is the main advantage of using L3Ms for a...</td>\n","      <td>L3Ms enable tailored alignments by allowing co...</td>\n","      <td>Compressed SGD is a technique used to accelera...</td>\n","      <td>robustness of these techniques in distributed ...</td>\n","      <td>14.64</td>\n","      <td>0.8</td>\n","      <td>16.9</td>\n","      <td>0.52</td>\n","      <td>36.90</td>\n","      <td>0.010000</td>\n","      <td>7</td>\n","      <td>0.925140</td>\n","      <td>0.582782</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What approach is typically used to align LLMs ...</td>\n","      <td>Existing methods usually align LLMs with heuri...</td>\n","      <td>PowerSGD is a gradient compression technique u...</td>\n","      <td>capturing the primary directions of the gradie...</td>\n","      <td>12.37</td>\n","      <td>10.8</td>\n","      <td>8.9</td>\n","      <td>0.37</td>\n","      <td>36.90</td>\n","      <td>0.044444</td>\n","      <td>8</td>\n","      <td>0.904165</td>\n","      <td>0.544810</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>In the L3Ms framework, how are constraints app...</td>\n","      <td>Constraints are enforced using a logarithmic b...</td>\n","      <td>\\nTop-K SGD and PowerSGD differ in their compr...</td>\n","      <td>gradient compression: PowerSGD uses low-rank a...</td>\n","      <td>11.88</td>\n","      <td>17.8</td>\n","      <td>9.2</td>\n","      <td>3.34</td>\n","      <td>36.90</td>\n","      <td>0.771084</td>\n","      <td>7</td>\n","      <td>0.908933</td>\n","      <td>0.568917</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1930b020-0622-4873-a0ac-194aa31dba2b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1930b020-0622-4873-a0ac-194aa31dba2b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1930b020-0622-4873-a0ac-194aa31dba2b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-eee56357-d575-4629-9208-b715b2339ec4\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eee56357-d575-4629-9208-b715b2339ec4')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-eee56357-d575-4629-9208-b715b2339ec4 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"combined_df","summary":"{\n  \"name\": \"combined_df\",\n  \"rows\": 200,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 197,\n        \"samples\": [\n          \"What is the function of the implicit correlation encoder in DECRL?\",\n          \"What is Scene Return Consistency (SRC) in the context of SLOWFAST-VGEN?\",\n          \"What type of datasets are used in the experiments, and why?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"Prompt-driven diverse sampling generates a wider range of high-quality search queries, leading to better exploration and more effective reinforcement learning outcomes than high-temperature sampling alone.\",\n          \"The paper proposes a kernel approximation regularization (KR), allowing low-dimensional bilinear features to approximate the kernel function and maintain distance expansion.\",\n          \"They often struggle with unstable training dynamics and mode collapse, particularly when dealing with heavy-tailed distributions.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rag_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 105,\n        \"samples\": [\n          \"The main contribution of the paper is the development and application of identifiability theory to understand the properties of next-token predictors. Specifically, the authors provide three main contributions:\\n\\n1. An identifiability result characterizing distribution-equivalent next-token predictors. This generalizes previous results by Roeder et al. and provides conditions under which all or none of the models in the \\u223cEL equivalence class share the same linear property.\\n2. A subsume framework for several linear properties, including relational linearity. The authors define an analogue to relational linearity and represent entities as vectors, binary relations as matrices, and the operation of applying a relation to an entity through matrix multiplication.\\n3. A showing that under suitable conditions, these linear properties either hold in all or none of the models generating a given distribution. This combines the definitions in Section 4 and the characterization of distribution-equivalent next-token prediction models in Section 3.\\n\\nOverall, the paper provides a theoretical foundation for understanding the properties of next-token predictors and their relationship to distribution-equivalent models.\",\n          \"The main objective of the Multi-Student Distillation (MSD) framework is to maximize a weighted combination of two key sub-objectives: maximizing task performance and minimizing communication resource costs. The SoS manager's primary goal is to find the optimal allocation of communication networks among workers, which involves utilizing communication resources while minimizing the Kullback\\u2013Leibler divergence between the approximated posterior and the prior.\",\n          \"The main function of the masked conditional video diffusion model in SLOW FAST-VGEN is to condition on language inputs denoting actions and the preceding video chunk to generate the subsequent chunk. The model uses a masked diffusion process, where only the frames that correspond to the actions are unmasked, to learn the world dynamics. This allows the model to memorize the trajectories prior to the current context window, leading to more consistent and coherent long-term videos.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contexts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"Table 4 that while sampling with higher temperature improves diversity in search queries, few-shot\\nprompting leads to significantly higher quality data and using multiple few-shot prompts provides\\ncomparable diversity.\\nWe train on four of the sampled datasets: (1) queries sampled with diverse few-shot prompting at\\nstandard temperature (0.7), (2) queries sampled at a high temperature (2.0), (3) queries sampled with\\n8 Fixed few-shot @ temp 2.0 93,613 92,542 47.7 13.5 2.41 1.32 0.16 0.038\\nDiverse few-shot @ temp 2.0 95,373 71,433 47.5 12.3 2.47 1.34 0.17 0.044\\nDiverse few-shot @ temp 0.7 105,506 49,304 54.2 13.8 2.35 1.28 0.15 0.031\\nTable 4: Sampling with higher temperature results in greater diversity of responses (higher\\nunique ap, ap std dev) while few shot prompting results in better data (higher gold rate). version of LeReT and find that its performance improves over iterations. Our analysis reveals that\\nprompt-driven diverse sampling is critical for LeReT to be effective, and we also analyze different\\nways to generate rewards for retrievals. Finally, our experiments find that LeReT can be used across\\nretrievers, and thus, provides a simple and general framework for improving retrieval. While we\\nfocus on retrieval for grounding LLM answers in this work, the core method behind LeReT can be responds to the exploration problem in RL. As our experiments later in Section 5.4 also indicate, a\\ngood distribution of queries would result in diverse outcomes (for better exploration), but it is impor-\\ntant that some queries produce high quality retrievals. To sample such diverse and effective queries,\\nLeReT moves beyond high-temperature sampling and uses a diverse set of examples to few-shot\\nprompt the LLM \\u03c0r. We use DSPy (Khattab et al., 2022; 2023)\\u2019s prompt optimizers, specifically We now evaluate how LeReT impacts the quality of retrieval and of downstream generation. We\\nfirst test LeReT on two multi-hop question answering datasets, finding that LeReT significantly\\noutperforms baselines such as few-shot prompting and supervised fine-tuning. We also find that\\napplying LeReT iteratively leads to further improvement over iterations. We analyze prompt driven\\ndiverse sampling in contrast with sampling using high temperature and also discuss different reward that alternates between sampling and optimization. Finally, we combine the elements and give a\\npractical overview in Section 4.3.\\n4.1 P ROMPT DRIVEN DIVERSE QUERY GENERATION\\nGiven a dataset of questions, we want to \\u201ctry\\u201d a set of search queries and observe the retrieved\\ndocuments. What queries would be good to observe the retrieved documents for? This roughly cor-\\nresponds to the exploration problem in RL. As our experiments later in Section 5.4 also indicate, a\",\n          \"achieves good results on some datasets. This validates that\\nbilinear pooling can help hyperbolic representation learning.\\nOur low-dimensional version can surpass the naive bilinear\\npooling, which may be because our proposed regularization\\ncan adjust the non-linearity of the bilinear pooling, while the\\nnaive one can not because it does not adopt the normalization\\nstrategy. This demonstrates the superiority of the proposed\\nmethod.\\nFor the OGB datasets (large datasets), the results are sum- ability, and the distances among the obtained low-\\ndimensional features are upper-bounded by a con-\\nstant.\\nThe proof is presented in the Appendix.\\nIn the following section, we want to introduce a novel\\napproach to utilize the benefits of the two types of compact\\nbilinear pooling and discard their shortcomings.\\n3.2 Kernel approximation regularization\\nWe also employ the Hadamard product bilinear projection\\nlike Eq.(8) to learn the low-dimension bilinear features be- shelf low-dimensional bilinear pooling methods cannot be di-\\nrectly employed in hyperbolic representation learning because\\nthey inevitably reduce the distance expansion capability. To\\nsolve this problem, we propose a kernel approximation regular-\\nization, which enables the low-dimensional bilinear features\\nto approximate the kernel function well in low-dimensional\\nspace. Finally, we conduct extensive experiments on graph-\\nstructured datasets to demonstrate the effectiveness of the expand the distances of input features. Random Maclaurin\\nprojection can keep that ability of distance expansion, but its\\nperformance is not stable, requiring the high dimension of its\\noutputs (Yu, Li, and Li 2021).\\nTo address the above problem, we propose a regularization\\nterm named kernel approximation regularization ( KR),\\nwhich lets the inner product of the low-dimensional bilinear\\nfeatures approximate a given kernel function. The benefits of the backbone\\u2019s generalization ability. To address this issue, we\\nintroduce second-order pooling into hyperbolic representation\\nlearning, as it naturally increases the distance between samples\\nwithout compromising the generalization ability of the input\\nfeatures. In this way, the Lipschitz constant of the backbone\\ndoes not necessarily need to be large. However, current off-the-\\nshelf low-dimensional bilinear pooling methods cannot be di-\",\n          \"Implicit generative models employ a neural network (NN) g\\u03b8 to convert a r.v. z\\ndrawn from a (known and typically simple) probability density function (pdf) pz into a\\ntransformed variate \\u02dcy = g\\u03b8(z) with pdf \\u02dcp. The objective is to select the set of parameters\\n\\u03b8in such a way that the pdf \\u02dcp resembles a prescribed density p as much as possible.\\nSpecifically, the training process aims at minimising a discrepancy d(p, \\u02dcp), such that\\nd(p, \\u02dcp) = 0 if and only if p = \\u02dcp. and statistics, such as classifiers for object recognition, sequence models for machine\\ntranslation, and spatio-temporal models for disease spread [4, 5]. Implicit models, as\\nhighlighted by [6], directly generate data using a stochastic procedure, and are effective\\nin areas like climate science, population genetics, and ecology [7, 8, 9, 10, 11].\\nImplicit generative models employ a neural network (NN) g\\u03b8 to convert a r.v. z terised using heavy-tailed probability distributions, and traditional implicit methods\\nstruggle to e ffectively capture their asymptotic behavior. To address this problem,\\nwe introduce a generator trained with ISL, that uses input noise from a generalised\\nPareto distribution (GPD). We refer to this generative scheme as Pareto-ISL for concise-\\nness. Our experiments demonstrate that Pareto-ISL accurately models the tails of the generated data using adversarial discriminators, which can lead to unstable training\\ndynamics and mode dropping issues. In this work, we build on the invariant statistical\\nloss (ISL) method introduced in [1], and extend it to handle heavy-tailed and multivariate\\ndata distributions.\\nThe data generated by many real-world phenomena can only be properly charac-\\nterised using heavy-tailed probability distributions, and traditional implicit methods 8: If hypothesis \\\"AK is uniform\\\" is accepted and K(i) <Kmax do\\n9: Set K = K(i+1)\\n10: return g\\u03b8\\nGaussian noise is used as an input, NNs struggle to capture the tails of Cauchy mixtures,\\nsince compactly supported inputs cannot produce unbounded pdfs (which we will refer\\nto as unbounded distributions). This issue can be addressed by using input noise from a\\ngeneralized Pareto distribution (GPD). In this section, we introduce Pareto-ISL, which 1. Introduction\\n1.1. Motivation\\nProbabilistic models can be divided into two primary types: prescribed models and\\nimplicit models [2]. Prescribed models give a parametric description of the distribution\\nof an observed random variable (r.v.) x using a log-likelihood function log q\\u03b8(x), where\\n\\u03b8 denotes the parameters [ 3]. They include standard models in machine learning\\nand statistics, such as classifiers for object recognition, sequence models for machine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_times\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.494634518766392,\n        \"min\": 7.02,\n        \"max\": 49.4,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          10.58,\n          9.03,\n          11.38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_start_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.2202131159123475,\n        \"min\": 0.3,\n        \"max\": 17.8,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          3.8,\n          3.2,\n          9.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_end_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.9562639093724528,\n        \"min\": 0.2,\n        \"max\": 16.9,\n        \"num_unique_values\": 55,\n        \"samples\": [\n          6.7,\n          0.4,\n          6.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_cpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.7214582943630337,\n        \"min\": 0.15,\n        \"max\": 13.95,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          9.72,\n          1.35,\n          1.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_gpu_usages\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.53946868943207,\n        \"min\": 27.4,\n        \"max\": 90.35,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          72.88,\n          27.4,\n          69.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21233588252152705,\n        \"min\": 0.01,\n        \"max\": 1.0,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          0.4193548387096774,\n          0.7710843373493976,\n          0.782608695652174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 9,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          7,\n          9,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"groundedness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0688403414234784,\n        \"min\": 0.60773396,\n        \"max\": 0.96667546,\n        \"num_unique_values\": 200,\n        \"samples\": [\n          0.76129705,\n          0.795903,\n          0.88685346\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09152136646421564,\n        \"min\": 0.5284089,\n        \"max\": 0.93360245,\n        \"num_unique_values\": 200,\n        \"samples\": [\n          0.62012374,\n          0.7052256,\n          0.8432518\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_judge_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 9,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          8,\n          7,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SbKh4nPOnMoX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731217752543,"user_tz":480,"elapsed":8623,"user":{"displayName":"neelamegam divya","userId":"04586948823655281329"}},"outputId":"b99799ef-42f1-41bd-8347-dbf4c0fcfffd"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Average correctness of RAG answers:\n","                model  context_relevance  answer_relevance  groundedness  \\\n","0  Ensemble Retriever           0.607526               7.5      0.815855   \n","\n","   answer_correctness  human_judge_score  \n","0            0.726977               7.72  \n","\n","Average CPU performance metrics:\n","                model  response_times  cpu_start_usages  cpu_end_usages  \\\n","0  Ensemble Retriever         10.1532            3.2015           3.156   \n","\n","   average_cpu_usages  average_gpu_usages  \n","0             2.78565             72.7211  \n"]}],"source":["import pandas as pd\n","import os\n","\n","# Define the column names that match the expected structure of your metrics CSVs\n","column_names = ['question', 'ground_truth', 'rag_answer', 'contexts', 'response_times',\n","                'cpu_start_usages', 'cpu_end_usages', 'average_cpu_usages', 'average_gpu_usages',\n","                'context_relevance', 'answer_relevance', 'groundedness', 'answer_correctness',\n","                'human_judge_score']\n","\n","# Path to the directory containing the metric files\n","metrics_directory = '/content/drive/MyDrive/298A/search_engine/metrics'\n","\n","# List to store all the metric DataFrames\n","metrics_list = []\n","\n","# Loop through all CSV files in the directory and load them into DataFrames\n","for file in os.listdir(metrics_directory):\n","    if file.endswith('.csv'):  # Assuming the metrics files are CSVs\n","        file_path = os.path.join(metrics_directory, file)\n","        df = pd.read_csv(file_path, header=None, names=column_names)  # Load without headers and assign column names\n","        metrics_list.append(df)\n","\n","# Concatenate all DataFrames into one DataFrame\n","combined_df = pd.concat(metrics_list, ignore_index=True)\n","\n","\n","# Columns for correctness of RAG answers\n","correctness_columns = ['context_relevance', 'answer_relevance', 'groundedness', 'answer_correctness', 'human_judge_score']\n","\n","# Ensure that the correctness columns are numeric\n","combined_df[correctness_columns] = combined_df[correctness_columns].apply(pd.to_numeric, errors='coerce')\n","\n","# Compute the average correctness of RAG answers for the entire dataset\n","rag_correctness_avg = combined_df[correctness_columns].mean(axis=0)\n","\n","# Convert the computed averages to a DataFrame for easy viewing\n","rag_correctness_avg_df = pd.DataFrame(rag_correctness_avg).transpose()\n","\n","# Add the \"model\" column with the value \"Ensemble Retriever\"\n","rag_correctness_avg_df.insert(0, 'model', 'Ensemble Retriever')\n","\n","# Display the average correctness of RAG answers\n","print(\"\\nAverage correctness of RAG answers:\")\n","print(rag_correctness_avg_df.head())\n","\n","# Check if the necessary columns are numeric, and convert them if necessary\n","cpu_columns = ['response_times', 'cpu_start_usages', 'cpu_end_usages', 'average_cpu_usages', 'average_gpu_usages']\n","\n","# Ensure that the CPU columns are numeric\n","cpu_df= combined_df[cpu_columns]\n","\n","# Compute the average CPU performance metrics for the entire dataset\n","cpu_performance_avg = cpu_df[cpu_columns].mean(axis=0)\n","\n","# Convert the computed averages to a DataFrame for easy viewing\n","cpu_performance_avg_df = pd.DataFrame(cpu_performance_avg).transpose()\n","\n","# Add the \"model\" column with the value \"Ensemble Retriever\"\n","cpu_performance_avg_df.insert(0, 'model', 'Ensemble Retriever')\n","\n","# Display the average CPU performance metrics\n","print(\"\\nAverage CPU performance metrics:\")\n","print(cpu_performance_avg_df.head())\n","\n"]}]}